# encoding:utf-8
import json
import os
import html
from urllib.parse import urlparse, quote
import time
import re
import random

import requests
import plugins
from bridge.context import ContextType
from bridge.reply import Reply, ReplyType
from common.log import logger
from plugins import *

# é»˜è®¤è®¤ä¸ºrequestså·²å®‰è£…ï¼Œå› ä¸ºå®ƒæ˜¯åŸºæœ¬ä¾èµ–
has_requests = True

# å°è¯•å¯¼å…¥BeautifulSoupå’Œrequests_htmlï¼Œç”¨äºé«˜çº§å†…å®¹æå–
try:
    from bs4 import BeautifulSoup
    has_bs4 = True
except ImportError:
    has_bs4 = False
    logger.warning("[JinaSum] BeautifulSoupåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨éƒ¨åˆ†å†…å®¹æå–åŠŸèƒ½")

try:
    from requests_html import HTMLSession
    has_requests_html = True
except ImportError:
    has_requests_html = False
    logger.warning("[JinaSum] requests_htmlåº“æœªå®‰è£…ï¼ŒåŠ¨æ€å†…å®¹æå–åŠŸèƒ½å°†ä¸å¯ç”¨")

# æ€»ä½“åˆ¤æ–­æ˜¯å¦å¯ä»¥ä½¿ç”¨é«˜çº§å†…å®¹æå–æ–¹æ³•
can_use_advanced_extraction = has_bs4 and has_requests

@plugins.register(
    name="JinaSum",
    desire_priority=20,
    hidden=False,
    desc="Sum url link content with jina reader and llm",
    version="1.1.0",
    author="AI assistant",
)
class JinaSum(Plugin):
    """ç½‘é¡µå†…å®¹æ€»ç»“æ’ä»¶

    åŠŸèƒ½ï¼š
    1. è‡ªåŠ¨æ€»ç»“åˆ†äº«çš„ç½‘é¡µå†…å®¹
    2. æ”¯æŒæ‰‹åŠ¨è§¦å‘æ€»ç»“
    3. æ”¯æŒç¾¤èŠå’Œå•èŠä¸åŒå¤„ç†æ–¹å¼
    4. æ”¯æŒé»‘åå•ç¾¤ç»„é…ç½®
    """

    # é»˜è®¤é…ç½®
    DEFAULT_CONFIG = {
        # åŸºç¡€é…ç½®
        "jina_reader_base": "https://r.jina.ai",
        "max_words": 8000,
        "prompt": "ç”¨ç®€æ´å‡ç»ƒçš„ä¸­æ–‡å¯¹ä»¥ä¸‹æ–‡æœ¬å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œæ€»ç»“è¾“å‡ºåŒ…æ‹¬ä»¥ä¸‹ä¸‰ä¸ªéƒ¨åˆ†(é™¤æ­¤ä¹‹å¤–æ— éœ€ä»»ä½•é¢å¤–çš„è§£é‡Šï¼Œæ€»å­—æ•°ä¸è¶…è¿‡300å­—)ï¼š\nğŸ“– ä¸€å¥è¯æ€»ç»“\n ğŸ’¡å…³é”®è¦ç‚¹,ç”¨æ•°å­—åºå·åˆ—å‡º3-5ä¸ªæ–‡ç« çš„æ ¸å¿ƒå†…å®¹\nğŸ”– æ ‡ç­¾: #xx #xx\nè¯·ä½¿ç”¨emojiè®©ä½ çš„è¡¨è¾¾æ›´ç”ŸåŠ¨ã€‚",

        # OpenAI API é…ç½®
        "open_ai_api_base": "",
        "open_ai_api_key": "",
        "open_ai_model": "gpt-3.5-turbo",

        # URL ç™½åå•å’Œé»‘åå•
        "white_url_list": [],
        "black_url_list": [
            "https://support.weixin.qq.com",  # è§†é¢‘å·è§†é¢‘
            "https://channels-aladin.wxqcloud.qq.com",  # è§†é¢‘å·éŸ³ä¹
        ],

        # ç”¨æˆ·å’Œç¾¤ç»„æ§åˆ¶
        "auto_sum": True,
        "white_user_list": [],  # ç§èŠç™½åå•
        "black_user_list": [],  # ç§èŠé»‘åå•
        "white_group_list": [],  # ç¾¤èŠç™½åå•
        "black_group_list": [],  # ç¾¤èŠé»‘åå•

        # ç¼“å­˜å’Œè¶…æ—¶è®¾ç½®
        "pending_messages_timeout": 60,  # åˆ†äº«æ¶ˆæ¯ç¼“å­˜æ—¶é—´ï¼ˆé»˜è®¤ 60 ç§’ï¼‰
        "content_cache_timeout": 300,  # æ€»ç»“åæé—®çš„ç¼“å­˜æ—¶é—´ï¼ˆé»˜è®¤ 5 åˆ†é’Ÿï¼‰

        # è§¦å‘è¯è®¾ç½®
        "qa_trigger": "é—®",  # æé—®è§¦å‘è¯

        # Card Summary Feature Config
        "glif_api_token": "", 
        "card_summary_trigger": "jå¡ç‰‡æ€»ç»“",
        "card_summary_glif_id": "cmaxfce170002k004d8cp8iow",
        # "card_summary_default_aspect": "9:16", # User removed this based on testing
        "card_summary_wip_message": "ğŸ‰æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆæ€»ç»“å¡ç‰‡ï¼Œè¯·ç¨å€™...",
        "card_summary_target_domain": "mp.weixin.qq.com",
        "card_summary_api_url": "https://simple-api.glif.app",
        "card_summary_fail_message": "ç”Ÿæˆæ€»ç»“å¡ç‰‡å¤±è´¥ï¼Œè¯·ç¨åå†è¯•æˆ–æ£€æŸ¥URLã€‚",
        "card_summary_invalid_url_message": "è¯·è¾“å…¥æœ‰æ•ˆçš„å¾®ä¿¡å…¬ä¼—å·æ–‡ç« é“¾æ¥ä»¥ç”Ÿæˆå¡ç‰‡ã€‚",
        "card_summary_usage_message": "è¯·æä¾›URLï¼Œæ ¼å¼ï¼šjå¡ç‰‡æ€»ç»“ [URL]",
        "card_summary_api_timeout": 300,  # Timeout for Glif API call in seconds
        "card_summary_api_retries": 2,    # Number of retries for Glif API call
        "card_summary_api_retry_delay": 5 # Delay between retries in seconds
    }

    def __init__(self):
        super().__init__()
        try:
            # åŠ è½½é…ç½®
            self.config = self._load_config()
            if not self.config:
                raise Exception("é…ç½®åŠ è½½å¤±è´¥")

            # ä½¿ç”¨é…ç½®æ›´æ–°å®ä¾‹å±æ€§ï¼Œæ‰¾ä¸åˆ°æ—¶ä½¿ç”¨é»˜è®¤å€¼
            for key, default_value in self.DEFAULT_CONFIG.items():
                setattr(self, key, self.config.get(key, default_value))

            # éªŒè¯å¿…éœ€çš„é…ç½®
            if not self.open_ai_api_key:
                raise Exception("OpenAI API å¯†é’¥æœªé…ç½®")

            # æ¯æ¬¡å¯åŠ¨æ—¶é‡ç½®ç¼“å­˜
            self.pending_messages = {}  # å¾…å¤„ç†æ¶ˆæ¯ç¼“å­˜
            self.content_cache = {}  # æŒ‰ chat_id ç¼“å­˜æ€»ç»“å†…å®¹

            logger.info(f"[JinaSum] inited, config={self.config}")
            self.handlers[Event.ON_HANDLE_CONTEXT] = self.on_handle_context

        except Exception as e:
            logger.error(f"[JinaSum] åˆå§‹åŒ–å¼‚å¸¸ï¼š{e}")
            raise

    def _load_config(self):
        """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®"""
        try:
            # 1. ä½¿ç”¨çˆ¶ç±»æ–¹æ³•æŒ‰ä¼˜å…ˆçº§åŠ è½½æ’ä»¶é…ç½®ï¼ˆä¸Šçº§ç›®å½• > æ’ä»¶ç›®å½• > æ¨¡æ¿æ–‡ä»¶ï¼‰
            config = super().load_config() or {}

            # 2. åŠ è½½ä¸»é…ç½®æ–‡ä»¶
            main_config_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "config.json")
            if os.path.exists(main_config_path):
                with open(main_config_path, "r", encoding="utf-8") as f:
                    main_config = json.load(f)
                    # ç›´æ¥è®¾ç½®group_chat_prefixå®ä¾‹å±æ€§
                    self.group_chat_prefix = main_config.get('group_chat_prefix', ["å°çˆ±","@å°çˆ±"])
            else:
                logger.error("[JinaSum] æœªæ‰¾åˆ°ä¸»é…ç½®æ–‡ä»¶")
                raise Exception("ä¸»é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")

            # 3. ä½¿ç”¨é»˜è®¤é…ç½®è¡¥å……ç¼ºå¤±çš„å€¼
            for key, default_value in self.DEFAULT_CONFIG.items():
                if key not in config:
                    config[key] = default_value

            return config

        except Exception as e:
            logger.error(f"[JinaSum] åŠ è½½é…ç½®å¤±è´¥: {e}")
            raise

    def _get_user_info_from_msg(self, msg, context):
        """ä»æ¶ˆæ¯ä¸­è·å–ç”¨æˆ·ä¿¡æ¯"""
        try:
            # è·å–ç”¨æˆ·å¤‡æ³¨å
            user_remark = None
            if hasattr(msg, '_rawmsg'):
                raw_msg = msg._rawmsg
                if isinstance(raw_msg, dict) and 'Data' in raw_msg:
                    msg_data = raw_msg['Data']
                    if 'PushContent' in msg_data:
                        push_content = msg_data['PushContent']
                        remark_match = re.match(r'^([^:ï¼šåœ¨]+)(?:\s*[:ï¼š]|\s*åœ¨ç¾¤èŠä¸­)', push_content)
                        if remark_match:
                            user_remark = remark_match.group(1).strip()

            is_group = context.get("isgroup", False)

            if is_group:
                chat_id = msg.from_user_id  # ç¾¤ID
                user_id = msg.actual_user_id  # å‘é€è€…ID
                user_name = msg.actual_user_nickname  # å‘é€è€…æ˜µç§°
                group_name = msg.other_user_nickname  # ç¾¤åç§°
                display_name = user_remark or group_name or chat_id  # æ˜¾ç¤ºåç§°
                return {
                    'chat_id': chat_id,
                    'user_id': user_id,
                    'user_name': user_name,
                    'display_name': display_name,
                    'group_name': group_name,
                    'is_group': True
                }
            else:
                user_id = msg.from_user_id
                user_name = msg.actual_user_nickname or msg.from_user_nickname
                display_name = user_remark or user_name or user_id
                return {
                    'chat_id': user_id,
                    'user_id': user_id,
                    'user_name': user_name,
                    'display_name': display_name,
                    'group_name': None,
                    'is_group': False
                }
        except Exception as e:
            logger.error(f"[JinaSum] è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def _should_auto_summarize(self, user_info: dict) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è‡ªåŠ¨æ€»ç»“"""
        try:
            if not user_info:
                return self.auto_sum

            if user_info['is_group']:
                # ç¾¤èŠæƒé™æ£€æŸ¥
                group_identifiers = [
                    user_info['chat_id'],  # ç¾¤ID
                    user_info['group_name'],  # ç¾¤åç§°
                    user_info['display_name']  # æ˜¾ç¤ºåç§°
                ]

                # é»‘åå•ä¼˜å…ˆ
                if any(identifier in self.black_group_list
                      for identifier in group_identifiers if identifier):
                    return False

                # ç™½åå•æ¬¡ä¹‹
                if self.white_group_list:
                    if any(identifier in self.white_group_list
                          for identifier in group_identifiers if identifier):
                        return True
                    return False

                return self.auto_sum
            else:
                # ç§èŠæƒé™æ£€æŸ¥
                user_identifiers = [
                    user_info['user_id'],  # ç”¨æˆ·ID
                    user_info['user_name'],  # ç”¨æˆ·æ˜µç§°
                    user_info['display_name']  # æ˜¾ç¤ºåç§°
                ]

                # é»‘åå•ä¼˜å…ˆ
                if any(identifier in self.black_user_list
                      for identifier in user_identifiers if identifier):
                    return False

                # ç™½åå•æ¬¡ä¹‹
                if self.white_user_list:
                    if any(identifier in self.white_user_list
                          for identifier in user_identifiers if identifier):
                        return True
                    return False

                return self.auto_sum

        except Exception as e:
            logger.error(f"[JinaSum] æ£€æŸ¥è‡ªåŠ¨æ€»ç»“æƒé™å¤±è´¥: {e}")
            return self.auto_sum

    def on_handle_context(self, e_context: EventContext):
        """å¤„ç†æ¶ˆæ¯"""
        context = e_context['context']
        if context.type not in [ContextType.TEXT, ContextType.SHARING]:
            return

        content = context.content
        msg = e_context["context"]["msg"]

        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_info = self._get_user_info_from_msg(msg, context)
        if not user_info:
            return

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ€»ç»“
        should_auto_sum = self._should_auto_summarize(user_info)

        # æ¸…ç†è¿‡æœŸç¼“å­˜
        self._clean_expired_cache()

        # å¤„ç†åˆ†äº«æ¶ˆæ¯
        if context.type == ContextType.SHARING:
            logger.debug(f"[JinaSum] Processing SHARING message, chat_id: {user_info['chat_id']}")
            # æ–°å¢æ—¥å¿—: æ‰“å°is_groupçŠ¶æ€å’Œå³å°†æ£€æŸ¥çš„content (URL)
            logger.info(f"[JinaSum] Pre-check_url: is_group={user_info['is_group']}, content_to_check='{content}'")
            # æ£€æŸ¥ URL æ˜¯å¦æœ‰æ•ˆ
            if not self._check_url(content): # è¿™ä¸€è¡Œæ˜¯ self._check_url(content) çš„è°ƒç”¨ç‚¹
                reply = Reply(ReplyType.TEXT, "æ— æ•ˆçš„URLæˆ–è¢«ç¦æ­¢çš„URLã€‚")
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
                return

            if user_info['is_group']:
                if should_auto_sum:
                    return self._process_summary(content, e_context, user_info['chat_id'], retry_count=0)
                else:
                    self.pending_messages[user_info['chat_id']] = {
                        "content": content,
                        "timestamp": time.time(),
                    }
                    logger.debug(f"[JinaSum] Cached SHARING message: {content}, chat_id: {user_info['chat_id']}")
                    return
            else:  # å•èŠæ¶ˆæ¯
                if should_auto_sum:
                    return self._process_summary(content, e_context, user_info['chat_id'], retry_count=0)
                else:
                    logger.debug(f"[JinaSum] User {user_info['display_name']} not in whitelist, require 'æ€»ç»“' to trigger summary")
                    return

        # å¤„ç†æ–‡æœ¬æ¶ˆæ¯
        elif context.type == ContextType.TEXT:
            logger.debug(f"[JinaSum] Processing TEXT message, chat_id: {user_info['chat_id']}")
            original_content = content.strip() # Keep the original content for command parsing
            
            # è·å–ç¾¤èŠå‰ç¼€åˆ—è¡¨
            group_chat_prefix = self.group_chat_prefix
            content_for_commands = original_content # This will be used for command checks

            # å¤„ç†ç¾¤èŠæ¶ˆæ¯çš„æœºå™¨äººå‰ç¼€ç§»é™¤
            if user_info['is_group']:
                for prefix in group_chat_prefix:
                    pattern = r'^\s*{}\s+'.format(re.escape(prefix))
                    if re.match(pattern, original_content):
                        content_for_commands = re.sub(pattern, '', original_content).strip() # Update for subsequent commands if prefix found
                        break
            
            # Card Summary Command Check (New)
            if content_for_commands.startswith(self.card_summary_trigger):
                command_part = content_for_commands[len(self.card_summary_trigger):].strip()
                url_to_check = None
                if command_part: # Ensure there is something after the trigger
                    url_to_check = command_part.split()[0] # Take the first word as potential URL
                
                if url_to_check and self.card_summary_target_domain in url_to_check and self._check_url(url_to_check):
                    logger.info(f"[JinaSum] Card summary command detected for URL: {url_to_check}")
                    return self._process_card_summary(url_to_check, e_context, user_info['chat_id'])
                elif url_to_check: # URL provided but invalid or not a weixin mp article
                    logger.warning(f"[JinaSum] Invalid or non-MP URL for card summary: {url_to_check}")
                    reply_text = self.card_summary_invalid_url_message
                    if self.card_summary_target_domain not in url_to_check:
                        reply_text += f" (ä»…æ”¯æŒ {self.card_summary_target_domain} åŸŸåä¸‹çš„æ–‡ç« )"
                    reply = Reply(ReplyType.TEXT, reply_text)
                    e_context["reply"] = reply
                    e_context.action = EventAction.BREAK_PASS
                    return
                else: # No URL provided
                    logger.info("[JinaSum] Card summary command received without URL.")
                    reply = Reply(ReplyType.TEXT, self.card_summary_usage_message)
                    e_context["reply"] = reply
                    e_context.action = EventAction.BREAK_PASS
                    return

            # Parse regular summary/QA commands (Existing logic using content_for_commands)
            custom_prompt, url = self._parse_command(content_for_commands)
            if url or custom_prompt:  # å¤„ç†æ€»ç»“æŒ‡ä»¤
                if url:  # ç›´æ¥URLæ€»ç»“
                    return self._process_summary(url, e_context, user_info['chat_id'], custom_prompt=custom_prompt)
                elif user_info['chat_id'] in self.pending_messages:  # å¤„ç†ç¼“å­˜å†…å®¹
                    cached_content = self.pending_messages[user_info['chat_id']]["content"]
                    del self.pending_messages[user_info['chat_id']]
                    return self._process_summary(cached_content, e_context, user_info['chat_id'], skip_notice=True, custom_prompt=custom_prompt)
                else:
                    logger.debug("[JinaSum] No content to summarize")
                    return

            # æ·»åŠ å¤„ç†é—®ç­”è§¦å‘è¯çš„é€»è¾‘
            if hasattr(self, "qa_trigger") and content_for_commands.startswith(self.qa_trigger):
                # å»æ‰è§¦å‘è¯å’Œç©ºæ ¼,è·å–å®é™…é—®é¢˜
                question = content_for_commands[len(self.qa_trigger):].strip()
                if question:  # ç¡®ä¿é—®é¢˜ä¸ä¸ºç©º
                    logger.debug(f"[JinaSum] Processing question: {question}")
                    return self._process_question(question, user_info['chat_id'], e_context)
                else:
                    logger.debug("[JinaSum] Empty question")
                    return

    def _clean_expired_cache(self):
        """æ¸…ç†è¿‡æœŸçš„ç¼“å­˜"""
        current_time = time.time()
        # æ¸…ç†å¾…å¤„ç†æ¶ˆæ¯ç¼“å­˜
        expired_keys = [
            k
            for k, v in self.pending_messages.items()
            if current_time - v["timestamp"] > self.pending_messages_timeout
        ]
        for k in expired_keys:
            del self.pending_messages[k]

        # æ¸…ç† content_cache ä¸­è¿‡æœŸçš„æ•°æ®
        expired_chat_ids = [
            k
            for k, v in self.content_cache.items()
            if current_time - v["timestamp"] > self.content_cache_timeout
        ]
        for k in expired_chat_ids:
            del self.content_cache[k]

    def _process_summary(self, content: str, e_context: EventContext, chat_id: str, retry_count: int = 0, skip_notice: bool = False, custom_prompt: str = None):
        """å¤„ç†æ€»ç»“è¯·æ±‚

        Args:
            content: è¦å¤„ç†çš„å†…å®¹
            e_context: äº‹ä»¶ä¸Šä¸‹æ–‡
            chat_id: ç¾¤åç§°æˆ–ç”¨æˆ·æ˜µç§°
            retry_count: é‡è¯•æ¬¡æ•°
            skip_notice: æ˜¯å¦è·³è¿‡æç¤ºæ¶ˆæ¯
        """
        try:
            if retry_count == 0 and not skip_notice:
                logger.debug(f"[JinaSum] Processing URL: {content}, chat_id: {chat_id}")
                reply = Reply(ReplyType.TEXT, "ğŸ‰æ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆæ€»ç»“ï¼Œè¯·ç¨å€™...")
                channel = e_context["channel"]
                channel.send(reply, e_context["context"])

            # è·å–ç½‘é¡µå†…å®¹
            target_url = html.unescape(content)
            jina_url = self._get_jina_url(target_url)
            logger.debug(f"[JinaSum] Requesting jina url: {jina_url}")

            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
            }
            try:
                response = requests.get(jina_url, headers=headers, timeout=60)
                response.raise_for_status()
                target_url_content = response.text

                # æ£€æŸ¥æ˜¯å¦æ˜¯å¾®ä¿¡å¹³å°æ–‡ç« ï¼Œå¹¶æ£€æŸ¥è¿”å›å†…å®¹æ˜¯å¦åŒ…å«"ç¯å¢ƒå¼‚å¸¸"
                if "mp.weixin.qq.com" in target_url:
                    if not target_url_content or "ç¯å¢ƒå¼‚å¸¸" in target_url_content:
                        logger.error(f"[JinaSum] å¾®ä¿¡å¹³å°æ–‡ç« å†…å®¹è·å–å¤±è´¥æˆ–åŒ…å«'ç¯å¢ƒå¼‚å¸¸': {target_url}")
                        # å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–å†…å®¹
                        if can_use_advanced_extraction:
                            logger.info(f"[JinaSum] å°è¯•ä½¿ç”¨é€šç”¨å†…å®¹æå–æ–¹æ³•è·å–å¾®ä¿¡æ–‡ç« : {target_url}")
                            extracted_content = self._extract_content_general(target_url)
                            if extracted_content and len(extracted_content) > 500 and "ç¯å¢ƒå¼‚å¸¸" not in extracted_content:
                                logger.info(f"[JinaSum] é€šç”¨å†…å®¹æå–æ–¹æ³•æˆåŠŸè·å–å¾®ä¿¡æ–‡ç« : {target_url}, å†…å®¹é•¿åº¦: {len(extracted_content)}")
                                target_url_content = extracted_content
                            elif has_requests_html:
                                logger.info(f"[JinaSum] å°è¯•ä½¿ç”¨åŠ¨æ€å†…å®¹æå–æ–¹æ³•è·å–å¾®ä¿¡æ–‡ç« : {target_url}")
                                dynamic_content = self._extract_dynamic_content(target_url)
                                if dynamic_content and len(dynamic_content) > 500 and "ç¯å¢ƒå¼‚å¸¸" not in dynamic_content:
                                    logger.info(f"[JinaSum] åŠ¨æ€å†…å®¹æå–æ–¹æ³•æˆåŠŸè·å–å¾®ä¿¡æ–‡ç« : {target_url}, å†…å®¹é•¿åº¦: {len(dynamic_content)}")
                                    target_url_content = dynamic_content
                                else:
                                    if not dynamic_content or len(dynamic_content) <= 500:
                                        logger.warning(f"[JinaSum] åŠ¨æ€å†…å®¹æå–æ–¹æ³•è·å–çš„å¾®ä¿¡æ–‡ç« å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º: {target_url}")
                                    elif "ç¯å¢ƒå¼‚å¸¸" in dynamic_content:
                                        logger.warning(f"[JinaSum] åŠ¨æ€å†…å®¹æå–æ–¹æ³•è·å–çš„å¾®ä¿¡æ–‡ç« å†…å®¹åŒ…å«'ç¯å¢ƒå¼‚å¸¸': {target_url}")
                                    raise ValueError("æ— æ³•è·å–å¾®ä¿¡å¹³å°æ–‡ç« å†…å®¹")
                            else:
                                raise ValueError("æ— æ³•è·å–å¾®ä¿¡å¹³å°æ–‡ç« å†…å®¹ï¼Œä¸”æœªå®‰è£…é«˜çº§å†…å®¹æå–æ‰€éœ€çš„åº“")
                        else:
                            raise ValueError("æ— æ³•è·å–å¾®ä¿¡å¹³å°æ–‡ç« å†…å®¹ï¼Œä¸”æœªå®‰è£…é«˜çº§å†…å®¹æå–æ‰€éœ€çš„åº“")
                else:
                    # éå¾®ä¿¡å¹³å°æ–‡ç« ï¼Œåªæ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©º
                    if not target_url_content:
                        logger.error(f"[JinaSum] å†…å®¹è·å–å¤±è´¥ï¼Œè¿”å›ä¸ºç©º: {target_url}")
                        # å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•è·å–å†…å®¹
                        if can_use_advanced_extraction:
                            logger.info(f"[JinaSum] å°è¯•ä½¿ç”¨é€šç”¨å†…å®¹æå–æ–¹æ³•: {target_url}")
                            extracted_content = self._extract_content_general(target_url)
                            if extracted_content and len(extracted_content) > 500:
                                logger.info(f"[JinaSum] é€šç”¨å†…å®¹æå–æ–¹æ³•æˆåŠŸ: {target_url}, å†…å®¹é•¿åº¦: {len(extracted_content)}")
                                target_url_content = extracted_content
                            elif has_requests_html:
                                logger.info(f"[JinaSum] å°è¯•ä½¿ç”¨åŠ¨æ€å†…å®¹æå–æ–¹æ³•: {target_url}")
                                dynamic_content = self._extract_dynamic_content(target_url)
                                if dynamic_content and len(dynamic_content) > 500:
                                    logger.info(f"[JinaSum] åŠ¨æ€å†…å®¹æå–æ–¹æ³•æˆåŠŸ: {target_url}, å†…å®¹é•¿åº¦: {len(dynamic_content)}")
                                    target_url_content = dynamic_content
                                else:
                                    logger.warning(f"[JinaSum] åŠ¨æ€å†…å®¹æå–æ–¹æ³•è·å–çš„å†…å®¹è¿‡çŸ­æˆ–ä¸ºç©º: {target_url}")
                                    raise ValueError("Empty response from all content extraction methods")
                            else:
                                raise ValueError("Empty response from jina reader and no advanced extraction methods available")
                        else:
                            raise ValueError("Empty response from jina reader")
            except Exception as e:
                logger.error(f"[JinaSum] Failed to get content from jina reader: {str(e)}")
                if retry_count < 3:
                    logger.info(f"[JinaSum] Jina Reader Retrying {retry_count + 1}/3...")
                    time.sleep(1) # Jina Reader å¼‚å¸¸æ—¶é‡è¯•é—´éš” 1 ç§’
                    return self._process_summary(content, e_context, chat_id, retry_count + 1)

                reply = Reply(ReplyType.ERROR, f"æ— æ³•è·å–è¯¥å†…å®¹: {str(e)}")
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
                return

            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„å†…å®¹å¤„ç†æ–¹æ³•
                summary = self._process_content_query(target_url_content, custom_prompt, e_context)
                additional_prompt = "\n\nğŸ’¬5minå†…è¾“å…¥jè¿½é—®+é—®é¢˜ï¼Œå¯ç»§ç»­è¿½é—®"
                summary += additional_prompt
                reply = Reply(ReplyType.TEXT, summary)
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS

                # ç¼“å­˜å†…å®¹å’Œæ—¶é—´æˆ³ï¼ŒæŒ‰ chat_id ç¼“å­˜
                self.content_cache[chat_id] = {
                    "url": target_url,
                    "content": target_url_content,
                    "timestamp": time.time(),
                }
                logger.debug(f"[JinaSum] Content cached for chat_id: {chat_id}")

            except Exception as e:
                logger.error(f"[JinaSum] Failed to get summary from OpenAI: {str(e)}")
                if retry_count < 3:
                    logger.info(f"[JinaSum] OpenAI API Retrying {retry_count + 1}/3...")
                    time.sleep(1) # OpenAI API å¼‚å¸¸æ—¶é‡è¯•é—´éš” 2 ç§’
                    return self._process_summary(content, e_context, chat_id, retry_count + 1)
                reply = Reply(ReplyType.ERROR, f"å†…å®¹æ€»ç»“å‡ºç°é”™è¯¯: {str(e)}")
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS

        except Exception as e:
            logger.error(f"[JinaSum] Error in processing summary: {str(e)}", exc_info=True)
            if retry_count < 3:
                logger.info(f"[JinaSum] Retrying {retry_count + 1}/3...")
                time.sleep(1) # å…¶ä»–å¼‚å¸¸ä¹Ÿå¢åŠ 1ç§’é—´éš”
                return self._process_summary(content, e_context, chat_id, retry_count + 1)
            reply = Reply(ReplyType.ERROR, f"æ— æ³•è·å–è¯¥å†…å®¹: {str(e)}")
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS

    def _process_question(self, question: str, chat_id: str, e_context: EventContext, retry_count: int = 0):
        """å¤„ç†é—®é¢˜"""
        try:
            # ä½¿ç”¨ chat_id (ç¾¤åç§°æˆ–ç”¨æˆ·æ˜µç§°) ä½œä¸ºé”®ä» content_cache ä¸­è·å–ç¼“å­˜å†…å®¹
            cache_data = self.content_cache.get(chat_id)
            if (cache_data and time.time() - cache_data["timestamp"] <= self.content_cache_timeout):
                recent_content = cache_data["content"]
            else:
                logger.debug(f"[JinaSum] No valid content cache found or content expired for chat_id: {chat_id}")
                reply = Reply(ReplyType.TEXT, "æ€»ç»“å†…å®¹å·²è¿‡æœŸæˆ–ä¸å­˜åœ¨ï¼Œè¯·é‡æ–°æ€»ç»“åé‡è¯•ã€‚")
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS
                return

            if retry_count == 0:
                reply = Reply(ReplyType.TEXT, "ğŸ¤” æ­£åœ¨æ€è€ƒæ‚¨çš„é—®é¢˜ï¼Œè¯·ç¨å€™...")
                channel = e_context["channel"]
                channel.send(reply, e_context["context"])

            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„å†…å®¹å¤„ç†æ–¹æ³•
                answer = self._process_content_query(recent_content, question, e_context)
                reply = Reply(ReplyType.TEXT, answer)
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS

            except Exception as e:
                logger.error(f"[JinaSum] Failed to get answer from OpenAI: {str(e)}")
                if retry_count < 3:
                    logger.info(f"[JinaSum] OpenAI API Retrying {retry_count + 1}/3...")
                    time.sleep(1)
                    return self._process_question(question, chat_id, e_context, retry_count + 1)
                reply = Reply(ReplyType.ERROR, f"å¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}")
                e_context["reply"] = reply
                e_context.action = EventAction.BREAK_PASS

        except Exception as e:
            logger.error(f"[JinaSum] Error in processing question: {str(e)}")
            if retry_count < 3:
                logger.info(f"[JinaSum] Retrying {retry_count + 1}/3...")
                time.sleep(1) # å…¶ä»–å¼‚å¸¸ä¹Ÿå¢åŠ 1ç§’é—´éš”
                return self._process_question(question, chat_id, e_context, retry_count + 1)
            reply = Reply(ReplyType.ERROR, f"å¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}")
            e_context["reply"] = reply
            e_context.action = EventAction.BREAK_PASS

    def get_help_text(self, verbose=False, **kwargs):
        help_text = "ç½‘é¡µå†…å®¹æ€»ç»“\n"
        if not verbose:
            return help_text

        help_text += "ä½¿ç”¨æ–¹æ³•:\n"
        help_text += "1. æ€»ç»“ç½‘é¡µå†…å®¹:\n"
        help_text += "   - æ€»ç»“ ç½‘å€ (æ€»ç»“æŒ‡å®šç½‘é¡µçš„å†…å®¹)\n"

        if self.auto_sum:
            help_text += "2. å•èŠæ—¶ï¼Œé»˜è®¤è‡ªåŠ¨æ€»ç»“åˆ†äº«æ¶ˆæ¯æˆ–URL\n"
            if self.black_user_list:
                help_text += "   (é»‘åå•ç”¨æˆ·éœ€è¦å‘é€ã€Œæ€»ç»“ã€æ‰èƒ½è§¦å‘)\n"
            if self.white_user_list:
                help_text += "   (ç™½åå•ç”¨æˆ·å°†è‡ªåŠ¨æ€»ç»“)\n"
            help_text += "3. ç¾¤èŠä¸­ï¼Œé»˜è®¤è‡ªåŠ¨æ€»ç»“åˆ†äº«æ¶ˆæ¯æˆ–URL\n"
            if self.black_group_list:
                help_text += "   (é»‘åå•ç¾¤ç»„éœ€è¦å‘é€ã€Œæ€»ç»“ã€æ‰èƒ½è§¦å‘)\n"
            if self.white_group_list:
                help_text += "   (ç™½åå•ç¾¤ç»„å°†è‡ªåŠ¨æ€»ç»“)\n"
        else:
            help_text += "2. å•èŠæ—¶ï¼Œéœ€è¦å‘é€ã€Œæ€»ç»“ã€æ‰èƒ½è§¦å‘æ€»ç»“ï¼Œ ç™½åå•ç”¨æˆ·é™¤å¤–ã€‚\n"
            if self.white_user_list:
                help_text += "  (ç™½åå•ç”¨æˆ·å°†è‡ªåŠ¨æ€»ç»“)\n"
            help_text += "3. ç¾¤èŠä¸­ï¼Œéœ€è¦å‘é€ã€Œæ€»ç»“ã€æ‰èƒ½è§¦å‘æ€»ç»“ï¼Œç™½åå•ç¾¤ç»„é™¤å¤–ã€‚\n"
            if self.white_group_list:
                 help_text += "  (ç™½åå•ç¾¤ç»„å°†è‡ªåŠ¨æ€»ç»“)\n"

        if hasattr(self, "qa_trigger"):
            help_text += (
                f"4. æ€»ç»“å®Œæˆå{self.content_cache_timeout//60}åˆ†é’Ÿå†…ï¼Œå¯ä»¥å‘é€ã€Œ{self.qa_trigger}xxxã€æ¥è¯¢é—®æ–‡ç« ç›¸å…³é—®é¢˜\n"
            )

        help_text += f"æ³¨ï¼šæ‰‹åŠ¨è§¦å‘çš„ç½‘é¡µæ€»ç»“æŒ‡ä»¤éœ€è¦åœ¨{self.pending_messages_timeout}ç§’å†…å‘å‡º"
        return help_text

    def _get_jina_url(self, target_url):
        # åªå¯¹å¾®ä¿¡å…¬ä¼—å·é“¾æ¥åšç‰¹æ®Šå¤„ç†
        if "mp.weixin.qq.com" in target_url:
            # ä½¿ç”¨å®Œå…¨ç¼–ç çš„æ–¹å¼å¤„ç†å¾®ä¿¡URLï¼Œsafe=''ç¡®ä¿æ‰€æœ‰å­—ç¬¦éƒ½è¢«ç¼–ç 
            encoded_url = quote(target_url, safe='')
            logger.info(f"[JinaSum] å¾®ä¿¡å¹³å°æ–‡ç« ï¼Œä½¿ç”¨å®Œå…¨ç¼–ç : {encoded_url}")
            return self.jina_reader_base + "/" + encoded_url
        else:
            # å…¶ä»–ç½‘ç«™ä¿æŒåŸæœ‰å¤„ç†æ–¹å¼
            logger.info(f"[JinaSum] éå¾®ä¿¡å¹³å°æ–‡ç« ï¼Œä½¿ç”¨åŸå§‹URL")
            return self.jina_reader_base + "/" + target_url

    def _get_openai_chat_url(self):
        return self.open_ai_api_base + "/chat/completions"

    def _get_openai_headers(self):
        return {
            "Authorization": f"Bearer {self.open_ai_api_key}",
            "Host": urlparse(self.open_ai_api_base).netloc,
            "Content-Type": "application/json",
        }

    def _get_openai_payload(self, target_url_content):
        target_url_content = target_url_content[: self.max_words]
        sum_prompt = f"{self.prompt}\n\n'''{target_url_content}'''"
        messages = [{"role": "user", "content": sum_prompt}]
        payload = {
            "model": self.open_ai_model,
            "messages": messages,
        }
        return payload

    def _check_url(self, target_url: str):
        """æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆä¸”å…è®¸è®¿é—®

        Args:
            target_url: è¦æ£€æŸ¥çš„URL

        Returns:
            bool: URLæ˜¯å¦æœ‰æ•ˆä¸”å…è®¸è®¿é—®
        """
        stripped_url = target_url.strip()
        parsed_url = urlparse(stripped_url)
        if not parsed_url.scheme or not parsed_url.netloc:
            return False

        # æ£€æŸ¥é»‘åå•ï¼Œé»‘åå•ä¼˜å…ˆ
        for black_url in self.black_url_list:
            if stripped_url.startswith(black_url):
                return False

        # å¦‚æœæœ‰ç™½åå•ï¼Œåˆ™æ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­
        if self.white_url_list:
            if not any(stripped_url.startswith(white_url) for white_url in self.white_url_list):
                return False

        return True

    def _parse_command(self, content: str):
        """è§£ææ€»ç»“æŒ‡ä»¤
        è¿”å›: (custom_prompt, url)

        æ”¯æŒçš„æ ¼å¼:
        1. æ€»ç»“
        2. æ€»ç»“ [URL]
        3. æ€»ç»“ è‡ªå®šä¹‰é—®é¢˜
        4. æ€»ç»“ è‡ªå®šä¹‰é—®é¢˜ [URL]
        """
        # ç§»é™¤å¤šä½™ç©ºæ ¼ï¼Œä½†ä¿ç•™å•è¯é—´çš„ç©ºæ ¼
        content = ' '.join(content.split())

        # æ£€æŸ¥æ˜¯å¦ä»¥"æ€»ç»“"å¼€å¤´
        if not content.startswith("æ€»ç»“"):
            return None, None

        # å»æ‰å¼€å¤´çš„"æ€»ç»“"å’Œç©ºæ ¼
        content = content[2:].strip()
        if not content:  # åªæœ‰"æ€»ç»“"
            return None, None

        # æ£€æŸ¥æœ€åä¸€éƒ¨åˆ†æ˜¯å¦æ˜¯URL
        parts = content.split()
        if self._check_url(parts[-1]):  # æœ€åä¸€éƒ¨åˆ†æ˜¯URL
            url = parts[-1]
            custom_prompt = " ".join(parts[:-1]).strip()  # URLå‰çš„æ‰€æœ‰å†…å®¹ä½œä¸ºæç¤ºè¯
        else:  # æ²¡æœ‰URL
            url = None
            custom_prompt = content.strip()

        # å¦‚æœcustom_promptä¸ºç©ºï¼Œè¯´æ˜æ˜¯æ™®é€šçš„URLæ€»ç»“
        if not custom_prompt:
            return None, url

        return custom_prompt, url

    def _get_default_headers(self):
        """è·å–é»˜è®¤è¯·æ±‚å¤´"""
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5 Safari/605.1.15",
        ]
        selected_ua = random.choice(user_agents)

        return {
            "User-Agent": selected_ua,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Cache-Control": "max-age=0",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1"
        }

    def _extract_content_general(self, url, headers=None):
        """é€šç”¨ç½‘é¡µå†…å®¹æå–æ–¹æ³•ï¼Œæ”¯æŒé™æ€å’ŒåŠ¨æ€é¡µé¢

        é¦–å…ˆå°è¯•é™æ€æå–ï¼ˆæ›´å¿«ã€æ›´è½»é‡ï¼‰ï¼Œå¦‚æœå¤±è´¥æˆ–å†…å®¹å¤ªå°‘å†å°è¯•åŠ¨æ€æå–ï¼ˆæ›´æ…¢ä½†æ›´å¼ºå¤§ï¼‰

        Args:
            url: ç½‘é¡µURL
            headers: å¯é€‰çš„è¯·æ±‚å¤´ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤

        Returns:
            str: æå–çš„å†…å®¹ï¼Œå¤±è´¥è¿”å›None
        """
        if not has_bs4:
            logger.error("[JinaSum] BeautifulSoupåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨é€šç”¨å†…å®¹æå–æ–¹æ³•")
            return None

        try:
            # å¦‚æœæ²¡æœ‰æä¾›headersï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
            if not headers:
                headers = self._get_default_headers()

            # æ·»åŠ éšæœºå»¶è¿Ÿä»¥é¿å…è¢«æ£€æµ‹ä¸ºçˆ¬è™«
            time.sleep(random.uniform(0.5, 2))

            # åˆ›å»ºä¼šè¯å¯¹è±¡
            session = requests.Session()

            # è®¾ç½®åŸºæœ¬cookies
            session.cookies.update({
                f"visit_id_{int(time.time())}": f"{random.randint(1000000, 9999999)}",
                "has_visited": "1",
            })

            # å‘é€è¯·æ±‚è·å–é¡µé¢
            logger.debug(f"[JinaSum] é€šç”¨æå–æ–¹æ³•æ­£åœ¨è¯·æ±‚: {url}")
            response = session.get(url, headers=headers, timeout=30)
            response.raise_for_status()

            # ç¡®ä¿ç¼–ç æ­£ç¡®
            if response.encoding == 'ISO-8859-1':
                response.encoding = response.apparent_encoding

            # ä½¿ç”¨BeautifulSoupè§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')

            # ç§»é™¤æ— ç”¨å…ƒç´ 
            for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'form', 'iframe']):
                element.extract()

            # å¯»æ‰¾å¯èƒ½çš„æ ‡é¢˜
            title = None

            # å°è¯•å¤šç§æ ‡é¢˜é€‰æ‹©å™¨
            title_candidates = [
                soup.select_one('h1'),  # æœ€å¸¸è§çš„æ ‡é¢˜æ ‡ç­¾
                soup.select_one('title'),  # HTMLæ ‡é¢˜
                soup.select_one('.title'),  # å¸¸è§çš„æ ‡é¢˜ç±»
                soup.select_one('.article-title'),  # å¸¸è§çš„æ–‡ç« æ ‡é¢˜ç±»
                soup.select_one('.post-title'),  # åšå®¢æ ‡é¢˜
                soup.select_one('[class*="title" i]'),  # åŒ…å«titleçš„ç±»
            ]

            for candidate in title_candidates:
                if candidate and candidate.text.strip():
                    title = candidate.text.strip()
                    break

            # æŸ¥æ‰¾å¯èƒ½çš„å†…å®¹å…ƒç´ 
            content_candidates = []

            # 1. å°è¯•æ‰¾å¸¸è§çš„å†…å®¹å®¹å™¨
            content_selectors = [
                'article', 'main', '.content', '.article', '.post-content',
                '[class*="content" i]', '[class*="article" i]',
                '.story', '.entry-content', '.post-body',
                '#content', '#article', '.body'
            ]

            for selector in content_selectors:
                elements = soup.select(selector)
                if elements:
                    content_candidates.extend(elements)

            # 2. å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„å†…å®¹å®¹å™¨ï¼Œå¯»æ‰¾å…·æœ‰æœ€å¤šæ–‡æœ¬çš„divå…ƒç´ 
            if not content_candidates:
                paragraphs = {}
                # æŸ¥æ‰¾æ‰€æœ‰æ®µè½å’Œdiv
                for elem in soup.find_all(['p', 'div']):
                    text = elem.get_text(strip=True)
                    # åªè€ƒè™‘æœ‰å®é™…å†…å®¹çš„å…ƒç´ 
                    if len(text) > 100:
                        paragraphs[elem] = len(text)

                # æ‰¾å‡ºæ–‡æœ¬æœ€å¤šçš„å…ƒç´ 
                if paragraphs:
                    max_elem = max(paragraphs.items(), key=lambda x: x[1])[0]
                    # å¦‚æœæ˜¯divï¼Œç›´æ¥æ·»åŠ ï¼›å¦‚æœæ˜¯pï¼Œå°è¯•æ‰¾å…¶çˆ¶å…ƒç´ 
                    if max_elem.name == 'div':
                        content_candidates.append(max_elem)
                    else:
                        # æ‰¾åŒ…å«å¤šä¸ªæ®µè½çš„çˆ¶å…ƒç´ 
                        parent = max_elem.parent
                        if parent and len(parent.find_all('p')) > 3:
                            content_candidates.append(parent)
                        else:
                            content_candidates.append(max_elem)

            # 3. ç®€å•ç®—æ³•æ¥è¯„åˆ†å’Œé€‰æ‹©æœ€ä½³å†…å®¹å…ƒç´ 
            best_content = None
            max_score = 0

            for element in content_candidates:
                # è®¡ç®—æ–‡æœ¬é•¿åº¦
                text = element.get_text(strip=True)
                text_length = len(text)

                # è®¡ç®—æ–‡æœ¬å¯†åº¦ï¼ˆæ–‡æœ¬é•¿åº¦/HTMLé•¿åº¦ï¼‰
                html_length = len(str(element))
                text_density = text_length / html_length if html_length > 0 else 0

                # è®¡ç®—æ®µè½æ•°é‡
                paragraphs = element.find_all('p')
                paragraph_count = len(paragraphs)

                # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
                images = element.find_all('img')
                image_count = len(images)

                # æ ¹æ®å„ç§ç‰¹å¾è®¡ç®—åˆ†æ•°
                score = (
                    text_length * 1.0 +  # æ–‡æœ¬é•¿åº¦å¾ˆé‡è¦
                    text_density * 100 +  # æ–‡æœ¬å¯†åº¦å¾ˆé‡è¦
                    paragraph_count * 30 +  # æ®µè½æ•°é‡ä¹Ÿå¾ˆé‡è¦
                    image_count * 10  # å›¾ç‰‡ä¸å¤ªé‡è¦ï¼Œä½†ä¹Ÿæ˜¯ä¸€ä¸ªæŒ‡æ ‡
                )

                # å‡åˆ†é¡¹ï¼šå¦‚æœåŒ…å«è®¸å¤šé“¾æ¥ï¼Œå¯èƒ½æ˜¯å¯¼èˆªæˆ–ä¾§è¾¹æ 
                links = element.find_all('a')
                link_text_ratio = sum(len(a.get_text(strip=True)) for a in links) / text_length if text_length > 0 else 0
                if link_text_ratio > 0.5:  # å¦‚æœé“¾æ¥æ–‡æœ¬å æ¯”è¿‡é«˜
                    score *= 0.5

                # æ›´æ–°æœ€ä½³å†…å®¹
                if score > max_score:
                    max_score = score
                    best_content = element

            # å¦‚æœæ‰¾åˆ°å†…å®¹ï¼Œæå–å¹¶æ¸…ç†æ–‡æœ¬
            static_content_result = None
            if best_content:
                # é¦–å…ˆç§»é™¤å†…å®¹ä¸­å¯èƒ½çš„å¹¿å‘Šæˆ–æ— å…³å…ƒç´ 
                for ad in best_content.select('[class*="ad" i], [class*="banner" i], [id*="ad" i], [class*="recommend" i]'):
                    ad.extract()

                # è·å–å¹¶æ¸…ç†æ–‡æœ¬
                content_text = best_content.get_text(separator='\n', strip=True)

                # ç§»é™¤å¤šä½™çš„ç©ºç™½è¡Œ
                content_text = re.sub(r'\n{3,}', '\n\n', content_text)

                # æ„å»ºæœ€ç»ˆè¾“å‡º
                result = ""
                if title:
                    result += f"æ ‡é¢˜: {title}\n\n"

                result += content_text

                logger.debug(f"[JinaSum] é€šç”¨æå–æ–¹æ³•æˆåŠŸï¼Œæå–å†…å®¹é•¿åº¦: {len(result)}")
                static_content_result = result

            # åˆ¤æ–­é™æ€æå–çš„å†…å®¹è´¨é‡
            content_is_good = False
            if static_content_result:
                # å†…å®¹é•¿åº¦æ£€æŸ¥
                if len(static_content_result) > 1000:
                    content_is_good = True
                # ç»“æ„æ£€æŸ¥ - è‡³å°‘åº”è¯¥æœ‰å¤šä¸ªæ®µè½
                elif static_content_result.count('\n\n') >= 3:
                    content_is_good = True

            # å¦‚æœé™æ€æå–å†…å®¹è´¨é‡ä¸ä½³ï¼Œå°è¯•åŠ¨æ€æå–
            if not content_is_good:
                logger.debug("[JinaSum] é™æ€æå–å†…å®¹è´¨é‡ä¸ä½³ï¼Œå°è¯•åŠ¨æ€æå–")
                dynamic_content = self._extract_dynamic_content(url, headers)
                if dynamic_content:
                    logger.debug(f"[JinaSum] åŠ¨æ€æå–æˆåŠŸï¼Œå†…å®¹é•¿åº¦: {len(dynamic_content)}")
                    return dynamic_content

            return static_content_result

        except Exception as e:
            logger.error(f"[JinaSum] é€šç”¨å†…å®¹æå–æ–¹æ³•å¤±è´¥: {str(e)}")
            return None

    def _extract_dynamic_content(self, url, headers=None):
        """ä½¿ç”¨JavaScriptæ¸²æŸ“æå–åŠ¨æ€é¡µé¢å†…å®¹

        Args:
            url: ç½‘é¡µURL
            headers: å¯é€‰çš„è¯·æ±‚å¤´

        Returns:
            str: æå–çš„å†…å®¹ï¼Œå¤±è´¥è¿”å›None
        """
        if not has_requests_html:
            logger.error("[JinaSum] requests_htmlåº“æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨åŠ¨æ€å†…å®¹æå–æ–¹æ³•")
            return None

        try:
            logger.debug(f"[JinaSum] å¼€å§‹åŠ¨æ€æå–å†…å®¹: {url}")

            # åˆ›å»ºä¼šè¯å¹¶è®¾ç½®è¶…æ—¶
            session = HTMLSession()

            # æ·»åŠ è¯·æ±‚å¤´
            req_headers = headers or self._get_default_headers()

            # è·å–é¡µé¢
            response = session.get(url, headers=req_headers, timeout=30)

            # æ‰§è¡ŒJavaScript (è®¾ç½®è¶…æ—¶ï¼Œé˜²æ­¢æ— é™ç­‰å¾…)
            logger.debug("[JinaSum] å¼€å§‹æ‰§è¡ŒJavaScript")
            response.html.render(timeout=20, sleep=2)
            logger.debug("[JinaSum] JavaScriptæ‰§è¡Œå®Œæˆ")

            # å¤„ç†æ¸²æŸ“åçš„HTML
            rendered_html = response.html.html

            # ä½¿ç”¨BeautifulSoupè§£ææ¸²æŸ“åçš„HTML
            soup = BeautifulSoup(rendered_html, 'html.parser')

            # æ¸…ç†æ— ç”¨å…ƒç´ 
            for element in soup(['script', 'style', 'nav', 'header', 'footer', 'aside']):
                element.extract()

            # æŸ¥æ‰¾æ ‡é¢˜
            title = None
            title_candidates = [
                soup.select_one('h1'),
                soup.select_one('title'),
                soup.select_one('.title'),
                soup.select_one('[class*="title" i]'),
            ]

            for candidate in title_candidates:
                if candidate and candidate.text.strip():
                    title = candidate.text.strip()
                    break

            # å¯»æ‰¾ä¸»è¦å†…å®¹
            main_content = None

            # 1. å°è¯•æ‰¾ä¸»è¦å†…å®¹å®¹å™¨
            main_selectors = [
                'article', 'main', '.content', '.article',
                '[class*="content" i]', '[class*="article" i]',
                '#content', '#article'
            ]

            for selector in main_selectors:
                elements = soup.select(selector)
                if elements:
                    # é€‰æ‹©åŒ…å«æœ€å¤šæ–‡æœ¬çš„å…ƒç´ 
                    main_content = max(elements, key=lambda x: len(x.get_text()))
                    break

            # 2. å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå¯»æ‰¾æ–‡æœ¬æœ€å¤šçš„div
            if not main_content:
                paragraphs = {}
                for elem in soup.find_all(['div']):
                    text = elem.get_text(strip=True)
                    if len(text) > 200:  # åªè€ƒè™‘é•¿æ–‡æœ¬
                        paragraphs[elem] = len(text)

                if paragraphs:
                    main_content = max(paragraphs.items(), key=lambda x: x[1])[0]

            # 3. å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨æ•´ä¸ªbody
            if not main_content:
                main_content = soup.body

            # ä»ä¸»è¦å†…å®¹ä¸­æå–æ–‡æœ¬
            if main_content:
                # æ¸…ç†å¯èƒ½çš„å¹¿å‘Šæˆ–æ— å…³å…ƒç´ 
                for ad in main_content.select('[class*="ad" i], [class*="banner" i], [id*="ad" i], [class*="recommend" i]'):
                    ad.extract()

                # è·å–æ–‡æœ¬
                content_text = main_content.get_text(separator='\n', strip=True)
                content_text = re.sub(r'\n{3,}', '\n\n', content_text)  # æ¸…ç†å¤šä½™ç©ºè¡Œ

                # æ„å»ºæœ€ç»ˆç»“æœ
                result = ""
                if title:
                    result += f"æ ‡é¢˜: {title}\n\n"
                result += content_text

                # å…³é—­ä¼šè¯
                session.close()

                return result

            # å…³é—­ä¼šè¯
            session.close()

            return None

        except Exception as e:
            logger.error(f"[JinaSum] åŠ¨æ€æå–å¤±è´¥: {str(e)}")
            return None

    def _call_glif_for_card(self, prompt_text: str) -> str | None:
        """è°ƒç”¨Glif APIä¸ºå¡ç‰‡æ€»ç»“ç”Ÿæˆå›¾ç‰‡"""
        logger.debug(f"[JinaSum] Calling Glif API for card summary with prompt: {prompt_text[:100]}...")
        if not self.glif_api_token:
            logger.error("[JinaSum] Glif API token is not configured.")
            return None

        headers = {
            'Authorization': f'Bearer {self.glif_api_token}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            "id": self.card_summary_glif_id,
            "inputs": [prompt_text]
        }

        for attempt in range(self.card_summary_api_retries + 1):
            try:
                logger.debug(f"[JinaSum] Attempt {attempt + 1} to call Glif API for card summary.")
                response = requests.post(
                    self.card_summary_api_url, 
                    headers=headers, 
                    json=payload, 
                    timeout=self.card_summary_api_timeout
                )
                response.raise_for_status()  # Raises an HTTPError for bad responses (4XX or 5XX)
                result = response.json()
                
                if 'error' in result:
                    logger.error(f"[JinaSum] Glif API returned an error: {result['error']}")
                    return None # Do not retry on API-level errors
                
                if 'output' not in result or not result['output']:
                    logger.error("[JinaSum] Glif API response does not contain an output URL.")
                    return None # Do not retry if response format is unexpected

                image_url = result['output']
                logger.info(f"[JinaSum] Glif API generated image URL: {image_url} on attempt {attempt + 1}")
                return image_url

            except requests.exceptions.Timeout as e:
                logger.warning(f"[JinaSum] Glif API call timed out (attempt {attempt + 1}/{self.card_summary_api_retries + 1}): {e}")
                if attempt < self.card_summary_api_retries:
                    logger.info(f"[JinaSum] Retrying in {self.card_summary_api_retry_delay} seconds...")
                    time.sleep(self.card_summary_api_retry_delay)
                else:
                    logger.error("[JinaSum] Glif API call failed after all retries due to timeout.")
                    return None
            except requests.exceptions.RequestException as e:
                logger.error(f"[JinaSum] Glif API request failed (attempt {attempt + 1}): {e}")
                return None # Do not retry on other request exceptions like DNS failure, connection refused etc.
            except json.JSONDecodeError as e:
                logger.error(f"[JinaSum] Failed to decode Glif API JSON response (attempt {attempt + 1}): {e}")
                return None # Do not retry on JSON decode errors
            except Exception as e:
                logger.error(f"[JinaSum] Unexpected error calling Glif API (attempt {attempt + 1}): {e}", exc_info=True)
                return None # Do not retry on other unexpected errors
        
        return None # Should be unreachable if logic is correct, but as a fallback

    def _process_card_summary(self, target_url: str, e_context: EventContext, chat_id: str):
        """å¤„ç†å¡ç‰‡æ€»ç»“è¯·æ±‚"""
        logger.info(f"[JinaSum] Processing card summary for URL: {target_url}, chat_id: {chat_id}")
        channel = e_context["channel"]
        reply_wip = Reply(ReplyType.TEXT, self.card_summary_wip_message)
        channel.send(reply_wip, e_context["context"])

        try:
            extracted_text = self._extract_content_general(target_url)
            if not extracted_text or len(extracted_text) < 50: # Basic check for meaningful content
                logger.warning(f"[JinaSum] Failed to extract meaningful content or content too short for card summary from {target_url}")
                reply_fail = Reply(ReplyType.TEXT, self.card_summary_fail_message)
                e_context["reply"] = reply_fail
                e_context.action = EventAction.BREAK_PASS
                return

            # The prompt for Glif should be the extracted text itself.
            # _extract_content_general already formats it as "æ ‡é¢˜: {title}\n\n{content_text}"
            prompt_for_glif = extracted_text
            
            image_url = self._call_glif_for_card(prompt_for_glif)

            if image_url:
                logger.info(f"[JinaSum] Successfully generated card image URL: {image_url} for {target_url}")
                reply_image = Reply(ReplyType.IMAGE_URL, image_url)
                e_context["reply"] = reply_image
                e_context.action = EventAction.BREAK_PASS
            else:
                logger.error(f"[JinaSum] Failed to generate card image from Glif API for {target_url}")
                reply_fail = Reply(ReplyType.TEXT, self.card_summary_fail_message)
                e_context["reply"] = reply_fail
                e_context.action = EventAction.BREAK_PASS
        
        except Exception as e:
            logger.error(f"[JinaSum] Error in _process_card_summary for {target_url}: {e}", exc_info=True)
            reply_error = Reply(ReplyType.ERROR, self.card_summary_fail_message)
            e_context["reply"] = reply_error
            e_context.action = EventAction.BREAK_PASS

    def _process_content_query(self, content: str, query: str, e_context: EventContext):
        """ç»Ÿä¸€å¤„ç†å†…å®¹æŸ¥è¯¢
        Args:
            content: æ–‡ç« å†…å®¹
            query: ç”¨æˆ·æŸ¥è¯¢(å¯ä»¥æ˜¯æ€»ç»“è¯·æ±‚æˆ–é—®é¢˜)
            e_context: äº‹ä»¶ä¸Šä¸‹æ–‡
        """
        try:
            # é™åˆ¶å†…å®¹é•¿åº¦
            content = content[:self.max_words]

            # æ„å»ºprompt
            if query:
                # ä¿®æ”¹è¿™é‡Œ,è®©è‡ªå®šä¹‰æ€»ç»“å’Œé—®ç­”ä½¿ç”¨ç›¸åŒçš„æé—®æ–¹å¼
                prompt = f"è¯·æ ¹æ®ä»¥ä¸‹å¼•å·å†…çš„æ–‡ç« å†…å®¹å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š{query}\n\n'''{content}'''"
            else:
                # ä½¿ç”¨é»˜è®¤æ€»ç»“æ¨¡æ¿
                prompt = f"{self.prompt}\n\n'''{content}'''"

            # å‡†å¤‡APIè¯·æ±‚
            openai_payload = {
                "model": self.open_ai_model,
                "messages": [{"role": "user", "content": prompt}],
            }

            # è°ƒç”¨API
            openai_chat_url = self._get_openai_chat_url()
            openai_headers = self._get_openai_headers()
            response = requests.post(
                openai_chat_url, headers=openai_headers, json=openai_payload, timeout=60
            )
            response.raise_for_status()

            # è·å–å›ç­”
            answer = response.json()["choices"][0]["message"]["content"]
            return answer

        except Exception as e:
            logger.error(f"[JinaSum] Error in processing content query: {str(e)}")
            raise