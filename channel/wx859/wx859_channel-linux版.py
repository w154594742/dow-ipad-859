import asyncio
import os
import re
import json
import time
import threading
import io
import sys
import traceback 
import xml.etree.ElementTree as ET  
import cv2
import aiohttp
import uuid 
from typing import Union, BinaryIO, Optional, Tuple, List, Dict
import urllib.parse  
import requests
from PIL import Image
from bridge.context import Context, ContextType  
from bridge.reply import Reply, ReplyType
from channel.chat_channel import ChatChannel
from channel.chat_message import ChatMessage
from channel.wx859.wx859_message import WX859Message  # æ”¹ä¸ºä»wx859_messageå¯¼å…¥WX859Message
from common.expired_dict import ExpiredDict
from common.log import logger
from common.singleton import singleton
from common.time_check import time_checker
from common.utils import remove_markdown_symbol, split_string_by_utf8_length
from config import conf, get_appdata_dir
from voice.audio_convert import split_audio # Added for voice splitting
from common.tmp_dir import TmpDir # Added for temporary file management
from plugins import PluginManager, EventContext, Event
# æ–°å¢HTTPæœåŠ¡å™¨ç›¸å…³å¯¼å…¥
from aiohttp import web
from pathlib import Path
import base64
import subprocess
import math
from pydub import AudioSegment # Added for audio duration
from io import BytesIO # Added for pydub if it operates on BytesIO
import functools

# Attempt to import pysilk
try:
    import pysilk
    PYSLIK_AVAILABLE = True
    logger.info("[WX859] pysilk library loaded successfully.")
except ImportError:
    PYSLIK_AVAILABLE = False
    logger.warning("[WX859] pysilk library not found. Voice message SILK encoding will be unavailable.")

# å¢å¤§æ—¥å¿—è¡Œé•¿åº¦é™åˆ¶ï¼Œä»¥ä¾¿å®Œæ•´æ˜¾ç¤ºXMLå†…å®¹
try:
    import logging
    # å°è¯•è®¾ç½®æ—¥å¿—æ ¼å¼åŒ–å™¨çš„æœ€å¤§é•¿åº¦é™åˆ¶
    for handler in logging.getLogger().handlers:
        if hasattr(handler, 'formatter'):
            handler.formatter._fmt = handler.formatter._fmt.replace('%(message)s', '%(message).10000s')
    logger.info("[WX859] å·²å¢å¤§æ—¥å¿—è¾“å‡ºé•¿åº¦é™åˆ¶")
except Exception as e:
    logger.warning(f"[WX859] è®¾ç½®æ—¥å¿—é•¿åº¦é™åˆ¶å¤±è´¥: {e}")

# æ·»åŠ  wx859 ç›®å½•åˆ° sys.path
current_dir = os.path.dirname(os.path.abspath(__file__))
# ä¿®æ”¹è·¯å¾„æŸ¥æ‰¾é€»è¾‘ï¼Œç¡®ä¿èƒ½æ‰¾åˆ°æ­£ç¡®çš„ lib/wx859 ç›®å½•
# å°è¯•å¤šç§å¯èƒ½çš„è·¯å¾„
possible_lib_dirs = [
    # å°è¯•ç›¸å¯¹é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
    os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(current_dir))), "lib", "wx859"),
    # å°è¯•å½“å‰ç›®å½•çš„ä¸Šä¸€çº§
    os.path.join(os.path.dirname(os.path.dirname(current_dir)), "lib", "wx859"),
    # å°è¯•å½“å‰ç›®å½•çš„ä¸Šä¸Šçº§
    os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))), "lib", "wx859"),
    # å°è¯•ç»å¯¹è·¯å¾„ï¼ˆWindowså…¼å®¹å†™æ³•ï¼‰
    os.path.join(os.path.abspath(os.sep), "root", "dow-859", "lib", "wx859")
]

# å°è¯•æ‰€æœ‰å¯èƒ½çš„è·¯å¾„
lib_dir = None
for possible_dir in possible_lib_dirs:
    if os.path.exists(possible_dir):
        lib_dir = possible_dir
        break

# æ‰“å°è·¯å¾„ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
logger.info(f"WechatAPI æ¨¡å—æœç´¢è·¯å¾„å°è¯•åˆ—è¡¨: {possible_lib_dirs}")
logger.info(f"æœ€ç»ˆé€‰æ‹©çš„WechatAPIæ¨¡å—è·¯å¾„: {lib_dir}")

if lib_dir and os.path.exists(lib_dir):
    if lib_dir not in sys.path:
        sys.path.append(lib_dir)
    # ç›´æ¥æ·»åŠ  WechatAPI ç›®å½•åˆ°è·¯å¾„
    wechat_api_dir = os.path.join(lib_dir, "WechatAPI")
    if os.path.exists(wechat_api_dir) and wechat_api_dir not in sys.path:
        sys.path.append(wechat_api_dir)
    logger.info(f"å·²æ·»åŠ  WechatAPI æ¨¡å—è·¯å¾„: {lib_dir}")
    logger.info(f"Python æœç´¢è·¯å¾„: {sys.path}")
else:
    logger.error(f"WechatAPI æ¨¡å—è·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•çš„æ‰€æœ‰è·¯å¾„å‡ä¸å¯ç”¨")

# å¯¼å…¥ WechatAPI å®¢æˆ·ç«¯
try:
    # ä½¿ç”¨ä¸åŒçš„å¯¼å…¥æ–¹å¼å°è¯•
    try:
        # å°è¯•æ–¹å¼1ï¼šç›´æ¥å¯¼å…¥
        import WechatAPI
        from WechatAPI import WechatAPIClient
        logger.info("æˆåŠŸå¯¼å…¥ WechatAPI æ¨¡å—ï¼ˆæ–¹å¼1ï¼‰")
    except ImportError:
        try:
            # å°è¯•æ–¹å¼2ï¼šä»ç›¸å¯¹è·¯å¾„å¯¼å…¥
            sys.path.append(os.path.dirname(lib_dir))
            from wx859.WechatAPI import WechatAPIClient
            import wx859.WechatAPI as WechatAPI
            logger.info("æˆåŠŸå¯¼å…¥ WechatAPI æ¨¡å—ï¼ˆæ–¹å¼2ï¼‰")
        except ImportError:
            # å°è¯•æ–¹å¼3ï¼šWindowsç‰¹æ®Šå¤„ç†
            if os.name == 'nt':  # Windowsç³»ç»Ÿ
                # åˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„åº“è·¯å¾„
                for path in sys.path:
                    if 'wx859' in path:
                        logger.info(f"åœ¨è·¯å¾„ä¸­æŸ¥æ‰¾wx859: {path}")
                        if os.path.exists(path):
                            subdirs = os.listdir(path)
                            logger.info(f"ç›®å½• {path} ä¸‹çš„å†…å®¹: {subdirs}")
                
                # å°è¯•ç›´æ¥å°†wx859ç›®å½•åŠ å…¥sys.path
                parent_dir = os.path.dirname(current_dir) # channelç›®å½•
                project_dir = os.path.dirname(parent_dir) # é¡¹ç›®æ ¹ç›®å½•
                wx859_lib_dir = os.path.join(project_dir, "lib", "wx859")
                
                if os.path.exists(wx859_lib_dir):
                    if wx859_lib_dir not in sys.path:
                        sys.path.append(wx859_lib_dir)
                    
                    # å°è¯•å¯¼å…¥
                    import WechatAPI
                    from WechatAPI import WechatAPIClient
                    logger.info("æˆåŠŸå¯¼å…¥ WechatAPI æ¨¡å—ï¼ˆWindowsç‰¹æ®Šå¤„ç†ï¼‰")
                else:
                    raise ImportError(f"åœ¨Windowsç³»ç»Ÿä¸Šæ‰¾ä¸åˆ°wx859åº“: {wx859_lib_dir}")
            else:
                raise
    
    # è®¾ç½® WechatAPI çš„ loguru æ—¥å¿—çº§åˆ«ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
    try:
        from loguru import logger as api_logger
        import logging
        
        # ç§»é™¤æ‰€æœ‰ç°æœ‰å¤„ç†å™¨
        api_logger.remove()
        
        # è·å–é…ç½®çš„æ—¥å¿—çº§åˆ«ï¼Œé»˜è®¤ä¸º ERROR ä»¥å‡å°‘è¾“å‡º
        log_level = conf().get("log_level", "ERROR")
        
        # æ·»åŠ æ–°çš„å¤„ç†å™¨ï¼Œä»…è¾“å‡º ERROR çº§åˆ«ä»¥ä¸Šçš„æ—¥å¿—
        api_logger.add(sys.stderr, level=log_level)
        logger.info(f"å·²è®¾ç½® WechatAPI æ—¥å¿—çº§åˆ«ä¸º: {log_level}")
    except Exception as e:
        logger.error(f"è®¾ç½® WechatAPI æ—¥å¿—çº§åˆ«æ—¶å‡ºé”™: {e}")
except Exception as e:
    logger.error(f"å¯¼å…¥ WechatAPI æ¨¡å—å¤±è´¥: {e}")
    # æ‰“å°æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
    logger.error(f"å½“å‰Pythonè·¯å¾„: {sys.path}")
    
    # æ£€æŸ¥ç›®å½•å†…å®¹
    if lib_dir and os.path.exists(lib_dir):
        logger.info(f"lib_dir ç›®å½•å†…å®¹: {os.listdir(lib_dir)}")
        wechat_api_dir = os.path.join(lib_dir, "WechatAPI")
        if os.path.exists(wechat_api_dir):
            logger.info(f"WechatAPI ç›®å½•å†…å®¹: {os.listdir(wechat_api_dir)}")
    
    # æ‰“å°å †æ ˆä¿¡æ¯
    import traceback
    logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
    
    raise ImportError(f"æ— æ³•å¯¼å…¥ WechatAPI æ¨¡å—ï¼Œè¯·ç¡®ä¿ wx859 ç›®å½•å·²æ­£ç¡®é…ç½®: {e}")

# æ·»åŠ  ContextType.PAT ç±»å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if not hasattr(ContextType, 'PAT'):
    setattr(ContextType, 'PAT', 'PAT')
if not hasattr(ContextType, 'QUOTE'):
    setattr(ContextType, 'QUOTE', 'QUOTE')
# æ·»åŠ  ContextType.UNKNOWN ç±»å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if not hasattr(ContextType, 'UNKNOWN'):
    setattr(ContextType, 'UNKNOWN', 'UNKNOWN')
# æ·»åŠ  ContextType.XML ç±»å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
if not hasattr(ContextType, 'XML'):
    setattr(ContextType, 'XML', 'XML')
    logger.info("[WX859] å·²æ·»åŠ  ContextType.XML ç±»å‹")
# æ·»åŠ å…¶ä»–å¯èƒ½ä½¿ç”¨çš„ContextTypeç±»å‹
if not hasattr(ContextType, 'LINK'):
    setattr(ContextType, 'LINK', 'LINK')
    logger.info("[WX859] å·²æ·»åŠ  ContextType.LINK ç±»å‹")
if not hasattr(ContextType, 'FILE'):
    setattr(ContextType, 'FILE', 'FILE')
    logger.info("[WX859] å·²æ·»åŠ  ContextType.FILE ç±»å‹")
if not hasattr(ContextType, 'MINIAPP'):
    setattr(ContextType, 'MINIAPP', 'MINIAPP')
    logger.info("[WX859] å·²æ·»åŠ  ContextType.MINIAPP ç±»å‹")
if not hasattr(ContextType, 'SYSTEM'):
    setattr(ContextType, 'SYSTEM', 'SYSTEM')
    logger.info("[WX859] å·²æ·»åŠ  ContextType.SYSTEM ç±»å‹")
if not hasattr(ContextType, 'VIDEO'):
    setattr(ContextType, 'VIDEO', 'VIDEO')
    logger.info("[WX859] å·²æ·»åŠ  ContextType.VIDEO ç±»å‹")

# å¯¼å…¥cv2ï¼ˆOpenCVï¼‰ç”¨äºå¤„ç†è§†é¢‘
try:
    import cv2
    logger.info("[WX859] æˆåŠŸå¯¼å…¥OpenCV(cv2)æ¨¡å—")
except ImportError:
    logger.warning("[WX859] æœªå®‰è£…OpenCV(cv2)æ¨¡å—ï¼Œè§†é¢‘å¤„ç†åŠŸèƒ½å°†å—é™")
    cv2 = None

def _find_ffmpeg_path():
    """Finds the ffmpeg executable path."""
    ffmpeg_cmd = "ffmpeg" # Default command
    if os.name == 'nt': # Windows
        possible_paths = [
            r"C:\ffmpeg\bin\ffmpeg.exe",
            r"C:\Program Files\ffmpeg\bin\ffmpeg.exe",
            r"C:\Program Files (x86)\ffmpeg\bin\ffmpeg.exe",
            * [os.path.join(p, "ffmpeg.exe") for p in os.environ.get("PATH", "").split(os.pathsep) if p]
        ]
        for path in possible_paths:
            if os.path.exists(path):
                ffmpeg_cmd = path
                logger.debug(f"[WX859] Found ffmpeg at: {ffmpeg_cmd}")
                return ffmpeg_cmd
        logger.warning("[WX859] ffmpeg not found in common Windows paths or PATH, will try system PATH with 'ffmpeg'.")
        return "ffmpeg"
    else: # Linux/macOS
        import shutil
        ffmpeg_path = shutil.which("ffmpeg")
        if ffmpeg_path:
            logger.debug(f"[WX859] Found ffmpeg at: {ffmpeg_path}")
            return ffmpeg_path
        else:
            logger.warning("[WX859] ffmpeg not found using shutil.which. Will try system PATH with 'ffmpeg'.")
            return "ffmpeg"

def _check(func):
    if asyncio.iscoroutinefunction(func):
        @functools.wraps(func)
        async def wrapper(self, cmsg: ChatMessage):
            msgId = cmsg.msg_id
            if not msgId:
                msgId = f"msg_{int(time.time())}_{hash(str(cmsg.msg))}"
                logger.debug(f"[WX859] _check: ä¸ºç©ºæ¶ˆæ¯IDç”Ÿæˆå”¯ä¸€ID: {msgId}")
            
            if msgId in self.received_msgs:
                logger.debug(f"[WX859] æ¶ˆæ¯ {msgId} å·²å¤„ç†è¿‡ï¼Œå¿½ç•¥")
                return
            
            self.received_msgs[msgId] = True
            
            create_time = cmsg.create_time
            current_time = int(time.time())
            timeout = 60
            if int(create_time) < current_time - timeout:
                logger.debug(f"[WX859] å†å²æ¶ˆæ¯ {msgId} å·²è·³è¿‡ï¼Œæ—¶é—´å·®: {current_time - int(create_time)}ç§’")
                return
            return await func(self, cmsg)
        return wrapper
    else:
        @functools.wraps(func)
        def wrapper(self, cmsg: ChatMessage):
            msgId = cmsg.msg_id
            if not msgId:
                msgId = f"msg_{int(time.time())}_{hash(str(cmsg.msg))}"
                logger.debug(f"[WX859] _check: ä¸ºç©ºæ¶ˆæ¯IDç”Ÿæˆå”¯ä¸€ID: {msgId}")

            if msgId in self.received_msgs:
                logger.debug(f"[WX859] æ¶ˆæ¯ {msgId} å·²å¤„ç†è¿‡ï¼Œå¿½ç•¥")
                return

            self.received_msgs[msgId] = True

            create_time = cmsg.create_time
            current_time = int(time.time())
            timeout = 60
            if int(create_time) < current_time - timeout:
                logger.debug(f"[WX859] å†å²æ¶ˆæ¯ {msgId} å·²è·³è¿‡ï¼Œæ—¶é—´å·®: {current_time - int(create_time)}ç§’")
                return
            return func(self, cmsg)
        return wrapper

@singleton
class WX859Channel(ChatChannel):
    """
    wx859 channel - ç‹¬ç«‹é€šé“å®ç°
    """
    NOT_SUPPORT_REPLYTYPE = []

    def __init__(self):
        super().__init__()
        self.received_msgs = ExpiredDict(conf().get("expires_in_seconds", 3600))
        self.recent_image_msgs = ExpiredDict(conf().get("image_expires_in_seconds", 7200)) # Added initialization
        self.bot = None
        self.user_id = None
        self.name = None
        self.wxid = None
        self.is_running = False
        self.is_logged_in = False
        self.group_name_cache = {}
        self.image_cache_dir = os.path.join(os.getcwd(), "tmp", "wx859_img_cache")
        
        # ğŸ”¥ æ–°å¢ï¼šä¸‹è½½é”æœºåˆ¶ï¼Œé˜²æ­¢é‡å¤ä¸‹è½½
        self._download_locks = {}  # ä¸‹è½½é”å­—å…¸ {attach_id: asyncio.Future}
        self._download_cache_check_enabled = True  # å¯ç”¨ç¼“å­˜æ£€æŸ¥
        
        # åˆå§‹åŒ–æ¶ˆæ¯è¿‡æ»¤è®¾ç½®
        self.single_ignore_blacklist = conf().get("single_ignore_blacklist", [])
        
        # è®°å½•è¿‡æ»¤é…ç½®ä¿¡æ¯
        if self.single_ignore_blacklist:
            logger.info(f"[WX859] ä¸ªäººé»‘åå•: {self.single_ignore_blacklist}")
        
        try:
            if not os.path.exists(self.image_cache_dir):
                os.makedirs(self.image_cache_dir, exist_ok=True)
                logger.info(f"[{self.name}] Created image cache directory: {self.image_cache_dir}")
        except Exception as e:
            logger.error(f"[{self.name}] Failed to create image cache directory {self.image_cache_dir}: {e}")
        
        # åˆå§‹åŒ–æ–‡ä»¶ç¼“å­˜ç›®å½•
        self.file_cache_dir = os.path.join(os.getcwd(), "tmp", "wx859_file_cache")
        try:
            if not os.path.exists(self.file_cache_dir):
                os.makedirs(self.file_cache_dir, exist_ok=True)
                logger.info(f"[{self.name}] Created file cache directory: {self.file_cache_dir}")
        except Exception as e:
            logger.error(f"[{self.name}] Failed to create file cache directory {self.file_cache_dir}: {e}")

    def _cleanup_cached_images(self):
        """Cleans up expired image files from the cache directory."""
        import glob
        if not hasattr(self, 'image_cache_dir') or not self.image_cache_dir:
            logger.warning(f"[{self.name}] Image cache directory not configured. Skipping cleanup.")
            return
        
        logger.info(f"[{self.name}] Starting image cache cleanup in {self.image_cache_dir}...")
        try:
            current_time = time.time()
            max_age_seconds = 7 * 24 * 60 * 60  # Cache images for 7 days

            # Iterate over common image extensions used for caching
            # Ensure this matches extensions used during caching (see phase A3)
            for ext_pattern in ['*.jpg', '*.jpeg', '*.png', '*.gif']: 
                pattern = os.path.join(self.image_cache_dir, ext_pattern)
                cleaned_count = 0
                total_size_cleaned = 0

                for fpath in glob.glob(pattern):
                    try:
                        if os.path.isfile(fpath): # Ensure it's a file
                            mtime = os.path.getmtime(fpath)
                            if current_time - mtime > max_age_seconds:
                                file_size = os.path.getsize(fpath)
                                os.remove(fpath)
                                cleaned_count += 1
                                total_size_cleaned += file_size
                                logger.debug(f"[{self.name}] Cleaned up expired cached image: {fpath} (Age: {(current_time - mtime)/3600/24:.1f} days)")
                    except Exception as e:
                        logger.warning(f"[{self.name}] Failed to process/delete cached image {fpath}: {e}")
                
                if cleaned_count > 0:
                    logger.info(f"[{self.name}] Cleaned up {cleaned_count} '{ext_pattern}' images, freed {total_size_cleaned/1024/1024:.2f} MB.")
            logger.info(f"[{self.name}] Image cache cleanup finished.")
        except Exception as e:
            logger.error(f"[{self.name}] Image cache cleanup task encountered an error: {e}")

    def _start_image_cache_cleanup_task(self):
        """Starts the periodic image cache cleanup task."""
        if not hasattr(self, 'image_cache_dir'): # Don't start if cache isn't configured
            return

        def _cleanup_loop():
            logger.info(f"[{self.name}] Image cache cleanup thread started.")
            # Initial delay before first cleanup, e.g., 5 minutes after startup
            time.sleep(5 * 60) 
            while True:
                try:
                    self._cleanup_cached_images()
                    # Sleep for a longer interval, e.g., 6 hours or 24 hours
                    cleanup_interval_hours = 24 
                    logger.debug(f"[{self.name}] Image cache cleanup task sleeping for {cleanup_interval_hours} hours.")
                    time.sleep(cleanup_interval_hours * 60 * 60)
                except Exception as e:
                    logger.error(f"[{self.name}] Image cache cleanup loop error: {e}. Retrying in 1 hour.")
                    time.sleep(60 * 60) # Wait an hour before retrying the loop on major error

        cleanup_thread = threading.Thread(target=_cleanup_loop, daemon=True)
        cleanup_thread.name = "WX859ImageCacheCleanupThread"
        cleanup_thread.start()
        logger.info(f"[{self.name}] Image cache cleanup task scheduled.")
        
    def _start_file_cache_cleanup_task(self):
        """å¯åŠ¨æ–‡ä»¶ç¼“å­˜å®šæœŸæ¸…ç†ä»»åŠ¡"""
        if not hasattr(self, 'file_cache_dir') or not self.file_cache_dir:
            logger.debug(f"[{self.name}] æ–‡ä»¶ç¼“å­˜ç›®å½•æœªé…ç½®ï¼Œè·³è¿‡å¯åŠ¨æ¸…ç†ä»»åŠ¡")
            return

        def _file_cleanup_loop():
            logger.info(f"[{self.name}] æ–‡ä»¶ç¼“å­˜æ¸…ç†çº¿ç¨‹å·²å¯åŠ¨")
            # å¯åŠ¨åç­‰å¾…10åˆ†é’Ÿå†å¼€å§‹ç¬¬ä¸€æ¬¡æ¸…ç†
            time.sleep(10 * 60) 
            while True:
                try:
                    # ä½¿ç”¨asyncio.runæ¥è¿è¡Œå¼‚æ­¥æ–¹æ³•
                    asyncio.run(self._cleanup_file_cache())
                    
                    # æ¯12å°æ—¶æ¸…ç†ä¸€æ¬¡æ–‡ä»¶ç¼“å­˜
                    cleanup_interval_hours = 12
                    logger.debug(f"[{self.name}] æ–‡ä»¶ç¼“å­˜æ¸…ç†ä»»åŠ¡ä¼‘çœ  {cleanup_interval_hours} å°æ—¶")
                    time.sleep(cleanup_interval_hours * 60 * 60)
                except Exception as e:
                    logger.error(f"[{self.name}] æ–‡ä»¶ç¼“å­˜æ¸…ç†å¾ªç¯å‡ºé”™: {e}. 1å°æ—¶åé‡è¯•")
                    time.sleep(60 * 60)  # å‡ºé”™åç­‰å¾…1å°æ—¶é‡è¯•

        file_cleanup_thread = threading.Thread(target=_file_cleanup_loop, daemon=True)
        file_cleanup_thread.name = "WX859FileCacheCleanupThread"
        file_cleanup_thread.start()
        logger.info(f"[{self.name}] æ–‡ä»¶ç¼“å­˜æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨")

    def show_cache_status(self):
        """æ˜¾ç¤ºç¼“å­˜çŠ¶æ€ç»Ÿè®¡ä¿¡æ¯ - é›†æˆcache_monitorçš„æŸ¥çœ‹åŠŸèƒ½"""
        try:
            file_cache_dir = os.path.join(os.getcwd(), "tmp", "wx859_file_cache")
            mapping_file = os.path.join(file_cache_dir, "file_mapping.json")
            
            logger.info("=" * 60)
            logger.info("ğŸ” æ–‡ä»¶ä¸‹è½½ç¼“å­˜çŠ¶æ€ç›‘æ§")
            logger.info("=" * 60)
            
            # æ£€æŸ¥ç¼“å­˜ç›®å½•
            if not os.path.exists(file_cache_dir):
                logger.info("âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
                return
            
            logger.info(f"ğŸ“ ç¼“å­˜ç›®å½•: {file_cache_dir}")
            
            # æ£€æŸ¥æ˜ å°„æ–‡ä»¶
            if not os.path.exists(mapping_file):
                logger.info("âŒ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¯èƒ½è¿˜æ²¡æœ‰ç¼“å­˜ä»»ä½•æ–‡ä»¶")
                return
            
            with open(mapping_file, 'r', encoding='utf-8') as f:
                mapping = json.load(f)
            
            if not mapping:
                logger.info("ğŸ“‹ ç¼“å­˜æ˜ å°„ä¸ºç©º")
                return
            
            logger.info(f"ğŸ“Š ç¼“å­˜æ–‡ä»¶æ€»æ•°: {len(mapping)}")
            logger.info("-" * 60)
            
            total_size = 0
            valid_files = 0
            invalid_files = 0
            
            for attach_id, info in mapping.items():
                cached_filename = info.get("cached_filename", "unknown")
                original_filename = info.get("original_filename", "unknown")
                file_size = info.get("file_size", 0)
                cached_time = info.get("cached_time", 0)
                msg_id = info.get("msg_id", "unknown")
                from_user = info.get("from_user_id", "unknown")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                file_path = os.path.join(file_cache_dir, cached_filename)
                file_exists = os.path.exists(file_path)
                actual_size = os.path.getsize(file_path) if file_exists else 0
                
                status = "âœ…" if file_exists and actual_size > 0 else "âŒ"
                
                if file_exists and actual_size > 0:
                    valid_files += 1
                    total_size += actual_size
                else:
                    invalid_files += 1
                
                # è®¡ç®—æ—¶é—´è·ç¦»
                now = time.time()
                time_ago = int(now - cached_time)
                if time_ago < 60:
                    time_str = f"{time_ago}ç§’å‰"
                elif time_ago < 3600:
                    time_str = f"{time_ago // 60}åˆ†é’Ÿå‰"
                elif time_ago < 86400:
                    time_str = f"{time_ago // 3600}å°æ—¶å‰"
                else:
                    time_str = f"{time_ago // 86400}å¤©å‰"
                
                logger.info(f"{status} {original_filename}")
                logger.info(f"   ğŸ“ attach_id: {attach_id[:20]}...")
                logger.info(f"   ğŸ’¾ ç¼“å­˜æ–‡ä»¶: {cached_filename}")
                logger.info(f"   ğŸ“ æ–‡ä»¶å¤§å°: {self._format_file_size(actual_size)}")
                logger.info(f"   â° ç¼“å­˜æ—¶é—´: {time_str}")
                logger.info(f"   ğŸ‘¤ æ¥æºç”¨æˆ·: {from_user}")
                logger.info(f"   ğŸ“¨ æ¶ˆæ¯ID: {msg_id}")
                logger.info()
            
            logger.info("-" * 60)
            logger.info(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯:")
            logger.info(f"   âœ… æœ‰æ•ˆæ–‡ä»¶: {valid_files}")
            logger.info(f"   âŒ æ— æ•ˆæ–‡ä»¶: {invalid_files}")
            logger.info(f"   ğŸ’¾ æ€»ç¼“å­˜å¤§å°: {self._format_file_size(total_size)}")
            
            # è®¡ç®—ç¼“å­˜æœ‰æ•ˆç‡
            if valid_files + invalid_files > 0:
                hit_rate = (valid_files / (valid_files + invalid_files)) * 100
                logger.info(f"   ğŸ“Š ç¼“å­˜æœ‰æ•ˆç‡: {hit_rate:.1f}%")
            
            logger.info("=" * 60)
            
        except Exception as e:
            logger.error(f"[{self.name}] æ˜¾ç¤ºç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
            import traceback
            logger.error(f"[{self.name}] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    async def manual_cleanup_file_cache(self, hours=24):
        """æ‰‹åŠ¨æ¸…ç†è¿‡æœŸç¼“å­˜ - æä¾›ç»™å¤–éƒ¨è°ƒç”¨çš„æ¥å£"""
        logger.info(f"[{self.name}] å¼€å§‹æ‰‹åŠ¨æ¸…ç†è¶…è¿‡ {hours} å°æ—¶çš„æ–‡ä»¶ç¼“å­˜...")
        
        # ä¸´æ—¶ä¿®æ”¹æ¸…ç†æ—¶é—´
        original_max_age = 24 * 60 * 60
        temp_max_age = hours * 60 * 60
        
        # è°ƒç”¨æ¸…ç†æ–¹æ³•
        await self._cleanup_file_cache()
        
        logger.info(f"[{self.name}] æ‰‹åŠ¨æ¸…ç†å®Œæˆ")

    async def _initialize_bot(self):
        """åˆå§‹åŒ– bot"""
        logger.info("[WX859] æ­£åœ¨åˆå§‹åŒ– bot...")
        
        # å›ºå®šä½¿ç”¨859åè®®
        logger.info("ä½¿ç”¨åè®®ç‰ˆæœ¬: 859")
        
        api_host = conf().get("wx859_api_host", "127.0.0.1")
        api_port = conf().get("wx859_api_port", 8059)
        
        # 859åè®®æ ¹æ®swagger.jsonå®šä¹‰ï¼Œä½¿ç”¨/apiå‰ç¼€
        api_path_prefix = "/api"
        logger.info(f"ä½¿ç”¨APIè·¯å¾„å‰ç¼€: {api_path_prefix} (é€‚ç”¨äº859åè®®)")
        
        # åˆå§‹åŒ–WechatAPIå®¢æˆ·ç«¯
        try:
            # ä½¿ç”¨859åè®®å®¢æˆ·ç«¯
            self.bot = WechatAPI.WechatAPIClient(api_host, api_port)
            logger.info("ä½¿ç”¨859åè®®å®¢æˆ·ç«¯")
            
            # è®¾ç½®APIè·¯å¾„å‰ç¼€ - ç¡®ä¿æ­£ç¡®è®¾ç½®
            self.bot.set_api_path_prefix(api_path_prefix)
            logger.info(f"[WX859] å·²è®¾ç½®APIè·¯å¾„å‰ç¼€: {api_path_prefix}")
            
            # éªŒè¯APIè·¯å¾„å‰ç¼€è®¾ç½®
            if hasattr(self.bot, "api_path_prefix"):
                logger.info(f"[WX859] éªŒè¯APIè·¯å¾„å‰ç¼€: {self.bot.api_path_prefix}")
            else:
                logger.warning("[WX859] botå¯¹è±¡æ²¡æœ‰api_path_prefixå±æ€§")
                
            # è®¾ç½®botçš„ignore_protectionå±æ€§ä¸ºTrueï¼Œå¼ºåˆ¶å¿½ç•¥æ‰€æœ‰é£æ§ä¿æŠ¤
            if hasattr(self.bot, "ignore_protection"):
                self.bot.ignore_protection = True
                logger.info("[WX859] å·²è®¾ç½®å¿½ç•¥é£æ§ä¿æŠ¤")
        except Exception as e:
            logger.error(f"[WX859] åˆå§‹åŒ–WechatAPIå®¢æˆ·ç«¯å¤±è´¥: {e}")
            return False
        
        # ç­‰å¾… WechatAPI æœåŠ¡å¯åŠ¨
        service_ok = await self._check_api_service(api_host, api_port, api_path_prefix)
        if not service_ok:
            logger.error("[WX859] WechatAPI æœåŠ¡è¿æ¥å¤±è´¥")
            return False
        
        # æ£€æŸ¥å¹¶è¯»å–ä¿å­˜çš„è®¾å¤‡ä¿¡æ¯å’Œç™»å½•ä¿¡æ¯
        device_info_path = os.path.join(get_appdata_dir(), "wx859_device_info.json")
        
        # é»˜è®¤è®¾å¤‡ä¿¡æ¯
        saved_wxid = ""
        saved_device_id = ""
        saved_device_name = "9527's Pad"
        
        # è¯»å–å·²ä¿å­˜çš„è®¾å¤‡ä¿¡æ¯
        if os.path.exists(device_info_path):
            try:
                with open(device_info_path, "r", encoding="utf-8") as f:
                    device_info = json.load(f)
                    saved_wxid = device_info.get("wxid", "")
                    saved_device_id = device_info.get("device_id", "")
                    saved_device_name = device_info.get("device_name", "9527's Pad")
                    
                    logger.info(f"[WX859] å·²è¯»å–ä¿å­˜çš„è®¾å¤‡ä¿¡æ¯: wxid={saved_wxid}, device_id={saved_device_id}")
            except Exception as e:
                logger.error(f"[WX859] è¯»å–è®¾å¤‡ä¿¡æ¯æ–‡ä»¶å¤±è´¥: {e}")
        
        # ğŸ”¥ æ£€æŸ¥å¹¶è‡ªåŠ¨ç”Ÿæˆç¼ºå¤±çš„è®¾å¤‡ä¿¡æ¯
        device_info_updated = False
        
        # æ£€æŸ¥è®¾å¤‡åç§°
        if not saved_device_name or saved_device_name == "9527's Pad":
            # é¦–å…ˆæ£€æŸ¥login.pyä¸­æ˜¯å¦æœ‰create_device_nameæ–¹æ³•
            try:
                from lib.wx859.WechatAPI.Client.login import LoginMixin
                if hasattr(LoginMixin, 'create_device_name'):
                    saved_device_name = LoginMixin.create_device_name()
                    logger.info(f"[WX859] è‡ªåŠ¨ç”Ÿæˆè®¾å¤‡åç§°: {saved_device_name}")
                    device_info_updated = True
                else:
                    logger.debug("[WX859] LoginMixinä¸­æœªæ‰¾åˆ°create_device_nameæ–¹æ³•")
            except Exception as e:
                logger.debug(f"[WX859] å¯¼å…¥LoginMixinå¤±è´¥: {e}")
        
        # æ£€æŸ¥è®¾å¤‡ID
        if not saved_device_id:
            # é¦–å…ˆæ£€æŸ¥login.pyä¸­æ˜¯å¦æœ‰create_device_idæ–¹æ³•
            try:
                from lib.wx859.WechatAPI.Client.login import LoginMixin
                if hasattr(LoginMixin, 'create_device_id'):
                    saved_device_id = LoginMixin.create_device_id()
                    logger.info(f"[WX859] è‡ªåŠ¨ç”Ÿæˆè®¾å¤‡ID: {saved_device_id}")
                    device_info_updated = True
                else:
                    logger.debug("[WX859] LoginMixinä¸­æœªæ‰¾åˆ°create_device_idæ–¹æ³•")
            except Exception as e:
                logger.debug(f"[WX859] å¯¼å…¥LoginMixinå¤±è´¥: {e}")
        
        # å¦‚æœè®¾å¤‡ä¿¡æ¯æœ‰æ›´æ–°ï¼Œä¿å­˜åˆ°æ–‡ä»¶
        if device_info_updated and saved_wxid:
            try:
                updated_device_info = {
                    "wxid": saved_wxid,
                    "device_id": saved_device_id,
                    "device_name": saved_device_name
                }
                os.makedirs(os.path.dirname(device_info_path), exist_ok=True)
                with open(device_info_path, "w", encoding="utf-8") as f:
                    json.dump(updated_device_info, f, indent=2)
                logger.info(f"[WX859] å·²æ›´æ–°è®¾å¤‡ä¿¡æ¯æ–‡ä»¶: device_name={saved_device_name}, device_id={saved_device_id}")
            except Exception as e:
                logger.error(f"[WX859] ä¿å­˜æ›´æ–°çš„è®¾å¤‡ä¿¡æ¯å¤±è´¥: {e}")
        
        # ä»é…ç½®ä¸­è¯»å–æ˜¯å¦å¯ç”¨è‡ªåŠ¨ç™»å½•
        # åŸæ¥çš„ä»£ç ä¼šå°è¯•è¯»å–wx859_auto_loginé…ç½®é¡¹ï¼Œç°åœ¨ç›´æ¥ä½¿ç”¨True
        # auto_login_enabled = conf().get("wx859_auto_login", True)
        auto_login_enabled = True  # é»˜è®¤å¯ç”¨è‡ªåŠ¨ç™»å½•
        
        # å°è¯•è‡ªåŠ¨ç™»å½•
        if auto_login_enabled and saved_wxid:
            auto_login_success = await self._auto_login(saved_wxid, saved_device_id, saved_device_name)
            if auto_login_success:
                return True
        
        # è‡ªåŠ¨ç™»å½•å¤±è´¥æˆ–æœªå¯ç”¨ï¼Œè¿›è¡Œæ‰«ç ç™»å½•
        logger.info("[WX859] è‡ªåŠ¨ç™»å½•å¤±è´¥æˆ–æœªå¯ç”¨ï¼Œä½¿ç”¨æ‰«ç ç™»å½•")
        
        # ç”Ÿæˆdevice_nameå’Œdevice_id
        device_name = saved_device_name or "9527's Pad"
        device_id = saved_device_id or ""
        
        if hasattr(self.bot, "create_device_name") and not device_name:
            device_name = self.bot.create_device_name()
            
        if hasattr(self.bot, "create_device_id") and not device_id:
            device_id = self.bot.create_device_id()
        
        # è·å–ç™»å½•äºŒç»´ç 
        logger.info("[WX859] å¼€å§‹è·å–ç™»å½•äºŒç»´ç ")
        try:
            # ä¿®æ”¹è°ƒç”¨æ–¹å¼ï¼Œä½¿ç”¨å°å†™å‚æ•°
            uuid, url = await self.bot.get_qr_code(device_name=device_name, device_id=device_id, print_qr=True)
            logger.info(f"[WX859] è·å–åˆ°ç™»å½•uuid: {uuid}")
            logger.info(f"[WX859] è·å–åˆ°ç™»å½•äºŒç»´ç : {url}")
        except Exception as e:
            logger.error(f"[WX859] è·å–ç™»å½•äºŒç»´ç å¤±è´¥: {e}")
            return False
        
        # ç­‰å¾…æ‰«ç å¹¶ç™»å½•
        login_success, new_wxid = await self._wait_for_qr_login(uuid, device_id, device_name, device_info_path)
        return login_success

    async def _check_api_service(self, api_host, api_port, api_path_prefix):
        """æ£€æŸ¥APIæœåŠ¡æ˜¯å¦å¯ç”¨"""
        logger.info(f"å°è¯•è¿æ¥åˆ° WechatAPI æœåŠ¡ (åœ°å€: {api_host}:{api_port}{api_path_prefix})")
        
        time_out = 30
        is_connected = False
        
        while not is_connected and time_out > 0:
            try:
                # å°è¯•ä½¿ç”¨botå¯¹è±¡çš„is_runningæ–¹æ³•
                if hasattr(self.bot, "is_running") and await self.bot.is_running():
                    is_connected = True
                    logger.info("[WX859] APIæœåŠ¡å·²é€šè¿‡is_runningæ–¹æ³•ç¡®è®¤å¯ç”¨")
                    break
                
                # å¦‚æœbotå¯¹è±¡çš„æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ç›´æ¥å‘é€HTTPè¯·æ±‚æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯ç”¨
                import aiohttp
                async with aiohttp.ClientSession() as session:
                    try:
                        # å°è¯•è®¿é—®ç™»å½•æ¥å£ï¼Œç¡®ä¿URLæ ¼å¼æ­£ç¡®
                        url = f"http://{api_host}:{api_port}{api_path_prefix}/Login/LoginGetQR"
                        logger.debug(f"å°è¯•è¿æ¥: {url}")
                        async with session.get(url, timeout=5) as response:
                            if response.status in [200, 401, 403, 404]:  # ä»»ä½•HTTPå“åº”éƒ½è¡¨ç¤ºæœåŠ¡åœ¨è¿è¡Œ
                                is_connected = True
                                logger.info("[WX859] é€šè¿‡HTTPè¯·æ±‚ç¡®è®¤æœåŠ¡å¯ç”¨")
                                break
                    except Exception as e:
                        logger.debug(f"APIè·¯å¾„è¯·æ±‚å¤±è´¥: {e}")
                        
                        # å¦‚æœç‰¹å®šè·¯å¾„å¤±è´¥ï¼Œå°è¯•è®¿é—®æ ¹è·¯å¾„
                        url = f"http://{api_host}:{api_port}/"
                        logger.debug(f"å°è¯•è¿æ¥æ ¹è·¯å¾„: {url}")
                        try:
                            async with session.get(url, timeout=5) as response:
                                if response.status in [200, 401, 403, 404]:
                                    is_connected = True
                                    logger.info("[WX859] é€šè¿‡æ ¹è·¯å¾„ç¡®è®¤æœåŠ¡å¯ç”¨")
                                    break
                        except Exception as e2:
                            logger.debug(f"æ ¹è·¯å¾„è¯·æ±‚ä¹Ÿå¤±è´¥: {e2}")
            except Exception as e:
                logger.debug(f"è¿æ¥å°è¯•å¤±è´¥: {e}")
            
            logger.info("ç­‰å¾… WechatAPI å¯åŠ¨ä¸­")
            await asyncio.sleep(2)
            time_out -= 2
        
        return is_connected

    async def _wait_for_qr_login(self, uuid, device_id, device_name, device_info_path):
        """ç­‰å¾…æ‰«ç ç™»å½•å®Œæˆ"""
        login_timeout = 120
        
        while login_timeout > 0:
            try:
                # æ£€æŸ¥ç™»å½•çŠ¶æ€ - ä¿®æ”¹å‚æ•°ä¸ºå°å†™
                login_success, login_result = await self.bot.check_login_uuid(uuid, device_id=device_id)
                
                if login_success:
                    logger.info("[WX859] æ‰«ç ç™»å½•æˆåŠŸï¼Œå·²è·å–ç™»å½•ä¿¡æ¯")
                    
                    # ğŸ”¥ æ·»åŠ å®Œæ•´çš„ç™»å½•ç»“æœè°ƒè¯•æ—¥å¿—
                    logger.info(f"[WX859] ç™»å½•ç»“æœè¯¦æƒ…: {json.dumps(login_result, ensure_ascii=False, indent=2)}")
                    
                    # æå–å¾®ä¿¡IDå’Œæ˜µç§°
                    new_wxid = ""
                    new_name = ""
                    
                    # æå–ä¸åŒåè®®ç‰ˆæœ¬è¿”å›çš„ç”¨æˆ·ä¿¡æ¯
                    if isinstance(login_result, dict):
                        # ğŸ”¥ æ”¹è¿›çš„é€’å½’æœç´¢å‡½æ•°
                        def find_wxid_in_nested_dict(obj, depth=0):
                            """é€’å½’æŸ¥æ‰¾å¯èƒ½çš„wxidå­—æ®µ"""
                            if depth > 10:  # é˜²æ­¢æ— é™é€’å½’
                                return None
                            
                            if isinstance(obj, dict):
                                # ç›´æ¥æ£€æŸ¥å¸¸è§çš„wxidå­—æ®µ
                                wxid_fields = ["Wxid", "wxid", "UserName", "userName", "WxId", "userid", "UserId"]
                                for field in wxid_fields:
                                    if field in obj and obj[field]:
                                        candidate = obj[field]
                                        # å¤„ç†åµŒå¥—çš„stringç»“æ„
                                        if isinstance(candidate, dict) and "string" in candidate:
                                            candidate = candidate["string"]
                                        # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„wxidï¼ˆä¸æ˜¯ä¸´æ—¶IDï¼Œä¸”é•¿åº¦åˆç†ï¼‰
                                        if isinstance(candidate, str) and candidate and not candidate.startswith("temp_") and len(candidate) > 5:
                                            logger.debug(f"[WX859] åœ¨å­—æ®µ {field} ä¸­æ‰¾åˆ°å€™é€‰wxid: {candidate}")
                                            return candidate
                                
                                # é€’å½’æœç´¢æ‰€æœ‰å­å¯¹è±¡
                                for key, value in obj.items():
                                    result = find_wxid_in_nested_dict(value, depth + 1)
                                    if result:
                                        return result
                            elif isinstance(obj, list):
                                # æœç´¢åˆ—è¡¨ä¸­çš„æ¯ä¸ªå…ƒç´ 
                                for item in obj:
                                    result = find_wxid_in_nested_dict(item, depth + 1)
                                    if result:
                                        return result
                            return None
                        
                        # é¦–å…ˆå°è¯•é€’å½’æœç´¢
                        new_wxid = find_wxid_in_nested_dict(login_result)
                        
                        # å¦‚æœé€’å½’æœç´¢å¤±è´¥ï¼Œå°è¯•åŸæœ‰çš„é€»è¾‘
                        if not new_wxid:
                            # ä¼˜å…ˆä»Dataå­—æ®µæå–çœŸå®wxid
                            data = login_result.get("Data", {})
                            if data and isinstance(data, dict):
                                # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„å­—æ®µè·å–çœŸå®wxid
                                for wxid_field in ["Wxid", "wxid", "UserName", "userName"]:
                                    if wxid_field in data and data[wxid_field]:
                                        candidate_wxid = data[wxid_field]
                                        # ç¡®ä¿ä¸æ˜¯ä¸´æ—¶ID
                                        if not candidate_wxid.startswith("temp_"):
                                            new_wxid = candidate_wxid
                                            break
                                
                                # å°è¯•è·å–æ˜µç§°
                                for name_field in ["NickName", "nickName", "DisplayName"]:
                                    if name_field in data and data[name_field]:
                                        new_name = data[name_field]
                                        break
                            
                            # å¦‚æœDataå­—æ®µæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–å­—æ®µ
                            if not new_wxid:
                                if "acctSectResp" in login_result:
                                    acct_resp = login_result["acctSectResp"]
                                    candidate_wxid = acct_resp.get("userName", "")
                                    if candidate_wxid and not candidate_wxid.startswith("temp_"):
                                        new_wxid = candidate_wxid
                                    new_name = acct_resp.get("nickName", "")
                                elif "userName" in login_result:
                                    candidate_wxid = login_result["userName"]
                                    if candidate_wxid and not candidate_wxid.startswith("temp_"):
                                        new_wxid = candidate_wxid
                                    new_name = login_result.get("nickName", "")
                    
                    # ğŸ”¥ å¦‚æœä»ç„¶æ‰¾ä¸åˆ°wxidï¼Œå°è¯•ä»device_info.jsonæ–‡ä»¶ä¸­è¯»å–çœŸå®wxid
                    if not new_wxid:
                        logger.warning("[WX859] æ— æ³•ä»ç™»å½•ç»“æœä¸­è·å–æœ‰æ•ˆçš„å¾®ä¿¡IDï¼Œå°è¯•ä»device_info.jsonæ–‡ä»¶ä¸­è¯»å–")
                        
                        # å°è¯•ä»device_info.jsonæ–‡ä»¶ä¸­è¯»å–å·²ä¿å­˜çš„çœŸå®wxid
                        try:
                            if os.path.exists(device_info_path):
                                with open(device_info_path, "r", encoding="utf-8") as f:
                                    existing_device_info = json.load(f)
                                    saved_real_wxid = existing_device_info.get("wxid", "")
                                    
                                    # ç¡®ä¿è¯»å–åˆ°çš„ä¸æ˜¯ä¸´æ—¶ID
                                    if saved_real_wxid and not saved_real_wxid.startswith("temp_"):
                                        new_wxid = saved_real_wxid
                                        logger.info(f"[WX859] ä»device_info.jsonæˆåŠŸè¯»å–çœŸå®wxid: {new_wxid}")
                                    else:
                                        logger.warning(f"[WX859] device_info.jsonä¸­çš„wxidæ— æ•ˆæˆ–ä¸ºä¸´æ—¶ID: {saved_real_wxid}")
                        except Exception as e:
                            logger.error(f"[WX859] è¯»å–device_info.jsonå¤±è´¥: {e}")
                    
                    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œæ‰ä½¿ç”¨uuidä½œä¸ºä¸´æ—¶æ ‡è¯†ç¬¦
                    if not new_wxid:
                        logger.warning("[WX859] æ‰€æœ‰è·å–çœŸå®wxidçš„æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨uuidä½œä¸ºä¸´æ—¶æ ‡è¯†ç¬¦")
                        new_wxid = f"temp_{uuid}"
                        logger.info(f"[WX859] ä¸´æ—¶å¾®ä¿¡ID: {new_wxid}")
                    else:
                        logger.info(f"[WX859] æˆåŠŸè·å–å¾®ä¿¡ID: {new_wxid}")
                    
                    # ğŸ”¥ è®°å½•æå–åˆ°çš„ä¿¡æ¯
                    logger.info(f"[WX859] æå–ç»“æœ - wxid: {new_wxid}, æ˜µç§°: {new_name}")
                    
                    # æ‰«ç æˆåŠŸåçš„å®Œæ•´ç™»å½•æµç¨‹
                    logger.info(f"[WX859] æ‰«ç ç™»å½•æˆåŠŸï¼Œwxid: {new_wxid}, æ˜µç§°: {new_name}")

                    # ğŸ”¥ ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤åå†è¿›è¡Œå®Œæ•´ç™»å½•æµç¨‹
                    logger.info("[WX859] æ‰«ç æˆåŠŸï¼Œç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤ç™»å½•...")
                    
                    # ğŸ”¥ é‡è¦ä¿®å¤ï¼šä¼˜å…ˆä½¿ç”¨çœŸå®wxidè¿›è¡Œåç»­æ“ä½œ
                    login_identifier = new_wxid
                    if new_wxid.startswith("temp_"):
                        logger.warning(f"[WX859] æ£€æµ‹åˆ°ä¸´æ—¶wxid: {new_wxid}ï¼Œå°†ä½¿ç”¨uuidè¿›è¡Œåç»­æ“ä½œ")
                        login_identifier = uuid
                    else:
                        logger.info(f"[WX859] ä½¿ç”¨çœŸå®wxidè¿›è¡Œåç»­ç™»å½•æ“ä½œ: {login_identifier}")
                    
                    # ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤å¹¶å®Œæˆå®Œæ•´ç™»å½•æµç¨‹
                    final_login_success = await self._wait_for_phone_confirmation_and_complete_login(uuid, login_identifier)
                    
                    if not final_login_success:
                        logger.error("[WX859] ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤æˆ–å®Œæ•´ç™»å½•æµç¨‹å¤±è´¥")
                        return False, ""

                    # å…³é”®æ­¥éª¤4ï¼šæ— è®ºå¦‚ä½•éƒ½å°è¯•å¯åŠ¨å¿ƒè·³
                    logger.info(f"[WX859] æ­£åœ¨è°ƒç”¨AutoHeartBeat APIå¯åŠ¨æ¶ˆæ¯ç›‘å¬...")
                    try:
                        async with aiohttp.ClientSession() as session:
                            heartbeat_url = f"http://127.0.0.1:8059/api/Login/AutoHeartBeat?wxid={new_wxid}"
                            async with session.post(heartbeat_url) as response:
                                heartbeat_result = await response.json()
                                if heartbeat_result and heartbeat_result.get("Success", False):
                                    logger.info("[WX859] AutoHeartBeat APIè°ƒç”¨æˆåŠŸï¼Œæ¶ˆæ¯ç›‘å¬å·²å¯åŠ¨")
                                else:
                                    logger.warning(f"[WX859] AutoHeartBeat APIè°ƒç”¨å¤±è´¥: {heartbeat_result}")
                    except Exception as e:
                        logger.error(f"[WX859] AutoHeartBeat APIè°ƒç”¨å¼‚å¸¸: {e}")                   


                    try:
                        device_info = {
                            "wxid": new_wxid,
                            "device_id": device_id,
                            "device_name": device_name
                        }
                        
                        os.makedirs(os.path.dirname(device_info_path), exist_ok=True)
                        with open(device_info_path, "w", encoding="utf-8") as f:
                            json.dump(device_info, f, indent=2)
                        logger.info(f"[WX859] å·²ä¿å­˜ç™»å½•ä¿¡æ¯åˆ°: {device_info_path}")
                    except Exception as e:
                        logger.error(f"[WX859] ä¿å­˜ç™»å½•ä¿¡æ¯å¤±è´¥: {e}")
                    
                    # è®¾ç½®ç™»å½•çŠ¶æ€
                    self.wxid = new_wxid
                    self.user_id = new_wxid
                    self.name = new_name or new_wxid
                    self.is_logged_in = True
                    
                    # åŒæ­¥è®¾ç½®botçš„wxidå±æ€§ï¼Œç¡®ä¿æ¶ˆæ¯è·å–ä¸ä¼šå¤±è´¥
                    if hasattr(self.bot, 'wxid'):
                        self.bot.wxid = new_wxid
                        logger.info(f"[WX859] å·²åŒæ­¥è®¾ç½®bot.wxid = {new_wxid}")
                    else:
                        logger.error(f"[WX859] botå¯¹è±¡æ²¡æœ‰wxidå±æ€§ï¼Œå¯èƒ½å¯¼è‡´æ¶ˆæ¯è·å–å¤±è´¥")
                    
                    logger.info(f"[WX859] ç™»å½•ä¿¡æ¯: user_id={self.user_id}, nickname={self.name}")
                    
                    # å¦‚æœæ²¡æœ‰è·å–åˆ°åç§°ï¼Œå°è¯•è·å–ä¸ªäººèµ„æ–™
                    if not new_name:
                        threading.Thread(target=lambda: asyncio.run(self._get_user_profile())).start()
                    
                    return True, new_wxid
            except Exception as e:
                logger.error(f"[WX859] æ£€æŸ¥æ‰«ç ç™»å½•çŠ¶æ€å‡ºé”™: {e}")
            
            # ç­‰å¾…2ç§’åå†æ¬¡æ£€æŸ¥
            await asyncio.sleep(2)
            login_timeout -= 2
            logger.info(f"[WX859] ç­‰å¾…æ‰«ç ç™»å½•å®Œæˆï¼Œå‰©ä½™ {login_timeout} ç§’...")
        
        logger.error("[WX859] æ‰«ç ç™»å½•è¶…æ—¶")
        return False, ""

    async def _wait_for_phone_confirmation_and_complete_login(self, uuid, wxid):
        """ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤ç™»å½•å¹¶å®Œæˆå®Œæ•´ç™»å½•æµç¨‹"""
        logger.info(f"[WX859] å¼€å§‹ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤ç™»å½•ï¼Œwxid: {wxid}")
        
        # ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤çš„è¶…æ—¶æ—¶é—´ï¼ˆ2åˆ†é’Ÿï¼‰
        confirmation_timeout = 120
        
        import aiohttp
        async with aiohttp.ClientSession() as session:
            while confirmation_timeout > 0:
                try:
                    logger.info(f"[WX859] ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤ç™»å½•ï¼Œå‰©ä½™ {confirmation_timeout} ç§’...")
                    
                    # æ­¥éª¤1ï¼šè°ƒç”¨LoginCheckQR APIç¡®è®¤æ‰«ç çŠ¶æ€
                    logger.debug("[WX859] æ­£åœ¨è°ƒç”¨LoginCheckQR API...")
                    qr_check_url = f"http://127.0.0.1:8059/api/Login/LoginCheckQR?uuid={uuid}"
                    async with session.post(qr_check_url) as response:
                        qr_check_result = await response.json()

                    if qr_check_result and qr_check_result.get("Success", False):
                        logger.info("[WX859] LoginCheckQRæˆåŠŸï¼Œæ‰‹æœºç«¯å·²ç¡®è®¤ï¼Œå¼€å§‹äºŒæ¬¡è®¤è¯...")
                        
                        # æ­¥éª¤2ï¼šè°ƒç”¨LoginTwiceAutoAuth API
                        logger.info(f"[WX859] æ­£åœ¨è°ƒç”¨LoginTwiceAutoAuth API...")
                        
                        # ğŸ”¥ ä¼˜åŒ–ï¼šä¼˜å…ˆå°è¯•ä½¿ç”¨çœŸå®wxidï¼Œå¦‚æœå¤±è´¥å†ä½¿ç”¨uuid
                        real_wxid = None
                        
                        # å¦‚æœä¼ å…¥çš„wxidæ˜¯ä¸´æ—¶IDï¼Œå°è¯•ä»device_info.jsonè¯»å–çœŸå®wxid
                        if wxid.startswith("temp_"):
                            try:
                                device_info_path = os.path.join(get_appdata_dir(), "wx859_device_info.json")
                                if os.path.exists(device_info_path):
                                    with open(device_info_path, "r", encoding="utf-8") as f:
                                        device_info = json.load(f)
                                        saved_wxid = device_info.get("wxid", "")
                                        if saved_wxid and not saved_wxid.startswith("temp_"):
                                            real_wxid = saved_wxid
                                            logger.info(f"[WX859] ä»device_info.jsonè¯»å–åˆ°çœŸå®wxidç”¨äºLoginTwiceAutoAuth: {real_wxid}")
                            except Exception as e:
                                logger.warning(f"[WX859] è¯»å–device_info.jsonä¸­çš„çœŸå®wxidå¤±è´¥: {e}")
                        else:
                            real_wxid = wxid
                        
                        # æ ¹æ®è·å–åˆ°çš„wxidé€‰æ‹©APIè°ƒç”¨æ–¹å¼
                        if real_wxid and not real_wxid.startswith("temp_"):
                            twice_auth_url = f"http://127.0.0.1:8059/api/Login/LoginTwiceAutoAuth?wxid={real_wxid}"
                            logger.info(f"[WX859] ä½¿ç”¨çœŸå®wxidå‚æ•°è°ƒç”¨LoginTwiceAutoAuth: {real_wxid}")
                        else:
                            # ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆï¼Œä½¿ç”¨uuid
                            twice_auth_url = f"http://127.0.0.1:8059/api/Login/LoginTwiceAutoAuth?uuid={uuid}"
                            logger.info(f"[WX859] ä½¿ç”¨uuidå‚æ•°è°ƒç”¨LoginTwiceAutoAuth: {uuid}")
                        
                        async with session.post(twice_auth_url) as response:
                            twice_auth_result = await response.json()
                        
                        if twice_auth_result and twice_auth_result.get("Success", False):
                            logger.info("[WX859] LoginTwiceAutoAuthæˆåŠŸï¼Œå¼€å§‹åˆå§‹åŒ–...")

                            # æ­¥éª¤3ï¼šæŒç»­è°ƒç”¨Newinit APIç›´åˆ°è¿”å›ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
                            logger.info(f"[WX859] å¼€å§‹è°ƒç”¨Newinit APIç­‰å¾…ç™»å½•å®Œæˆ...")
                            newinit_success = await self._wait_for_newinit_success(wxid, session)
                            
                            if newinit_success:
                                logger.info("[WX859] ğŸ‰ å®Œæ•´ç™»å½•æµç¨‹æˆåŠŸå®Œæˆï¼")
                                return True
                            else:
                                logger.error("[WX859] Newinit APIè°ƒç”¨å¤±è´¥ï¼Œç™»å½•æµç¨‹æœªå®Œæˆ")
                                return False
                        else:
                            # ç®€åŒ–LoginTwiceAutoAuthå¤±è´¥æ—¥å¿—ï¼Œåªè®°å½•å…³é”®ä¿¡æ¯
                            error_code = twice_auth_result.get("Code", "æœªçŸ¥") if twice_auth_result else "æ— å“åº”"
                            error_msg = twice_auth_result.get("Message", "æœªçŸ¥é”™è¯¯") if twice_auth_result else "æ— å“åº”"
                            logger.debug(f"[WX859] LoginTwiceAutoAuthå¤±è´¥ (Code: {error_code}): {error_msg}")
                            # ç»§ç»­ç­‰å¾…ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´
                    else:
                        logger.debug(f"[WX859] LoginCheckQRå°šæœªæˆåŠŸï¼Œç»§ç»­ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤: {qr_check_result}")

                except Exception as e:
                    logger.error(f"[WX859] ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                
                # ç­‰å¾…3ç§’åå†æ¬¡æ£€æŸ¥
                await asyncio.sleep(3)
                confirmation_timeout -= 3
        
        logger.error("[WX859] ç­‰å¾…æ‰‹æœºç«¯ç¡®è®¤è¶…æ—¶")
        return False

    async def _wait_for_newinit_success(self, wxid, session):
        """æŒç»­è°ƒç”¨Newinit APIç›´åˆ°è¿”å›ç”¨æˆ·è¯¦ç»†ä¿¡æ¯"""
        logger.info(f"[WX859] å¼€å§‹ç­‰å¾…Newinit APIè¿”å›ç”¨æˆ·è¯¦ç»†ä¿¡æ¯...")
        
        # Newinitæ£€æµ‹è¶…æ—¶æ—¶é—´ï¼ˆ1åˆ†é’Ÿï¼‰
        newinit_timeout = 60
        
        call_count = 0
        while newinit_timeout > 0:
            try:
                call_count += 1
                logger.info(f"[WX859] ç¬¬{call_count}æ¬¡è°ƒç”¨Newinit APIï¼Œå‰©ä½™ {newinit_timeout} ç§’...")
                newinit_url = f"http://127.0.0.1:8059/api/Login/Newinit?wxid={wxid}"
                
                async with session.post(newinit_url) as response:
                    response_status = response.status
                    newinit_result = await response.json()
                
                logger.debug(f"[WX859] Newinit APIå“åº”çŠ¶æ€: {response_status}")
                # ç®€åŒ–Newinitè¿”å›ç»“æœæ—¥å¿—ï¼Œåªè®°å½•å…³é”®ä¿¡æ¯
                if newinit_result and newinit_result.get("Success", False):
                    logger.info(f"[WX859] Newinit APIæˆåŠŸ: {newinit_result.get('Message', 'æˆåŠŸ')}")
                else:
                    error_code = newinit_result.get("Code", "æœªçŸ¥") if newinit_result else "æ— å“åº”"
                    error_msg = newinit_result.get("Message", "æœªçŸ¥é”™è¯¯") if newinit_result else "æ— å“åº”"
                    logger.info(f"[WX859] Newinit APIå¤±è´¥ - Code: {error_code}, Message: {error_msg}")
                
                if newinit_result and newinit_result.get("Success", False):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
                    if self._check_newinit_user_details(newinit_result):
                        logger.info(f"[WX859] âœ… Newinit APIè¿”å›ç”¨æˆ·è¯¦ç»†ä¿¡æ¯ï¼Œç™»å½•çœŸæ­£å®Œæˆï¼")
                        # åªè®°å½•å…³é”®ç”¨æˆ·ä¿¡æ¯ï¼Œä¸è®°å½•å®Œæ•´çš„å†—é•¿æ•°æ®
                        user_info = newinit_result.get("Data", {}).get("ModUserInfos", [{}])[0]
                        user_name = user_info.get("UserName", {}).get("string", "æœªçŸ¥")
                        nick_name = user_info.get("NickName", {}).get("string", "æœªçŸ¥")
                        logger.info(f"[WX859] ç™»å½•ç”¨æˆ·: {user_name} ({nick_name})")
                        
                        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¿å­˜Newinitè¿”å›çš„Synckeyåˆ°botå¯¹è±¡
                        newinit_data = newinit_result.get("Data", {})
                        if "CurrentSynckey" in newinit_data:
                            current_synckey = newinit_data["CurrentSynckey"]
                            if isinstance(current_synckey, dict) and "buffer" in current_synckey:
                                synckey_buffer = current_synckey["buffer"]
                                if hasattr(self.bot, '_synckey'):
                                    self.bot._synckey = synckey_buffer
                                    logger.info(f"[WX859] å·²ä¿å­˜Newinitè¿”å›çš„Synckeyç”¨äºæ¶ˆæ¯åŒæ­¥")
                                else:
                                    logger.warning(f"[WX859] botå¯¹è±¡æ²¡æœ‰_synckeyå±æ€§ï¼Œæ— æ³•ä¿å­˜Synckey")
                        
                        return True
                    else:
                        logger.info("[WX859] Newinit APIæˆåŠŸä½†å°šæœªè¿”å›å®Œæ•´ç”¨æˆ·ä¿¡æ¯ï¼Œç»§ç»­ç­‰å¾…...")
                else:
                    # è¯¦ç»†è®°å½•å¤±è´¥ä¿¡æ¯
                    error_code = newinit_result.get("Code", "æœªçŸ¥") if newinit_result else "æ— å“åº”"
                    error_msg = newinit_result.get("Message", "æœªçŸ¥é”™è¯¯") if newinit_result else "æ— å“åº”"
                    
                    logger.info(f"[WX859] Newinit APIè°ƒç”¨å¤±è´¥ - Code: {error_code}, Message: {error_msg}")
                    
                    # åˆ†æå…·ä½“çš„å¤±è´¥åŸå› 
                    if error_code == -13:
                        logger.info("[WX859] é”™è¯¯åˆ†æ: ç”¨æˆ·å°šæœªå®Œå…¨ç™»å½•ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡ï¼Œç»§ç»­ç­‰å¾…...")
                    elif error_code == -8:
                        logger.warning("[WX859] é”™è¯¯åˆ†æ: ç™»å½•ä¼šè¯å¯èƒ½å·²å¤±æ•ˆï¼Œä½†ç»§ç»­å°è¯•...")
                    else:
                        logger.warning(f"[WX859] é”™è¯¯åˆ†æ: æœªçŸ¥é”™è¯¯ç  {error_code}ï¼Œç»§ç»­å°è¯•...")
                    
            except Exception as e:
                logger.error(f"[WX859] Newinit APIè°ƒç”¨å¼‚å¸¸: {e}")
                import traceback
                logger.error(f"[WX859] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            
            # ç­‰å¾…2ç§’åå†æ¬¡æ£€æŸ¥
            await asyncio.sleep(2)
            newinit_timeout -= 2
        
        logger.error(f"[WX859] ç­‰å¾…Newinit APIè¿”å›ç”¨æˆ·è¯¦ç»†ä¿¡æ¯è¶…æ—¶ï¼Œå…±å°è¯•äº† {call_count} æ¬¡")
        logger.error("[WX859] ğŸ” Newinitå¤±è´¥åˆ†æ:")
        logger.error("   1. å¯èƒ½åŸå› : æ‰‹æœºç«¯å°šæœªå®Œå…¨ç¡®è®¤ç™»å½•")
        logger.error("   2. å¯èƒ½åŸå› : ç½‘ç»œè¿æ¥ä¸ç¨³å®š")
        logger.error("   3. å¯èƒ½åŸå› : 859åè®®æœåŠ¡ç«¯çŠ¶æ€å¼‚å¸¸")
        logger.error("   4. å»ºè®®: é‡æ–°å¯åŠ¨ç¨‹åºå¹¶é‡æ–°æ‰«ç ç™»å½•")
        return False

    def _check_newinit_user_details(self, newinit_result):
        """æ£€æŸ¥Newinit APIè¿”å›æ˜¯å¦åŒ…å«ç”¨æˆ·è¯¦ç»†ä¿¡æ¯"""
        try:
            if not isinstance(newinit_result, dict):
                logger.info("[WX859] Newinitç»“æœä¸æ˜¯å­—å…¸ç±»å‹")
                return False
            
            # æ£€æŸ¥åŸºæœ¬æˆåŠŸçŠ¶æ€
            if not newinit_result.get("Success", False):
                logger.info("[WX859] Newinit APIè¿”å›Success=False")
                return False
            
            # æ£€æŸ¥Dataå­—æ®µ
            data = newinit_result.get("Data", {})
            if not isinstance(data, dict):
                logger.info("[WX859] Newinit APIè¿”å›çš„Dataå­—æ®µæ— æ•ˆ")
                return False
            
            # æ£€æŸ¥ModUserInfoså­—æ®µ
            mod_user_infos = data.get("ModUserInfos", [])
            if not isinstance(mod_user_infos, list) or len(mod_user_infos) == 0:
                logger.info("[WX859] Newinit APIè¿”å›çš„ModUserInfoså­—æ®µä¸ºç©ºæˆ–æ— æ•ˆ")
                return False
            
            # è·å–ç¬¬ä¸€ä¸ªç”¨æˆ·ä¿¡æ¯
            user_info = mod_user_infos[0]
            if not isinstance(user_info, dict):
                logger.info("[WX859] ç”¨æˆ·ä¿¡æ¯æ ¼å¼æ— æ•ˆ")
                return False
            
            # æå–ç”¨æˆ·è¯¦ç»†ä¿¡æ¯
            user_name_obj = user_info.get("UserName", {})
            nick_name_obj = user_info.get("NickName", {})
            status = user_info.get("Status", 0)
            
            # å¤„ç†åµŒå¥—çš„stringç»“æ„
            user_name = ""
            nick_name = ""
            
            if isinstance(user_name_obj, dict) and "string" in user_name_obj:
                user_name = user_name_obj["string"]
            elif isinstance(user_name_obj, str):
                user_name = user_name_obj
                
            if isinstance(nick_name_obj, dict) and "string" in nick_name_obj:
                nick_name = nick_name_obj["string"]
            elif isinstance(nick_name_obj, str):
                nick_name = nick_name_obj
            
            # éªŒè¯å…³é”®å­—æ®µ
            if user_name and nick_name and status > 0:
                logger.info(f"[WX859] âœ… æ£€æµ‹åˆ°å®Œæ•´ç”¨æˆ·ä¿¡æ¯: userName={user_name}, nickName={nick_name}, status={status}")
                return True
            else:
                logger.info(f"[WX859] ç”¨æˆ·ä¿¡æ¯å­—æ®µæ£€æŸ¥: userName='{user_name}', nickName='{nick_name}', status={status}")
                logger.info(f"[WX859] åŸå§‹UserNameå¯¹è±¡: {user_name_obj}")
                logger.info(f"[WX859] åŸå§‹NickNameå¯¹è±¡: {nick_name_obj}")
                return False
            
        except Exception as e:
            logger.error(f"[WX859] æ£€æŸ¥ç”¨æˆ·è¯¦ç»†ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            import traceback
            logger.error(f"[WX859] å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
            return False

    async def _check_login_status(self, wxid):
        """æ£€æŸ¥æ˜¯å¦å·²ç»ç™»å½•"""
        try:
            logger.info(f"[WX859] æ­£åœ¨æ£€æŸ¥ç”¨æˆ· {wxid} çš„ç™»å½•çŠ¶æ€")
            
            # è®¾ç½®botçš„wxid
            if hasattr(self.bot, 'wxid'):
                self.bot.wxid = wxid
            
            # ä½¿ç”¨botå¯¹è±¡çš„heartbeatæ–¹æ³•
            heartbeat_result = await self.bot.heartbeat()
            
            if heartbeat_result:
                logger.info(f"[WX859] å¿ƒè·³æ£€æµ‹æˆåŠŸï¼Œwxid={wxid}å¤„äºç™»å½•çŠ¶æ€")
                return True
            else:
                logger.debug(f"[WX859] å¿ƒè·³æ£€æµ‹å¤±è´¥ï¼Œwxid={wxid}ä¸åœ¨ç™»å½•çŠ¶æ€")
                return False
        except Exception as e:
            logger.debug(f"[WX859] æ£€æŸ¥ç™»å½•çŠ¶æ€å¤±è´¥: {e}")
            return False

    async def _get_cached_info(self, wxid):
        """è·å–ç™»å½•ç¼“å­˜ä¿¡æ¯"""
        try:
            logger.info(f"[WX859] æ­£åœ¨è·å–ç”¨æˆ· {wxid} çš„ç™»å½•ç¼“å­˜ä¿¡æ¯")
            
            # ä½¿ç”¨botå¯¹è±¡çš„get_cached_infoæ–¹æ³•
            cache_info = await self.bot.get_cached_info(wxid)
            
            if cache_info:
                logger.info(f"[WX859] æˆåŠŸè·å–ç™»å½•ç¼“å­˜ä¿¡æ¯: wxid={wxid}")
                return cache_info
            else:
                logger.debug(f"[WX859] è·å–ç™»å½•ç¼“å­˜ä¿¡æ¯å¤±è´¥: wxid={wxid}")
                return None
        except Exception as e:
            logger.debug(f"[WX859] è·å–ç™»å½•ç¼“å­˜ä¿¡æ¯å¤±è´¥: {e}")
            return None

    async def _twice_login(self, wxid, device_id=None):
        """å°è¯•äºŒæ¬¡ç™»å½•"""
        try:
            logger.debug(f"[WX859] å°è¯•äºŒæ¬¡ç™»å½•: wxid={wxid}, device_id={device_id}")
            
            # ä½¿ç”¨botå¯¹è±¡çš„twice_loginæ–¹æ³•
            login_result = await self.bot.twice_login(wxid)
            
            if login_result:
                logger.info(f"[WX859] äºŒæ¬¡ç™»å½•æˆåŠŸ: wxid={wxid}")
                return True
            else:
                logger.debug(f"[WX859] äºŒæ¬¡ç™»å½•å¤±è´¥: wxid={wxid}")
                return False
        except Exception as e:
            logger.debug(f"[WX859] äºŒæ¬¡ç™»å½•å¤±è´¥: {e}")
            return False

    async def _awaken_login(self, wxid, device_name="iPad"):
        """å°è¯•å”¤é†’ç™»å½•"""
        try:
            logger.info(f"[WX859] å°è¯•å”¤é†’ç™»å½•: wxid={wxid}, device_name={device_name}")
            
            # ä½¿ç”¨botå¯¹è±¡çš„awaken_loginæ–¹æ³•
            uuid = await self.bot.awaken_login(wxid)
            
            if uuid:
                logger.info(f"[WX859] å”¤é†’ç™»å½•æˆåŠŸï¼Œè·å–åˆ°UUID: {uuid}")
                return uuid
            else:
                logger.warning(f"[WX859] å”¤é†’ç™»å½•å¤±è´¥ï¼Œæœªè·å–åˆ°æœ‰æ•ˆUUID")
                return None
        except Exception as e:
            logger.error(f"[WX859] å”¤é†’ç™»å½•å¤±è´¥: {e}")
            import traceback
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None
        except Exception as e:
            logger.error(f"[WX859] å”¤é†’ç™»å½•å¤±è´¥: {e}")
            import traceback
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None

    async def _auto_login(self, saved_wxid, saved_device_id, saved_device_name):
        """è‡ªåŠ¨ç™»å½•æµç¨‹"""
        if not saved_wxid:
            logger.info("[WX859] æ— ä¿å­˜çš„å¾®ä¿¡IDï¼Œæ— æ³•æ‰§è¡Œè‡ªåŠ¨ç™»å½•")
            return False
        
        logger.info(f"[WX859] å¼€å§‹è‡ªåŠ¨ç™»å½•æµç¨‹: wxid={saved_wxid}")
        
        # 1. é¦–å…ˆæ£€æŸ¥ç™»å½•çŠ¶æ€ - é€šè¿‡å¿ƒè·³æ¥å£
        logger.info(f"[WX859] ç¬¬1æ­¥: æ£€æŸ¥å¿ƒè·³çŠ¶æ€")
        heart_beat_ok = await self._check_login_status(saved_wxid)
        if heart_beat_ok:
            logger.info(f"[WX859] å¿ƒè·³æ£€æµ‹æˆåŠŸï¼Œwxid={saved_wxid}å·²åœ¨çº¿")
            
            # å…ˆè®¾ç½®botçš„wxidï¼Œå†è°ƒç”¨_set_logged_in_stateæ–¹æ³•
            if hasattr(self.bot, 'wxid'):
                self.bot.wxid = saved_wxid
                logger.info(f"[WX859] å·²åŒæ­¥è®¾ç½®bot.wxid = {saved_wxid}")
            else:
                logger.error(f"[WX859] botå¯¹è±¡æ²¡æœ‰wxidå±æ€§ï¼Œå¯èƒ½å¯¼è‡´æ¶ˆæ¯è·å–å¤±è´¥")
                
            self._set_logged_in_state(saved_wxid)
            return True
        
        logger.debug(f"[WX859] å¿ƒè·³æ£€æµ‹å¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–è‡ªåŠ¨ç™»å½•æ–¹å¼")
        
        # 2. å°è¯•äºŒæ¬¡ç™»å½•ï¼ˆå¤šæ¬¡é‡è¯•ï¼‰
        logger.info(f"[WX859] ç¬¬2æ­¥: å°è¯•äºŒæ¬¡ç™»å½•")
        for retry in range(3):  # æœ€å¤šé‡è¯•3æ¬¡
            try:
                twice_login_result = await self._twice_login(saved_wxid, saved_device_id)
                if twice_login_result:
                    logger.info(f"[WX859] äºŒæ¬¡ç™»å½•æˆåŠŸ: {saved_wxid}")
                    
                    # å…ˆè®¾ç½®botçš„wxidï¼Œå†è°ƒç”¨_set_logged_in_stateæ–¹æ³•
                    if hasattr(self.bot, 'wxid'):
                        self.bot.wxid = saved_wxid
                        logger.info(f"[WX859] å·²åŒæ­¥è®¾ç½®bot.wxid = {saved_wxid}")
                    else:
                        logger.error(f"[WX859] botå¯¹è±¡æ²¡æœ‰wxidå±æ€§ï¼Œå¯èƒ½å¯¼è‡´æ¶ˆæ¯è·å–å¤±è´¥")
                        
                    self._set_logged_in_state(saved_wxid)
                    return True
                else:
                    logger.debug(f"[WX859] äºŒæ¬¡ç™»å½•å¤±è´¥ï¼Œç¬¬{retry+1}æ¬¡é‡è¯•")
                    if retry < 2:  # ä¸æ˜¯æœ€åä¸€æ¬¡é‡è¯•
                        await asyncio.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
            except Exception as e:
                logger.debug(f"[WX859] äºŒæ¬¡ç™»å½•å¼‚å¸¸ï¼Œç¬¬{retry+1}æ¬¡é‡è¯•: {e}")
                if retry < 2:
                    await asyncio.sleep(2)
        
        logger.debug(f"[WX859] äºŒæ¬¡ç™»å½•å¤±è´¥ï¼Œå°è¯•å”¤é†’ç™»å½•")
        
        # 3. å¦‚æœäºŒæ¬¡ç™»å½•å¤±è´¥ï¼Œå°è¯•å”¤é†’ç™»å½•
        logger.info(f"[WX859] ç¬¬3æ­¥: å°è¯•å”¤é†’ç™»å½•")
        uuid = await self._awaken_login(saved_wxid, saved_device_name or "iPad")
        if not uuid:
            logger.debug(f"[WX859] å”¤é†’ç™»å½•å¤±è´¥ï¼Œè‡ªåŠ¨ç™»å½•æµç¨‹ç»ˆæ­¢")
            return False
        
        logger.info(f"[WX859] å”¤é†’ç™»å½•æˆåŠŸï¼Œè·å–åˆ°UUID: {uuid}")
        
        # 4. ç­‰å¾…å”¤é†’ç™»å½•ç¡®è®¤
        logger.info(f"[WX859] ç¬¬4æ­¥: ç­‰å¾…å”¤é†’ç™»å½•ç¡®è®¤")
        login_result = await self._wait_for_login_confirmation(uuid, saved_device_id)
        if login_result:
            logger.info(f"[WX859] å”¤é†’ç™»å½•ç¡®è®¤æˆåŠŸ: {saved_wxid}")
            
            # å…ˆè®¾ç½®botçš„wxidï¼Œå†è°ƒç”¨_set_logged_in_stateæ–¹æ³•
            if hasattr(self.bot, 'wxid'):
                self.bot.wxid = saved_wxid
                logger.info(f"[WX859] å·²åŒæ­¥è®¾ç½®bot.wxid = {saved_wxid}")
            else:
                logger.error(f"[WX859] botå¯¹è±¡æ²¡æœ‰wxidå±æ€§ï¼Œå¯èƒ½å¯¼è‡´æ¶ˆæ¯è·å–å¤±è´¥")
                
            self._set_logged_in_state(saved_wxid)
            return True
        
        logger.warning(f"[WX859] å”¤é†’ç™»å½•ç¡®è®¤å¤±è´¥ï¼Œè‡ªåŠ¨ç™»å½•æµç¨‹å¤±è´¥")
        return False

    async def _wait_for_login_confirmation(self, uuid, device_id):
        """ç­‰å¾…å”¤é†’ç™»å½•ç¡®è®¤"""
        timeout = 60  # 60ç§’è¶…æ—¶
        logger.info(f"[WX859] ç­‰å¾…å”¤é†’ç™»å½•ç¡®è®¤ï¼ŒUUID: {uuid}, è®¾å¤‡ID: {device_id}, è¶…æ—¶æ—¶é—´: {timeout}ç§’")
        
        while timeout > 0:
            try:
                logger.info(f"[WX859] ç­‰å¾…å”¤é†’ç™»å½•ç¡®è®¤ï¼Œå‰©ä½™ {timeout} ç§’...")
                
                # æ£€æŸ¥ç™»å½•çŠ¶æ€ - ç¡®ä¿ä½¿ç”¨å°å†™å‚æ•°
                logger.debug(f"[WX859] æ£€æŸ¥ç™»å½•UUIDçŠ¶æ€: {uuid}")
                login_success, login_result = await self.bot.check_login_uuid(uuid, device_id=device_id)
                
                # è®°å½•ç»“æœè¯¦æƒ…
                logger.debug(f"[WX859] æ£€æŸ¥ç™»å½•UUIDç»“æœ: success={login_success}, result={login_result}")
                
                if login_success:
                    logger.info("[WX859] å”¤é†’ç™»å½•ç¡®è®¤æˆåŠŸ")
                    
                    # å…³é”®æ­¥éª¤ï¼šè°ƒç”¨LoginCheckQR APIç¡®è®¤äºŒç»´ç çŠ¶æ€
                    logger.info("[WX859] æ­£åœ¨è°ƒç”¨LoginCheckQR APIç¡®è®¤å”¤é†’ç™»å½•äºŒç»´ç çŠ¶æ€...")
                    try:
                        qr_check_result = await self._call_api("/Login/LoginCheckQR", {"uuid": uuid})
                        if qr_check_result and qr_check_result.get("Success", False):
                            logger.info("[WX859] å”¤é†’ç™»å½•LoginCheckQR APIè°ƒç”¨æˆåŠŸï¼ŒäºŒç»´ç çŠ¶æ€å·²ç¡®è®¤")
                        else:
                            logger.warning(f"[WX859] å”¤é†’ç™»å½•LoginCheckQR APIè°ƒç”¨å¤±è´¥: {qr_check_result}")
                    except Exception as qr_check_error:
                        logger.error(f"[WX859] å”¤é†’ç™»å½•LoginCheckQR APIè°ƒç”¨å¼‚å¸¸: {qr_check_error}")
                        # ä¸é˜»æ–­ç™»å½•æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
                    
                    return True
                else:
                    # å¦‚æœæœªæˆåŠŸï¼Œè®°å½•æ›´è¯¦ç»†çš„çŠ¶æ€ä¿¡æ¯
                    if isinstance(login_result, dict):
                        status = login_result.get("Status", "æœªçŸ¥")
                        msg = login_result.get("Message", "")
                        logger.debug(f"[WX859] ç™»å½•çŠ¶æ€: {status}, æ¶ˆæ¯: {msg}")
            except Exception as e:
                logger.error(f"[WX859] æ£€æŸ¥ç™»å½•ç¡®è®¤çŠ¶æ€å¤±è´¥: {e}")
                import traceback
                logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            
            # ç­‰å¾…2ç§’åå†æ¬¡æ£€æŸ¥
            await asyncio.sleep(2)
            timeout -= 2
        
        logger.error("[WX859] ç­‰å¾…ç™»å½•ç¡®è®¤è¶…æ—¶")
        return False

    def _set_logged_in_state(self, wxid):
        """è®¾ç½®ç™»å½•æˆåŠŸçŠ¶æ€"""
        self.wxid = wxid
        self.user_id = wxid
        self.is_logged_in = True
        
        # åŒæ­¥è®¾ç½®botçš„wxidå±æ€§ï¼Œç¡®ä¿æ¶ˆæ¯è·å–ä¸ä¼šå¤±è´¥
        if hasattr(self.bot, 'wxid'):
            self.bot.wxid = wxid
            logger.info(f"[WX859] å·²åŒæ­¥è®¾ç½®bot.wxid = {wxid}")
        else:
            logger.error(f"[WX859] botå¯¹è±¡æ²¡æœ‰wxidå±æ€§ï¼Œå¯èƒ½å¯¼è‡´æ¶ˆæ¯è·å–å¤±è´¥")

        # å¯åŠ¨è‡ªåŠ¨å¿ƒè·³å’Œæ¶ˆæ¯ç›‘å¬
        threading.Thread(target=lambda: asyncio.run(self._start_auto_heartbeat(wxid))).start()
        
        # å¼‚æ­¥è·å–ç”¨æˆ·èµ„æ–™
        threading.Thread(target=lambda: asyncio.run(self._get_user_profile())).start()

    async def _start_auto_heartbeat(self, wxid):
        """å¯åŠ¨è‡ªåŠ¨å¿ƒè·³å’Œæ¶ˆæ¯ç›‘å¬"""
        try:
            logger.info(f"[WX859] æ­£åœ¨å¯åŠ¨è‡ªåŠ¨å¿ƒè·³ï¼Œwxid: {wxid}")
            import aiohttp
            async with aiohttp.ClientSession() as session:
                heartbeat_url = f"http://127.0.0.1:8059/api/Login/AutoHeartBeat?wxid={wxid}"
                async with session.post(heartbeat_url) as response:
                    heartbeat_result = await response.json()
                    if heartbeat_result and heartbeat_result.get("Success", False):
                        logger.info("[WX859] è‡ªåŠ¨å¿ƒè·³å¯åŠ¨æˆåŠŸï¼Œæ¶ˆæ¯ç›‘å¬å·²æ¿€æ´»")
                    else:
                        logger.warning(f"[WX859] è‡ªåŠ¨å¿ƒè·³å¯åŠ¨å¤±è´¥: {heartbeat_result}")
        except Exception as e:
            logger.error(f"[WX859] å¯åŠ¨è‡ªåŠ¨å¿ƒè·³å¼‚å¸¸: {e}")

    async def _get_user_profile(self):
        """è·å–ç”¨æˆ·èµ„æ–™"""
        try:
            profile = await self.bot.get_profile()
            if profile and isinstance(profile, dict):
                userinfo = profile.get("userInfo", {})
                if isinstance(userinfo, dict):
                    if "NickName" in userinfo and isinstance(userinfo["NickName"], dict) and "string" in userinfo["NickName"]:
                        self.name = userinfo["NickName"]["string"]
                    elif "nickname" in userinfo:
                        self.name = userinfo["nickname"]
                    elif "nickName" in userinfo:
                        self.name = userinfo["nickName"]
                    else:
                        self.name = self.wxid
                    logger.info(f"[WX859] è·å–åˆ°ç”¨æˆ·æ˜µç§°: {self.name}")
                    return
            
            self.name = self.wxid
            logger.warning(f"[WX859] æ— æ³•è§£æç”¨æˆ·èµ„æ–™ï¼Œä½¿ç”¨wxidä½œä¸ºæ˜µç§°: {self.wxid}")
        except Exception as e:
            self.name = self.wxid
            logger.error(f"[WX859] è·å–ç”¨æˆ·èµ„æ–™å¤±è´¥: {e}")

    async def _message_listener(self):
        """æ¶ˆæ¯ç›‘å¬å™¨ - æ”¹ä¸ºWebSocketå®ç°"""
        logger.info("[WX859] å¼€å§‹ä½¿ç”¨ WebSocket ç›‘å¬æ¶ˆæ¯...")
        
        # ä»é…ç½®ä¸­è·å–APIåœ°å€å’Œç«¯å£
        api_host = conf().get("wx859_api_host", "127.0.0.1")
        api_port = conf().get("wx859_api_port", 8059)
        
        # æ„é€ WebSocketè¿æ¥åœ°å€
        # 859åè®®çš„WebSocketåœ°å€é€šå¸¸æ˜¯ /ws
        ws_url = f"ws://{api_host}:{api_port}/ws/{self.wxid}"
        
        while self.is_running:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.ws_connect(ws_url) as ws:
                        logger.info(f"[WX859] å·²æˆåŠŸè¿æ¥åˆ° WebSocket: {ws_url}")
                        
                        # å¯åŠ¨å¿ƒè·³ä»»åŠ¡
                        heartbeat_task = asyncio.create_task(self._websocket_heartbeat(ws))
                        
                        async for msg in ws:
                            if msg.type == aiohttp.WSMsgType.TEXT:
                                try:
                                    data = json.loads(msg.data)
                                    # æ£€æŸ¥æ¶ˆæ¯æ ¼å¼æ˜¯å¦ä¸ºé•¿è¿æ¥æ¶ˆæ¯
                                    if data.get("type") == "long_connection_message" and "data" in data:
                                        message_content = data.get("data")
                                        if message_content:
                                            # å°†å•ä¸ªæ¶ˆæ¯æ”¾å…¥åˆ—è¡¨ä¸­ä»¥å…¼å®¹å¤„ç†å‡½æ•°
                                            logger.info(f"[WX859] WebSocketæ”¶åˆ° 1 æ¡æ–°æ¶ˆæ¯ (type: long_connection_message)")
                                            await self._process_ws_messages([message_content])
                                        else:
                                            logger.debug("[WX859] WebSocketæ”¶åˆ°ç©ºçš„ 'data' å­—æ®µ")
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯new_messageæ ¼å¼ (æ–°å¢æ”¯æŒ)
                                    elif data.get("type") == "new_message" and "data" in data:
                                        message_content = data.get("data")
                                        if message_content:
                                            # å°†å•ä¸ªæ¶ˆæ¯æ”¾å…¥åˆ—è¡¨ä¸­ä»¥å…¼å®¹å¤„ç†å‡½æ•°
                                            logger.info(f"[WX859] WebSocketæ”¶åˆ° 1 æ¡æ–°æ¶ˆæ¯ (type: new_message)")
                                            await self._process_ws_messages([message_content])
                                        else:
                                            logger.debug("[WX859] WebSocketæ”¶åˆ°ç©ºçš„ 'data' å­—æ®µ")
                                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ—§æ ¼å¼çš„ new_msg äº‹ä»¶ (ä¸ºäº†å…¼å®¹æ€§)
                                    elif data.get("Event") == "new_msg" and "Data" in data:
                                        messages = data.get("Data", [])
                                        if messages:
                                            logger.info(f"[WX859] WebSocketæ”¶åˆ° {len(messages)} æ¡æ–°æ¶ˆæ¯ (Event: new_msg)")
                                            await self._process_ws_messages(messages)
                                        else:
                                            logger.debug("[WX859] WebSocketæ”¶åˆ°ç©ºæ¶ˆæ¯åˆ—è¡¨ (Event: new_msg)")
                                    else:
                                        logger.debug(f"[WX859] æ”¶åˆ°æœªçŸ¥æ ¼å¼æˆ–éæ¶ˆæ¯ç±»å‹çš„WebSocketäº‹ä»¶: {data}")

                                except json.JSONDecodeError:
                                    logger.warning(f"[WX859] æ— æ³•è§£æWebSocketæ¶ˆæ¯: {msg.data}")
                                except Exception as e:
                                    logger.error(f"[WX859] å¤„ç†WebSocketæ¶ˆæ¯æ—¶å‡ºé”™: {e}")
                                    logger.error(traceback.format_exc())

                            elif msg.type == aiohttp.WSMsgType.ERROR:
                                logger.error(f"[WX859] WebSocket è¿æ¥é”™è¯¯: {ws.exception()}")
                                break
            except aiohttp.ClientConnectorError as e:
                logger.error(f"[WX859] WebSocket è¿æ¥å¤±è´¥: {e}ï¼Œå°†åœ¨5ç§’åé‡è¯•...")
                await asyncio.sleep(5)
            except Exception as e:
                logger.error(f"[WX859] WebSocket ç›‘å¬å™¨å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
                logger.error(traceback.format_exc())
                logger.info("[WX859] ç›‘å¬å™¨å°†åœ¨10ç§’åé‡å¯...")
                await asyncio.sleep(10)

    async def _websocket_heartbeat(self, ws):
        """WebSocketå¿ƒè·³ä»»åŠ¡"""
        while not ws.closed:
            try:
                # æ¯60ç§’å‘é€ä¸€æ¬¡å¿ƒè·³åŒ…
                await asyncio.sleep(60)
                ping_payload = {"event": "ping", "data": "heartbeat"}
                await ws.send_json(ping_payload)
                logger.debug("[WX859] WebSocketå¿ƒè·³åŒ…å·²å‘é€")
            except asyncio.CancelledError:
                logger.info("[WX859] WebSocketå¿ƒè·³ä»»åŠ¡è¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"[WX859] WebSocketå¿ƒè·³ä»»åŠ¡å¼‚å¸¸: {e}")
                break

    async def _process_ws_messages(self, messages):
        """å¤„ç†ä»WebSocketæ¥æ”¶åˆ°çš„æ¶ˆæ¯åˆ—è¡¨"""
        if not messages:
            return
            
        for idx, msg in enumerate(messages):
            try:
                logger.debug(f"[WX859] å¤„ç†ç¬¬ {idx+1}/{len(messages)} æ¡æ¶ˆæ¯")
                is_group = False
                if "roomId" in msg and msg["roomId"]:
                    is_group = True
                if not is_group:
                    for field_name in ["fromUserName", "FromUserName", "toUserName", "ToUserName"]:
                        if field_name in msg and msg[field_name]:
                            user_name_field = msg[field_name]
                            if isinstance(user_name_field, dict) and "string" in user_name_field:
                                user_name_field = user_name_field["string"]
                            if isinstance(user_name_field, str) and user_name_field.endswith("@chatroom"):
                                is_group = True
                                logger.debug(f"[WX859] é€šè¿‡{field_name}å­—æ®µè¯†åˆ«ä¸ºç¾¤èŠ: {user_name_field}")
                                break
                
                cmsg = WX859Message(msg, is_group)
                logger.debug(f"[WX859] å¤„ç†æ¶ˆæ¯: {getattr(cmsg, 'ctype', 'Unknown')} - {getattr(cmsg, 'content', 'Unknown')[:2000]}")
                
                if self._should_filter_this_message(cmsg):
                    logger.debug(f"[WX859] æ¶ˆæ¯è¢«è¿‡æ»¤: {getattr(cmsg, 'sender_wxid', 'Unknown')}")
                    continue                            

                if is_group:
                    await self.handle_group(cmsg)
                else:
                    await self.handle_single(cmsg)
            except Exception as e:
                logger.error(f"[WX859] å¤„ç†æ¶ˆæ¯å‡ºé”™: {e}")
                logger.error(f"[WX859] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")

    def startup(self):
        """å¯åŠ¨å‡½æ•°"""
        logger.info("[WX859] æ­£åœ¨å¯åŠ¨...")
        
        # åˆ›å»ºäº‹ä»¶å¾ªç¯
        loop = asyncio.new_event_loop()
        self.loop = loop
        self._start_image_cache_cleanup_task()
        self._start_file_cache_cleanup_task()
        # å®šä¹‰å¯åŠ¨ä»»åŠ¡
        async def startup_task():
            # åˆå§‹åŒ–æœºå™¨äººï¼ˆç™»å½•ï¼‰
            login_success = await self._initialize_bot()
            if login_success:
                logger.info("[WX859] ç™»å½•æˆåŠŸï¼Œå‡†å¤‡å¯åŠ¨æ¶ˆæ¯ç›‘å¬...")
                self.is_running = True
                # å¯åŠ¨æ¶ˆæ¯ç›‘å¬
                await self._message_listener()
            else:
                logger.error("[WX859] åˆå§‹åŒ–å¤±è´¥")
        
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œäº‹ä»¶å¾ªç¯
        def run_loop():
            asyncio.set_event_loop(loop)
            loop.run_until_complete(startup_task())
        
        thread = threading.Thread(target=run_loop)
        thread.daemon = True
        thread.start()

    # MODIFIED: Enhanced filter method with comprehensive system message filtering
    def _should_filter_this_message(self, wx_msg: 'WX859Message') -> bool:
        """
        å®Œå–„çš„æ¶ˆæ¯è¿‡æ»¤æœºåˆ¶
        å‚è€ƒxybot-0603.pyä¸­çš„ignore_checkæ–¹æ³•ï¼Œè¿‡æ»¤å„ç§ç³»ç»Ÿæ¶ˆæ¯å’Œä¸éœ€è¦å¤„ç†çš„æ¶ˆæ¯
        """
        if not wx_msg:
            logger.debug("[WX859] Filter: Received an empty message object, ignoring.")
            return True

        actual_from_user_id = getattr(wx_msg, 'from_user_id', '')
        # actual_sender_wxid is specifically for the user who sent the message within a group
        actual_sender_wxid = getattr(wx_msg, 'sender_wxid', '') 

        effective_sender_id = actual_sender_wxid if actual_sender_wxid else actual_from_user_id

        _content_value = getattr(wx_msg, 'content', '') 
        _message_content_preview = f"(content type: {type(_content_value)}, first 50 chars: {str(_content_value)[:50]})"
        _message_type = getattr(wx_msg, 'type', None) # wx_msg.type should be ContextType
        _message_create_time = getattr(wx_msg, 'create_time', None)

        # 1. è¿‡æ»¤å…¬ä¼—å·æ¶ˆæ¯ï¼ˆå…¬ä¼—å·wxidé€šå¸¸ä»¥gh_å¼€å¤´ï¼‰
        if actual_sender_wxid and isinstance(actual_sender_wxid, str) and actual_sender_wxid.startswith("gh_"):
            logger.debug(f"[WX859] Filter: å¿½ç•¥å…¬ä¼—å·æ¶ˆæ¯: {actual_sender_wxid}")
            return True
        if actual_from_user_id and isinstance(actual_from_user_id, str) and actual_from_user_id.startswith("gh_"):
            logger.debug(f"[WX859] Filter: å¿½ç•¥å…¬ä¼—å·æ¶ˆæ¯: {actual_from_user_id}")
            return True

        # 2. è¿‡æ»¤å¾®ä¿¡å›¢é˜Ÿå’Œç³»ç»Ÿé€šçŸ¥
        system_accounts = [
            "weixin",  # å¾®ä¿¡å›¢é˜Ÿ
            "filehelper",  # æ–‡ä»¶ä¼ è¾“åŠ©æ‰‹
            "fmessage",  # æœ‹å‹æ¨èé€šçŸ¥
            "medianote",  # è¯­éŸ³è®°äº‹æœ¬
            "floatbottle",  # æ¼‚æµç“¶
            "qmessage",  # QQç¦»çº¿æ¶ˆæ¯
            "qqmail",  # QQé‚®ç®±æé†’
            "tmessage",  # è…¾è®¯æ–°é—»
            "weibo",  # å¾®åšæ¨é€
            "newsapp",  # æ–°é—»æ¨é€
            "notification_messages",  # æœåŠ¡é€šçŸ¥
            "helper_entry",  # æ–°ç‰ˆå¾®ä¿¡è¿åŠ¨
            "mphelper",  # å…¬ä¼—å·åŠ©æ‰‹
            "brandsessionholder",  # å…¬ä¼—å·æ¶ˆæ¯
            "weixinreminder",  # å¾®ä¿¡æé†’
            "officialaccounts",  # å…¬ä¼—å¹³å°
        ]

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç³»ç»Ÿè´¦å·
        for account in system_accounts:
            if (
                actual_sender_wxid and isinstance(actual_sender_wxid, str) and actual_sender_wxid == account
            ) or (actual_from_user_id and isinstance(actual_from_user_id, str) and actual_from_user_id == account):
                logger.debug(f"[WX859] Filter: å¿½ç•¥ç³»ç»Ÿè´¦å·æ¶ˆæ¯: {actual_sender_wxid or actual_from_user_id}")
                return True

        # 3. æ£€æµ‹å…¶ä»–ç‰¹æ®Šè´¦å·ç‰¹å¾
        # å¾®ä¿¡æ”¯ä»˜ç›¸å…³é€šçŸ¥
        if (actual_sender_wxid and isinstance(actual_sender_wxid, str) and "wxpay" in actual_sender_wxid) or (
            actual_from_user_id and isinstance(actual_from_user_id, str) and "wxpay" in actual_from_user_id
        ):
            logger.debug(f"[WX859] Filter: å¿½ç•¥å¾®ä¿¡æ”¯ä»˜ç›¸å…³æ¶ˆæ¯: {actual_sender_wxid or actual_from_user_id}")
            return True

        # è…¾è®¯æ¸¸æˆç›¸å…³é€šçŸ¥
        if (
            actual_sender_wxid
            and isinstance(actual_sender_wxid, str)
            and ("tencent" in actual_sender_wxid.lower() or "game" in actual_sender_wxid.lower())
        ) or (
            actual_from_user_id
            and isinstance(actual_from_user_id, str)
            and ("tencent" in actual_from_user_id.lower() or "game" in actual_from_user_id.lower())
        ):
            logger.debug(f"[WX859] Filter: å¿½ç•¥è…¾è®¯æ¸¸æˆç›¸å…³æ¶ˆæ¯: {actual_sender_wxid or actual_from_user_id}")
            return True

        # å…¶ä»–ç‰¹æ®Šè´¦å·ç‰¹å¾
        # å¾®ä¿¡å®˜æ–¹è´¦å·é€šå¸¸åŒ…å«"service"æˆ–"official"
        if (
            actual_sender_wxid
            and isinstance(actual_sender_wxid, str)
            and ("service" in actual_sender_wxid.lower() or "official" in actual_sender_wxid.lower())
        ) or (
            actual_from_user_id
            and isinstance(actual_from_user_id, str)
            and ("service" in actual_from_user_id.lower() or "official" in actual_from_user_id.lower())
        ):
            logger.debug(f"[WX859] Filter: å¿½ç•¥å®˜æ–¹æœåŠ¡è´¦å·æ¶ˆæ¯: {actual_sender_wxid or actual_from_user_id}")
            return True

        # 4. Ignore voice messages if speech recognition is off
        if _message_type == ContextType.VOICE:
            if conf().get("speech_recognition") != True:
                logger.debug(f"[WX859] Filter: Ignored voice message (speech recognition off): from {effective_sender_id}")
                return True

        # 5. Ignore messages from self (self.user_id should be the bot's own WXID)
        if self.user_id and effective_sender_id == self.user_id: 
            logger.debug(f"[WX859] Filter: Ignored message from myself ({self.user_id}): {_message_content_preview}")
            return True

        # 6. Ignore expired messages (e.g., older than 5 minutes)
        if _message_create_time:
            try:
                msg_ts = float(_message_create_time)
                current_ts = time.time()
                if msg_ts < (current_ts - 300):  # 300 seconds = 5 minutes
                    logger.debug(f"[WX859] Filter: Ignored expired message (timestamp: {msg_ts}) from {effective_sender_id}: {_message_content_preview}")
                    return True
            except (ValueError, TypeError):
                logger.warning(f"[WX859] Filter: Could not parse create_time '{_message_create_time}' for sender {effective_sender_id}.")
            except Exception as e: 
                logger.warning(f"[WX859] Filter: Error checking expired message for sender {effective_sender_id}: {e}")
        
        # 7. Ignore status sync messages
        if hasattr(ContextType, 'STATUS_SYNC') and _message_type == ContextType.STATUS_SYNC:
            logger.debug(f"[WX859] Filter: Ignored status sync message from {effective_sender_id}: {_message_content_preview}")
            return True
        
        # 8. Duplicate message check
        # Use effective_sender_id for the duplicate key to ensure uniqueness.
        if wx_msg and hasattr(wx_msg, 'msg_id') and wx_msg.msg_id:
            # Ensure received_msgs is initialized in WX859Channel.__init__
            # e.g., self.received_msgs = ExpiredDict(conf().get("expires_in_seconds", 3600))
            if not hasattr(self, 'received_msgs'):
                 logger.error("[WX859] Filter: self.received_msgs is not initialized. Cannot check for duplicates.")
            else:
                wx_msg_key = f"{wx_msg.msg_id}_{effective_sender_id}_{wx_msg.create_time}"
                if wx_msg_key in self.received_msgs: 
                    logger.debug(f"[WX859] Filter: Ignored duplicate message: {wx_msg_key}")
                    return True
                self.received_msgs[wx_msg_key] = wx_msg
        else:
            logger.debug("[WX859] Filter: Message lacks unique msg_id for duplicate check, proceeding with caution.")
        
        # 9. ä¸ªäººé»‘åå•è¿‡æ»¤æ£€æŸ¥
        if hasattr(self, 'single_ignore_blacklist') and self.single_ignore_blacklist:
            if actual_sender_wxid in self.single_ignore_blacklist:
                logger.debug(f"[WX859] Filter: å‘é€è€…åœ¨ä¸ªäººé»‘åå•ä¸­ï¼Œå¿½ç•¥: {actual_sender_wxid}")
                return True
        
        return False # Message passed all filters


    @_check
    async def handle_single(self, cmsg: ChatMessage):
        """å¤„ç†ç§èŠæ¶ˆæ¯"""
        try:
            # å¤„ç†æ¶ˆæ¯å†…å®¹å’Œç±»å‹
            await self._process_message(cmsg)
            
            # åªè®°å½•å…³é”®æ¶ˆæ¯ä¿¡æ¯ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
            if conf().get("log_level", "INFO") != "ERROR":
                logger.debug(f"[WX859] ç§èŠæ¶ˆæ¯ - ç±»å‹: {cmsg.ctype}, ID: {cmsg.msg_id}, å†…å®¹: {cmsg.content[:20]}...")
            
            # æ ¹æ®æ¶ˆæ¯ç±»å‹å¤„ç†
            if cmsg.ctype == ContextType.VOICE and conf().get("speech_recognition") != True:
                logger.debug("[WX859] è¯­éŸ³è¯†åˆ«åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡å¤„ç†")
                return
            
            # æ£€æŸ¥å‰ç¼€åŒ¹é…
            if cmsg.ctype == ContextType.TEXT:
                single_chat_prefix = conf().get("single_chat_prefix", [""])
                # æ—¥å¿—è®°å½•å‰ç¼€é…ç½®ï¼Œæ–¹ä¾¿è°ƒè¯•
                logger.debug(f"[WX859] å•èŠå‰ç¼€é…ç½®: {single_chat_prefix}")
                match_prefix = None
                for prefix in single_chat_prefix:
                    if prefix and cmsg.content.startswith(prefix):
                        logger.debug(f"[WX859] åŒ¹é…åˆ°å‰ç¼€: {prefix}")
                        match_prefix = prefix
                        # å»é™¤å‰ç¼€
                        cmsg.content = cmsg.content[len(prefix):].strip()
                        logger.debug(f"[WX859] å»é™¤å‰ç¼€åçš„å†…å®¹: {cmsg.content}")
                        break
                
                # è®°å½•æ˜¯å¦åŒ¹é…
                if not match_prefix and single_chat_prefix and "" not in single_chat_prefix:
                    logger.debug(f"[WX859] æœªåŒ¹é…åˆ°å‰ç¼€ï¼Œæ¶ˆæ¯è¢«è¿‡æ»¤: {cmsg.content}")
                    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å‰ç¼€ä¸”é…ç½®ä¸­æ²¡æœ‰ç©ºå‰ç¼€ï¼Œåˆ™ç›´æ¥è¿”å›ï¼Œä¸å¤„ç†è¯¥æ¶ˆæ¯
                    return
            
            # ç”Ÿæˆä¸Šä¸‹æ–‡
            context = self._compose_context(cmsg.ctype, cmsg.content, isgroup=False, msg=cmsg)
            if context:
                self.produce(context)
            else:
                logger.debug(f"[WX859] ç”Ÿæˆä¸Šä¸‹æ–‡å¤±è´¥ï¼Œè·³è¿‡å¤„ç†")
        except Exception as e:
            logger.error(f"[WX859] å¤„ç†ç§èŠæ¶ˆæ¯å¼‚å¸¸: {e}")
            if conf().get("log_level", "INFO") == "DEBUG":
                import traceback
                logger.debug(f"[WX859] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")

    @_check
    async def handle_group(self, cmsg: ChatMessage):
        """å¤„ç†ç¾¤èŠæ¶ˆæ¯"""
        try:
            # æ·»åŠ æ—¥å¿—ï¼Œè®°å½•å¤„ç†å‰çš„æ¶ˆæ¯åŸºæœ¬ä¿¡æ¯
            logger.debug(f"[WX859] å¼€å§‹å¤„ç†ç¾¤èŠæ¶ˆæ¯ - ID:{cmsg.msg_id} ç±»å‹:{cmsg.msg_type} ä»:{cmsg.from_user_id}")
            
            # å¤„ç†æ¶ˆæ¯å†…å®¹å’Œç±»å‹
            await self._process_message(cmsg)
            
            # åªè®°å½•å…³é”®æ¶ˆæ¯ä¿¡æ¯ï¼Œå‡å°‘æ—¥å¿—è¾“å‡º
            if conf().get("log_level", "INFO") != "ERROR":
                logger.debug(f"[WX859] ç¾¤èŠæ¶ˆæ¯ - ç±»å‹: {cmsg.ctype}, ç¾¤ID: {cmsg.other_user_id}")
            
            # æ ¹æ®æ¶ˆæ¯ç±»å‹å¤„ç†
            if cmsg.ctype == ContextType.VOICE and conf().get("group_speech_recognition") != True:
                logger.debug("[WX859] ç¾¤èŠè¯­éŸ³è¯†åˆ«åŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡å¤„ç†")
                return
            
            # æ£€æŸ¥ç™½åå•
            if cmsg.from_user_id and hasattr(cmsg, 'from_user_id'):
                group_white_list = conf().get("group_name_white_list", ["ALL_GROUP"])
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†ç™½åå•
                if "ALL_GROUP" not in group_white_list:
                    # è·å–ç¾¤å
                    group_name = None
                    try:
                        # ä½¿ç”¨åŒæ­¥æ–¹å¼è·å–ç¾¤åï¼Œé¿å…äº‹ä»¶å¾ªç¯åµŒå¥—
                        chatrooms_file = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp", 'wx859_rooms.json')
                        
                        if os.path.exists(chatrooms_file):
                            try:
                                with open(chatrooms_file, 'r', encoding='utf-8') as f:
                                    chatrooms_info = json.load(f)
                                
                                if cmsg.from_user_id in chatrooms_info:
                                    group_name = chatrooms_info[cmsg.from_user_id].get("nickName")
                                    if group_name:
                                        logger.debug(f"[WX859] ä»ç¼“å­˜è·å–åˆ°ç¾¤å: {group_name}")
                            except Exception as e:
                                logger.error(f"[WX859] è¯»å–ç¾¤èŠç¼“å­˜å¤±è´¥: {e}")
                        
                        # å¦‚æœæ²¡æœ‰ä»ç¼“å­˜è·å–åˆ°ç¾¤åï¼Œä½¿ç”¨ç¾¤IDä½œä¸ºå¤‡ç”¨
                        if not group_name:
                            group_name = cmsg.from_user_id
                            logger.debug(f"[WX859] æ²¡æœ‰æ‰¾åˆ°ç¾¤åï¼Œä½¿ç”¨ç¾¤ID: {group_name}")
                        
                        logger.debug(f"[WX859] ç¾¤èŠç™½åå•æ£€æŸ¥ - ç¾¤å: {group_name}")
                    except Exception as e:
                        logger.error(f"[WX859] è·å–ç¾¤åç§°å¤±è´¥: {e}")
                        group_name = cmsg.from_user_id
                    
                    # æ£€æŸ¥ç¾¤åæ˜¯å¦åœ¨ç™½åå•ä¸­
                    if group_name and group_name not in group_white_list:
                        # ä½¿ç”¨ç¾¤IDå†æ¬¡æ£€æŸ¥
                        if cmsg.from_user_id not in group_white_list:
                            logger.info(f"[WX859] ç¾¤èŠä¸åœ¨ç™½åå•ä¸­ï¼Œè·³è¿‡å¤„ç†: {group_name}")
                            return
                    
                    logger.debug(f"[WX859] ç¾¤èŠé€šè¿‡ç™½åå•æ£€æŸ¥: {group_name or cmsg.from_user_id}")
            
            # æ£€æŸ¥å‰ç¼€åŒ¹é…
            trigger_proceed = False
            if cmsg.ctype == ContextType.TEXT:
                group_chat_prefix = conf().get("group_chat_prefix", [])
                group_chat_keyword = conf().get("group_chat_keyword", [])
                
                # æ—¥å¿—è®°å½•å‰ç¼€é…ç½®ï¼Œæ–¹ä¾¿è°ƒè¯•
                logger.debug(f"[WX859] ç¾¤èŠå‰ç¼€é…ç½®: {group_chat_prefix}")
                logger.debug(f"[WX859] ç¾¤èŠå…³é”®è¯é…ç½®: {group_chat_keyword}")
                
                # MODIFIED: Enhanced prefix checking for normal and quote messages
                text_to_check_for_prefix = cmsg.content
                is_quote_with_extracted_question = False
                guide_prefix = ""
                original_user_question_in_quote = ""
                guide_suffix = "" # This will capture the quote marks and newlines after the user question

                if hasattr(cmsg, 'is_processed_text_quote') and cmsg.is_processed_text_quote:
                    # ç¡®ä¿ re æ¨¡å—åœ¨è¿™é‡Œæ˜¯å¯ç”¨çš„
                    import re # <--- åœ¨è¿™é‡Œæ˜¾å¼å¯¼å…¥ä¸€æ¬¡
                    match = re.match(r'(ç”¨æˆ·é’ˆå¯¹ä»¥ä¸‹(?:æ¶ˆæ¯|èŠå¤©è®°å½•)æé—®ï¼š")(.*?)("\n\n)', cmsg.content, re.DOTALL)
                    if match:
                        guide_prefix = match.group(1)  # "ç”¨æˆ·é’ˆå¯¹ä»¥ä¸‹æ¶ˆæ¯æé—®ï¼š""
                        original_user_question_in_quote = match.group(2) # "xyä»–è¯´ä»€ä¹ˆ"
                        guide_suffix = match.group(3)    # "\n\n"
                        text_to_check_for_prefix = original_user_question_in_quote
                        is_quote_with_extracted_question = True
                        logger.debug(f"[WX859] Quote message: Extracted text for prefix check: '{text_to_check_for_prefix}'")
                    else:
                        logger.debug(f"[WX859] Quote message format did not match extraction pattern: {cmsg.content[:100]}...")
                
                # Loop through configured prefixes
                for prefix in group_chat_prefix:
                    if prefix and text_to_check_for_prefix.startswith(prefix):
                        logger.debug(f"[WX859] Group chat matched prefix: '{prefix}' (on text: '{text_to_check_for_prefix[:50]}...')")
                        cleaned_question_content = text_to_check_for_prefix[len(prefix):].strip()
                        
                        if is_quote_with_extracted_question:
                            # Reconstruct cmsg.content with the cleaned question part, preserving the rest of the quote structure
                            # The rest of the message starts after the original full guide + question + suffix part
                            full_original_question_segment = guide_prefix + original_user_question_in_quote + guide_suffix
                            if cmsg.content.startswith(full_original_question_segment):
                                rest_of_message_after_quote_question = cmsg.content[len(full_original_question_segment):]
                                cmsg.content = guide_prefix + cleaned_question_content + guide_suffix + rest_of_message_after_quote_question
                                logger.debug(f"[WX859] Quote message, prefix removed. New content: {cmsg.content[:150]}...")
                            else:
                                # This fallback is less ideal as it might indicate an issue with segment identification
                                logger.warning(f"[WX859] Quote message content did not start as expected with extracted segments. Attempting direct replacement of user question part.")
                                # Attempt to replace only the original_user_question_in_quote part within the larger cmsg.content
                                # This is safer if the rest_of_message_after_quote_question logic is not robust enough for all cases
                                cmsg.content = cmsg.content.replace(original_user_question_in_quote, cleaned_question_content, 1)
                                logger.debug(f"[WX859] Quote message, prefix removed via replace. New content: {cmsg.content[:150]}...")
                        else:
                            # For non-quote messages, the behavior is as before
                            cmsg.content = cleaned_question_content
                            logger.debug(f"[WX859] Non-quote message, prefix removed. New content: {cmsg.content}")
                        
                        trigger_proceed = True
                        break
                
                # æ£€æŸ¥å…³é”®è¯åŒ¹é…
                if not trigger_proceed and group_chat_keyword:
                    for keyword in group_chat_keyword:
                        if keyword and keyword in cmsg.content:
                            logger.debug(f"[WX859] ç¾¤èŠåŒ¹é…åˆ°å…³é”®è¯: {keyword}")
                            trigger_proceed = True
                            break
                
                # æ£€æŸ¥æ˜¯å¦@äº†æœºå™¨äººï¼ˆå¢å¼ºç‰ˆï¼‰
                if not trigger_proceed and (cmsg.at_list or cmsg.content.find("@") >= 0):
                    logger.debug(f"[WX859] @åˆ—è¡¨: {cmsg.at_list}, æœºå™¨äººwxid: {self.wxid}")
                    
                    # æ£€æŸ¥at_listä¸­æ˜¯å¦åŒ…å«æœºå™¨äººwxid
                    at_matched = False
                    if cmsg.at_list and self.wxid in cmsg.at_list:
                        at_matched = True
                        logger.debug(f"[WX859] åœ¨at_listä¸­åŒ¹é…åˆ°æœºå™¨äººwxid: {self.wxid}")
                    
                    # å¦‚æœat_listä¸ºç©ºï¼Œæˆ–è€…at_listä¸­æ²¡æœ‰æ‰¾åˆ°æœºå™¨äººwxidï¼Œåˆ™æ£€æŸ¥æ¶ˆæ¯å†…å®¹ä¸­æ˜¯å¦ç›´æ¥åŒ…å«@æœºå™¨äººçš„æ–‡æœ¬
                    if not at_matched and cmsg.content:
                        # è·å–å¯èƒ½çš„æœºå™¨äººåç§°
                        robot_names = []
                        if self.name:
                            robot_names.append(self.name)
                        if hasattr(cmsg, 'self_display_name') and cmsg.self_display_name:
                            robot_names.append(cmsg.self_display_name)
                            
                        # æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«@æœºå™¨äººåç§°
                        for name in robot_names:
                            at_text = f"@{name}"
                            if at_text in cmsg.content:
                                at_matched = True
                                logger.debug(f"[WX859] åœ¨æ¶ˆæ¯å†…å®¹ä¸­ç›´æ¥åŒ¹é…åˆ°@æœºå™¨äºº: {at_text}")
                                break
                    
                    # å¤„ç†å¤šç§å¯èƒ½çš„@æ ¼å¼
                    if at_matched:
                        # å°è¯•ç§»é™¤ä¸åŒæ ¼å¼çš„@æ–‡æœ¬
                        original_content = cmsg.content
                        at_patterns = []
                        
                        # æ·»åŠ å¯èƒ½çš„@æ ¼å¼
                        if self.name:
                            at_patterns.extend([
                                f"@{self.name} ",  # å¸¦ç©ºæ ¼
                                f"@{self.name}\u2005",  # å¸¦ç‰¹æ®Šç©ºæ ¼
                                f"@{self.name}",  # ä¸å¸¦ç©ºæ ¼
                            ])
                        
                        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨è‡ªå®šä¹‰çš„ç¾¤å†…æ˜µç§°
                        if hasattr(cmsg, 'self_display_name') and cmsg.self_display_name:
                            at_patterns.extend([
                                f"@{cmsg.self_display_name} ",  # å¸¦ç©ºæ ¼
                                f"@{cmsg.self_display_name}\u2005",  # å¸¦ç‰¹æ®Šç©ºæ ¼
                                f"@{cmsg.self_display_name}",  # ä¸å¸¦ç©ºæ ¼
                            ])
                        
                        # æŒ‰ç…§ä¼˜å…ˆçº§å°è¯•ç§»é™¤@æ–‡æœ¬
                        for pattern in at_patterns:
                            if pattern in cmsg.content:
                                cmsg.content = cmsg.content.replace(pattern, "", 1).strip()
                                logger.debug(f"[WX859] åŒ¹é…åˆ°@æ¨¡å¼: {pattern}")
                                logger.debug(f"[WX859] å»é™¤@åçš„å†…å®¹: {cmsg.content}")
                                break
                        
                        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•@æ¨¡å¼ï¼Œä½†ç¡®å®åœ¨at_listä¸­æ‰¾åˆ°äº†æœºå™¨äººæˆ–å†…å®¹ä¸­åŒ…å«@
                        # å°è¯•ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ç§»é™¤é€šç”¨@æ ¼å¼
                        if cmsg.content == original_content and at_matched:
                            import re
                            # åŒ¹é…å½¢å¦‚"@ä»»ä½•å†…å®¹ "çš„æ¨¡å¼
                            at_pattern = re.compile(r'@[^\s]+[\s\u2005]+')
                            cmsg.content = at_pattern.sub("", cmsg.content, 1).strip()
                            logger.debug(f"[WX859] ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤@åçš„å†…å®¹: {cmsg.content}")
                        
                        trigger_proceed = True
                
                # è®°å½•æ˜¯å¦éœ€è¦å¤„ç†
                if not trigger_proceed:
                    logger.debug(f"[WX859] ç¾¤èŠæ¶ˆæ¯æœªåŒ¹é…è§¦å‘æ¡ä»¶ï¼Œè·³è¿‡å¤„ç†: {cmsg.content}")
                    return
            
            # ç”Ÿæˆä¸Šä¸‹æ–‡
            context = self._compose_context(cmsg.ctype, cmsg.content, isgroup=True, msg=cmsg)
            if context:
                self.produce(context)
            else:
                logger.debug(f"[WX859] ç”Ÿæˆç¾¤èŠä¸Šä¸‹æ–‡å¤±è´¥ï¼Œè·³è¿‡å¤„ç†")
        except Exception as e:
            error_msg = str(e)
            # æ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯æ—¥å¿—ä¿¡æ¯
            logger.error(f"[WX859] å¤„ç†ç¾¤èŠæ¶ˆæ¯å¼‚å¸¸: {error_msg}")
            logger.error(f"[WX859] æ¶ˆæ¯å†…å®¹: {getattr(cmsg, 'content', 'æœªçŸ¥')[:100]}")
            logger.error(f"[WX859] æ¶ˆæ¯ç±»å‹: {getattr(cmsg, 'msg_type', 'æœªçŸ¥')}")
            logger.error(f"[WX859] ä¸Šä¸‹æ–‡ç±»å‹: {getattr(cmsg, 'ctype', 'æœªçŸ¥')}")
            
            # è®°å½•å®Œæ•´çš„å¼‚å¸¸å †æ ˆ
            import traceback
            logger.error(f"[WX859] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")

    async def _process_message(self, cmsg):
        """å¤„ç†æ¶ˆæ¯å†…å®¹å’Œç±»å‹"""
        # å¤„ç†æ¶ˆæ¯ç±»å‹
        msg_type = cmsg.msg_type
        if not msg_type and "Type" in cmsg.msg:
            msg_type = cmsg.msg["Type"]
        
        # å°è¯•è·å–æœºå™¨äººåœ¨ç¾¤å†…çš„æ˜µç§°
        if cmsg.is_group and not cmsg.self_display_name:
            try:
                # ä»ç¼“å­˜ä¸­æŸ¥è¯¢ç¾¤æˆå‘˜è¯¦æƒ…
                tmp_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp")
                chatrooms_file = os.path.join(tmp_dir, 'wx859_rooms.json')
                
                if os.path.exists(chatrooms_file):
                    try:
                        with open(chatrooms_file, 'r', encoding='utf-8') as f:
                            chatrooms_info = json.load(f)
                        
                        if cmsg.from_user_id in chatrooms_info:
                            room_info = chatrooms_info[cmsg.from_user_id]
                            
                            # åœ¨æˆå‘˜ä¸­æŸ¥æ‰¾æœºå™¨äººçš„ä¿¡æ¯
                            if "members" in room_info and isinstance(room_info["members"], list):
                                for member in room_info["members"]:
                                    if member.get("UserName") == self.wxid:
                                        # ä¼˜å…ˆä½¿ç”¨ç¾¤å†…æ˜¾ç¤ºåç§°
                                        if member.get("DisplayName"):
                                            cmsg.self_display_name = member.get("DisplayName")
                                            logger.debug(f"[WX859] ä»ç¾¤æˆå‘˜ç¼“å­˜ä¸­è·å–åˆ°æœºå™¨äººç¾¤å†…æ˜µç§°: {cmsg.self_display_name}")
                                            break
                                        # å…¶æ¬¡ä½¿ç”¨æ˜µç§°
                                        elif member.get("NickName"):
                                            cmsg.self_display_name = member.get("NickName")
                                            logger.debug(f"[WX859] ä»ç¾¤æˆå‘˜ç¼“å­˜ä¸­è·å–åˆ°æœºå™¨äººæ˜µç§°: {cmsg.self_display_name}")
                                            break
                    except Exception as e:
                        logger.error(f"[WX859] è¯»å–ç¾¤æˆå‘˜ç¼“å­˜å¤±è´¥: {e}")
                
                # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨æœºå™¨äººåç§°
                if not cmsg.self_display_name:
                    cmsg.self_display_name = self.name
                    logger.debug(f"[WX859] ä½¿ç”¨æœºå™¨äººåç§°ä½œä¸ºç¾¤å†…æ˜µç§°: {cmsg.self_display_name}")
            except Exception as e:
                logger.error(f"[WX859] è·å–æœºå™¨äººç¾¤å†…æ˜µç§°å¤±è´¥: {e}")
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹è¿›è¡Œå¤„ç†
        if msg_type in [1, "1", "Text"]:
            self._process_text_message(cmsg)
        elif msg_type in [3, "3", "Image"]:
            await self._process_image_message(cmsg)
        elif msg_type in [6, "6", "File"]:
            await self._process_file_message(cmsg)
        elif msg_type in [34, "34", "Voice"]:
            self._process_voice_message(cmsg)
        elif msg_type in [43, "43", "Video"]:
            self._process_video_message(cmsg)
        elif msg_type in [47, "47", "Emoji"]:
            self._process_emoji_message(cmsg)
        elif msg_type in [49, "49", "App"]:
            self._process_xml_message(cmsg)
        elif msg_type in [10000, "10000", "System"]:
            self._process_system_message(cmsg)
        else:
            # æ£€æŸ¥æ˜¯å¦ä¸ºå†—é•¿çš„ç³»ç»Ÿé…ç½®æ¶ˆæ¯ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥å¿½ç•¥
            if (isinstance(cmsg.content, str) and 
                len(cmsg.content) > 1000 and  # åªè¿‡æ»¤è¶…é•¿æ¶ˆæ¯
                (cmsg.content.startswith('<sysmsg type="dynacfg">') or 
                 cmsg.content.startswith('<sysmsg type="functionmsg">'))):
                logger.debug(f"[WX859] æ”¶åˆ°å†—é•¿ç³»ç»Ÿé…ç½®æ¶ˆæ¯ï¼Œå·²å¿½ç•¥: ç±»å‹={msg_type}")
                return  # ç›´æ¥è¿”å›ï¼Œä¸å¤„ç†æ­¤ç±»æ¶ˆæ¯
            
            # é»˜è®¤ç±»å‹å¤„ç†
            cmsg.ctype = ContextType.UNKNOWN
            logger.warning(f"[WX859] æœªçŸ¥æ¶ˆæ¯ç±»å‹: {msg_type}, å†…å®¹: {cmsg.content[:100]}")
        
        # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦æ¥è‡ªç¾¤èŠ
        if cmsg.is_group or cmsg.from_user_id.endswith("@chatroom"):
            # å¢å¼ºçš„ç¾¤æ¶ˆæ¯å‘é€è€…æå–é€»è¾‘
            # å°è¯•å¤šç§å¯èƒ½çš„æ ¼å¼è§£æå‘é€è€…ä¿¡æ¯
            sender_extracted = False
            
            # æ–¹æ³•1: å°è¯•è§£æå®Œæ•´çš„æ ¼å¼ "wxid:\næ¶ˆæ¯å†…å®¹"
            split_content = cmsg.content.split(":\n", 1)
            if len(split_content) > 1 and split_content[0] and not split_content[0].startswith("<"):
                cmsg.sender_wxid = split_content[0]
                cmsg.content = split_content[1]
                sender_extracted = True
                logger.debug(f"[WX859] ç¾¤èŠå‘é€è€…æå–(æ–¹æ³•1): {cmsg.sender_wxid}")
            
            # æ–¹æ³•3: å°è¯•ä»å›å¤XMLä¸­æå–
            if not sender_extracted and cmsg.content and cmsg.content.startswith("<"):
                try:
                    # è§£æXMLå†…å®¹
                    root = ET.fromstring(cmsg.content)
                    
                    # æŸ¥æ‰¾ä¸åŒç±»å‹çš„XMLä¸­å¯èƒ½å­˜åœ¨çš„å‘é€è€…ä¿¡æ¯
                    if root.tag == "msg":
                        # å¸¸è§çš„XMLæ¶ˆæ¯æ ¼å¼
                        sender_node = root.find(".//username")
                        if sender_node is not None and sender_node.text:
                            cmsg.sender_wxid = sender_node.text
                            sender_extracted = True
                            logger.debug(f"[WX859] ç¾¤èŠå‘é€è€…ä»XMLæå–: {cmsg.sender_wxid}")
                        
                        # å°è¯•å…¶ä»–å¯èƒ½çš„æ ‡ç­¾
                        if not sender_extracted:
                            for tag in ["fromusername", "sender", "from"]:
                                sender_node = root.find(f".//{tag}")
                                if sender_node is not None and sender_node.text:
                                    cmsg.sender_wxid = sender_node.text
                                    sender_extracted = True
                                    logger.debug(f"[WX859] ç¾¤èŠå‘é€è€…ä»XML({tag})æå–: {cmsg.sender_wxid}")
                                    break
                except Exception as e:
                    logger.error(f"[WX859] ä»XMLæå–ç¾¤èŠå‘é€è€…å¤±è´¥: {e}")
            
            # æ–¹æ³•4: å°è¯•ä»å…¶å®ƒå­—æ®µæå–
            if not sender_extracted:
                for key in ["SenderUserName", "sender", "senderId", "fromUser"]:
                    if key in cmsg.msg and cmsg.msg[key]:
                        cmsg.sender_wxid = str(cmsg.msg[key])
                        sender_extracted = True
                        logger.debug(f"[WX859] ç¾¤èŠå‘é€è€…ä»å­—æ®µæå–({key}): {cmsg.sender_wxid}")
                        break
            
            # å¦‚æœä»ç„¶æ— æ³•æå–ï¼Œè®¾ç½®ä¸ºé»˜è®¤å€¼ä½†ä¸è¦ç•™ç©º
            if not sender_extracted or not cmsg.sender_wxid:
                cmsg.sender_wxid = f"æœªçŸ¥ç”¨æˆ·_{cmsg.from_user_id}"
                logger.debug(f"[WX859] æ— æ³•æå–ç¾¤èŠå‘é€è€…ï¼Œä½¿ç”¨é»˜è®¤å€¼: {cmsg.sender_wxid}")
            
            # è®¾ç½®other_user_idä¸ºç¾¤IDï¼Œç¡®ä¿å®ƒä¸ä¸ºNone
            cmsg.other_user_id = cmsg.from_user_id
            
            # è®¾ç½®actual_user_idä¸ºå‘é€è€…wxid
            cmsg.actual_user_id = cmsg.sender_wxid
            
            # å¼‚æ­¥è·å–å‘é€è€…æ˜µç§°å¹¶è®¾ç½®actual_user_nickname
            # ä½†ç°åœ¨æˆ‘ä»¬æ— æ³•åœ¨åŒæ­¥æ–¹æ³•ä¸­ç›´æ¥è°ƒç”¨å¼‚æ­¥æ–¹æ³•ï¼Œæ‰€ä»¥å…ˆä½¿ç”¨wxid
            cmsg.actual_user_nickname = cmsg.sender_wxid
            
            # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡è·å–æ˜µç§°å¹¶æ›´æ–°actual_user_nickname
            threading.Thread(target=lambda: asyncio.run(self._update_nickname_async(cmsg))).start()
            
            logger.debug(f"[WX859] è®¾ç½®å®é™…å‘é€è€…ä¿¡æ¯: actual_user_id={cmsg.actual_user_id}, actual_user_nickname={cmsg.actual_user_nickname}")
        else:
            # ç§èŠæ¶ˆæ¯
            cmsg.sender_wxid = cmsg.from_user_id
            cmsg.is_group = False
            
            # ç§èŠæ¶ˆæ¯ä¹Ÿè®¾ç½®actual_user_idå’Œactual_user_nickname
            cmsg.actual_user_id = cmsg.from_user_id
            cmsg.actual_user_nickname = cmsg.from_user_id
            logger.debug(f"[WX859] è®¾ç½®ç§èŠå‘é€è€…ä¿¡æ¯: actual_user_id={cmsg.actual_user_id}, actual_user_nickname={cmsg.actual_user_nickname}")

    async def _update_nickname_async(self, cmsg):
        """å¼‚æ­¥æ›´æ–°æ¶ˆæ¯ä¸­çš„æ˜µç§°ä¿¡æ¯"""
        if cmsg.is_group and cmsg.from_user_id.endswith("@chatroom"):
            nickname = await self._get_chatroom_member_nickname(cmsg.from_user_id, cmsg.sender_wxid)
            if nickname and nickname != cmsg.actual_user_nickname:
                cmsg.actual_user_nickname = nickname
                logger.debug(f"[WX859] å¼‚æ­¥æ›´æ–°äº†å‘é€è€…æ˜µç§°: {nickname}")

    def _process_text_message(self, cmsg):
        """å¤„ç†æ–‡æœ¬æ¶ˆæ¯"""
        import xml.etree.ElementTree as ET
        
        cmsg.ctype = ContextType.TEXT
        
        # ğŸ”¥ æ³¨æ„ï¼šå‘é€è€…ä¿¡æ¯å·²ç»åœ¨_process_messageæ–¹æ³•ä¸­å¤„ç†è¿‡äº†ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤å¤„ç†
        # åªéœ€è¦ç¡®ä¿ç¾¤èŠæ¶ˆæ¯çš„æ ‡è¯†æ­£ç¡®
        if cmsg.is_group or cmsg.from_user_id.endswith("@chatroom"):
            cmsg.is_group = True
            # å‘é€è€…ä¿¡æ¯å·²ç»åœ¨_process_messageä¸­è®¾ç½®ï¼Œè¿™é‡Œä¸é‡å¤å¤„ç†
            logger.debug(f"[WX859] ç¾¤èŠæ–‡æœ¬æ¶ˆæ¯ï¼Œå‘é€è€…: {cmsg.sender_wxid}")
        else:
            # ç§èŠæ¶ˆæ¯
            cmsg.is_group = False
            logger.debug(f"[WX859] ç§èŠæ–‡æœ¬æ¶ˆæ¯ï¼Œå‘é€è€…: {cmsg.sender_wxid}")
        
        # è§£æ@ä¿¡æ¯ - å¤šç§æ–¹å¼è§£æ
        try:
            # æ–¹æ³•1: ä»MsgSourceè§£æ
            msg_source = cmsg.msg.get("MsgSource", "")
            if msg_source:
                try:
                    if "<msgsource>" not in msg_source.lower():
                        msg_source = f"<msgsource>{msg_source}</msgsource>"
                    root = ET.fromstring(msg_source)
                    ats_elem = root.find(".//atuserlist")
                    if ats_elem is not None and ats_elem.text:
                        cmsg.at_list = [x for x in ats_elem.text.strip(",").split(",") if x]
                        logger.debug(f"[WX859] ä»MsgSourceè§£æåˆ°@åˆ—è¡¨: {cmsg.at_list}")
                except Exception as e:
                    logger.debug(f"[WX859] ä»MsgSourceè§£æ@åˆ—è¡¨å¤±è´¥: {e}")
            
            # æ–¹æ³•2: ä»å…¶ä»–å­—æ®µè§£æ
            if not cmsg.at_list:
                for key in ["AtUserList", "at_list", "atlist"]:
                    if key in cmsg.msg:
                        at_value = cmsg.msg[key]
                        if isinstance(at_value, list):
                            cmsg.at_list = [str(x) for x in at_value if x]
                        elif isinstance(at_value, str):
                            cmsg.at_list = [x for x in at_value.strip(",").split(",") if x]
                        
                        if cmsg.at_list:
                            logger.debug(f"[WX859] ä»å­—æ®µ{key}è§£æåˆ°@åˆ—è¡¨: {cmsg.at_list}")
                            break
            
            # æ–¹æ³•3: ä»æ¶ˆæ¯å†…å®¹ä¸­æ£€æµ‹@æœºå™¨äºº
            if cmsg.is_group and not cmsg.at_list and "@" in cmsg.content:
                # å¦‚æœæœºå™¨äººæœ‰åç§°æˆ–ç¾¤å†…æ˜µç§°ï¼Œæ£€æŸ¥æ˜¯å¦è¢«@
                if self.name and f"@{self.name}" in cmsg.content:
                    # æ¨¡æ‹Ÿæ·»åŠ è‡ªå·±åˆ°at_list
                    cmsg.at_list.append(self.wxid)
                    logger.debug(f"[WX859] ä»æ¶ˆæ¯å†…å®¹æ£€æµ‹åˆ°@æœºå™¨äººåç§°: {self.name}")
                elif hasattr(cmsg, 'self_display_name') and cmsg.self_display_name and f"@{cmsg.self_display_name}" in cmsg.content:
                    # æ¨¡æ‹Ÿæ·»åŠ è‡ªå·±åˆ°at_list
                    cmsg.at_list.append(self.wxid)
                    logger.debug(f"[WX859] ä»æ¶ˆæ¯å†…å®¹æ£€æµ‹åˆ°@æœºå™¨äººç¾¤å†…æ˜µç§°: {cmsg.self_display_name}")
        except Exception as e:
            logger.debug(f"[WX859] è§£æ@åˆ—è¡¨å¤±è´¥: {e}")
            cmsg.at_list = []
        
        # ç¡®ä¿at_listä¸ä¸ºç©ºåˆ—è¡¨
        if not cmsg.at_list or (len(cmsg.at_list) == 1 and cmsg.at_list[0] == ""):
            cmsg.at_list = []
        
        # è¾“å‡ºæ—¥å¿—
        logger.info(f"æ”¶åˆ°æ–‡æœ¬æ¶ˆæ¯: ID:{cmsg.msg_id} æ¥è‡ª:{cmsg.from_user_id} å‘é€äºº:{cmsg.sender_wxid} @:{cmsg.at_list} å†…å®¹:{cmsg.content}")

    async def _process_image_message(self, cmsg: WX859Message): # Added WX859Message type hint
        """å¤„ç†å›¾ç‰‡æ¶ˆæ¯"""
        import xml.etree.ElementTree as ET
        import os

        import time
        # import threading # Not used directly in this snippet
        import traceback # Added for logging
        from bridge.context import ContextType # Added for ContextType

        # åœ¨è¿™é‡Œä¸æ£€æŸ¥å’Œæ ‡è®°å›¾ç‰‡æ¶ˆæ¯ï¼Œè€Œæ˜¯åœ¨å›¾ç‰‡ä¸‹è½½å®Œæˆåå†æ ‡è®°
        # è¿™æ ·å¯ä»¥ç¡®ä¿å›¾ç‰‡æ¶ˆæ¯è¢«æ­£ç¡®å¤„ç†ä¸ºIMAGEç±»å‹ï¼Œè€Œä¸æ˜¯UNKNOWNç±»å‹

        cmsg.ctype = ContextType.IMAGE

        # ğŸ”¥ æ³¨æ„ï¼šå‘é€è€…ä¿¡æ¯å·²ç»åœ¨_process_messageæ–¹æ³•ä¸­å¤„ç†è¿‡äº†ï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤å¤„ç†
        # åªéœ€è¦ç¡®ä¿ç¾¤èŠæ¶ˆæ¯çš„æ ‡è¯†æ­£ç¡®
        if cmsg.is_group or (hasattr(cmsg, 'from_user_id') and cmsg.from_user_id and cmsg.from_user_id.endswith("@chatroom")):
            cmsg.is_group = True # Ensure is_group is set
            # å‘é€è€…ä¿¡æ¯å·²ç»åœ¨_process_messageä¸­è®¾ç½®ï¼Œè¿™é‡Œä¸é‡å¤å¤„ç†
            logger.debug(f"[WX859] ç¾¤èŠå›¾ç‰‡æ¶ˆæ¯ï¼Œå‘é€è€…: {cmsg.sender_wxid}")
            
            # å¯¹äºå›¾ç‰‡æ¶ˆæ¯ï¼Œéœ€è¦ä»contentä¸­æå–XMLéƒ¨åˆ†
            if isinstance(cmsg.content, str) and ":\n" in cmsg.content:
                split_content = cmsg.content.split(":\n", 1)
                if len(split_content) > 1:
                    # ä¿ç•™XMLéƒ¨åˆ†ä½œä¸ºcontent
                    cmsg.content = split_content[1]
                    logger.debug(f"[WX859] ä»ç¾¤èŠå›¾ç‰‡æ¶ˆæ¯ä¸­æå–XMLå†…å®¹")
        else:
            # ç§èŠæ¶ˆæ¯
            cmsg.is_group = False
            logger.debug(f"[WX859] ç§èŠå›¾ç‰‡æ¶ˆæ¯ï¼Œå‘é€è€…: {cmsg.sender_wxid}")

        # è§£æå›¾ç‰‡ä¿¡æ¯
        try:
            xml_content_to_parse = ""
            if isinstance(cmsg.content, str) and (cmsg.content.startswith('<?xml') or cmsg.content.startswith("<msg>")):
                xml_content_to_parse = cmsg.content
            # Add handling if cmsg.content might be bytes that need decoding
            elif isinstance(cmsg.content, bytes):
                try:
                    xml_content_to_parse = cmsg.content.decode('utf-8')
                    if not (xml_content_to_parse.startswith('<?xml') or xml_content_to_parse.startswith("<msg>")):
                        xml_content_to_parse = "" # Not valid XML
                except UnicodeDecodeError:
                    logger.warning(f"[{self.name}] Msg {cmsg.msg_id}: Image content is bytes but failed to decode as UTF-8.")
                    xml_content_to_parse = ""

            if xml_content_to_parse:
                try:
                    root = ET.fromstring(xml_content_to_parse)
                    img_element = root.find('img')
                    if img_element is not None:
                        # MODIFICATION START: Store aeskey and other info on cmsg directly
                        cmsg.img_aeskey = img_element.get('aeskey')
                        cmsg.img_cdnthumbaeskey = img_element.get('cdnthumbaeskey') # Optional
                        cmsg.img_md5 = img_element.get('md5') # Optional
                        cmsg.img_length = img_element.get('length', '0')
                        cmsg.img_cdnmidimgurl = img_element.get('cdnmidimgurl', '')
                        # MODIFICATION END

                        # Use a combined dictionary for logging for clarity
                        cmsg.image_info = {
                            'aeskey': cmsg.img_aeskey,
                            'cdnmidimgurl': cmsg.img_cdnmidimgurl,
                            'length': cmsg.img_length,
                            'md5': cmsg.img_md5
                        }
                        logger.debug(f"[{self.name}] Msg {cmsg.msg_id}: Parsed image XML: aeskey={cmsg.img_aeskey}, length={cmsg.img_length}, md5={cmsg.img_md5}")
                        
                        if not cmsg.img_aeskey:
                             logger.warning(f"[{self.name}] Msg {cmsg.msg_id}: Image XML 'aeskey' is missing. Caching by aeskey will not be possible.")
                    else:
                        logger.warning(f"[{self.name}] Msg {cmsg.msg_id}: XML in content but no <img> tag found. Content (first 100): {xml_content_to_parse[:100]}")
                        # Initialize attributes on cmsg to prevent AttributeError later
                        cmsg.img_aeskey = None
                        cmsg.img_length = '0'
                        # Create a default image_info for compatibility if other parts expect it
                        cmsg.image_info = {'aeskey': '', 'cdnmidimgurl': '', 'length': '0', 'md5': ''}
                except ET.ParseError as xml_err:
                    logger.warning(f"[{self.name}] Msg {cmsg.msg_id}: Failed to parse image XML: {xml_err}. Content (first 100): {xml_content_to_parse[:100]}")
                    cmsg.img_aeskey = None
                    cmsg.img_length = '0'
                    cmsg.image_info = {'aeskey': '', 'cdnmidimgurl': '', 'length': '0', 'md5': ''}
            else:
                # Content is not XML (could be a path if already processed by another layer, or unexpected format)
                logger.warning(f"[{self.name}] Msg {cmsg.msg_id}: Image content is not XML. Content (first 100): {str(cmsg.content)[:100]}")
                cmsg.img_aeskey = None # Ensure it's defined
                cmsg.img_length = '0'
                cmsg.image_info = {'aeskey': '', 'cdnmidimgurl': '', 'length': '0', 'md5': ''} # Default

            # Download logic (largely from your snippet)
            # Check if image_path is already set and valid
            if hasattr(cmsg, 'image_path') and cmsg.image_path and os.path.exists(cmsg.image_path):
                logger.info(f"[{self.name}] Msg {cmsg.msg_id}: Image already exists at path: {cmsg.image_path}")
            else:

                locks_tmp_dir = os.path.join(os.path.dirname(self.image_cache_dir) if hasattr(self, 'image_cache_dir') else os.path.join(os.getcwd(), "tmp"), "img_locks")

                try:
                    os.makedirs(locks_tmp_dir, exist_ok=True)
                except Exception as e_mkdir:
                     logger.error(f"[{self.name}] Failed to create lock directory {locks_tmp_dir}: {e_mkdir}")
                     # Potentially skip download if lock dir cannot be made, or try without lock

                lock_file = os.path.join(locks_tmp_dir, f"img_{cmsg.msg_id}.lock")

                if os.path.exists(lock_file):
                    # Check lock file age, could be stale
                    try:
                        lock_time = os.path.getmtime(lock_file)
                        if (time.time() - lock_time) < 300: # 5-minute timeout for stale lock
                            logger.info(f"[{self.name}] Image {cmsg.msg_id} is likely being downloaded by another thread (lock active). Skipping.")
                            return # Skip if lock is recent
                        else:
                            logger.warning(f"[{self.name}] Image {cmsg.msg_id} lock file is stale. Removing and attempting download.")
                            os.remove(lock_file)
                    except Exception as e_lock_check:
                        logger.warning(f"[{self.name}] Error checking stale lock for {cmsg.msg_id}: {e_lock_check}. Proceeding with caution.")
                
                download_attempted = False
                try:
                    # Create lock file
                    with open(lock_file, "w") as f:
                        f.write(str(time.time()))
                    
                    download_attempted = True
                    logger.info(f"[{self.name}] Msg {cmsg.msg_id}: Attempting to download image.")
                    # Asynchronously download the image
                    # _download_image should set cmsg.image_path upon success
                    await self._download_image(cmsg) 
                    
                except Exception as e:
                    logger.error(f"[{self.name}] Msg {cmsg.msg_id}: Failed to download image: {e}")
                    logger.error(traceback.format_exc())
                finally:
                    if download_attempted: # Only remove lock if we attempted to create it
                        try:
                            if os.path.exists(lock_file):
                                os.remove(lock_file)
                        except Exception as e:
                            logger.error(f"[{self.name}] Msg {cmsg.msg_id}: Failed to remove lock file {lock_file}: {e}")
        
        except Exception as e_outer: # Catch errors in the outer XML parsing/setup
            logger.error(f"[{self.name}] Msg {cmsg.msg_id}: Major error in _process_image_message: {e_outer}")
            logger.error(traceback.format_exc())
            # Ensure default attributes if parsing failed badly
            if not hasattr(cmsg, 'img_aeskey'): cmsg.img_aeskey = None
            if not hasattr(cmsg, 'image_info'):
                cmsg.image_info = {'aeskey': '', 'cdnmidimgurl': '', 'length': '0', 'md5': ''}


        # This logging and recent_image_msgs update should happen regardless of download success
        # as the message itself was an image message.
        logger.info(f"[{self.name}] Processed image message (ID:{cmsg.msg_id} From:{cmsg.from_user_id} Sender:{cmsg.sender_wxid})")

        # Record recently received image messages
        # Ensure actual_user_id is set for session_id
        session_user_id = cmsg.actual_user_id if hasattr(cmsg, 'actual_user_id') and cmsg.actual_user_id else cmsg.from_user_id

        # Use self.received_msgs or a dedicated dict for image contexts for plugins
        # self.recent_image_msgs was initialized in __init__
        if hasattr(self, 'recent_image_msgs') and session_user_id:
            self.recent_image_msgs[session_user_id] = cmsg # Store the WX859Message object
            logger.info(f"[{self.name}] Recorded image message context for session {session_user_id} (MsgID: {cmsg.msg_id}).")


        # Final check and update of cmsg properties if image was successfully downloaded and path is set
        if hasattr(cmsg, 'image_path') and cmsg.image_path and os.path.exists(cmsg.image_path):
            cmsg.content = cmsg.image_path # Update content to be the path
            cmsg.ctype = ContextType.IMAGE # Ensure ctype is IMAGE
            logger.info(f"[{self.name}] Msg {cmsg.msg_id}: Final image path set to: {cmsg.image_path}")
        else:
            logger.warning(f"[{self.name}] Msg {cmsg.msg_id}: Image path not available after processing. Image download might have failed or was skipped.")

    async def _process_file_message(self, cmsg: 'WX859Message'):
        """
        å¤„ç†æ–‡ä»¶æ¶ˆæ¯
        å‚è€ƒswagger.jsonä¸­çš„æ–‡ä»¶ç›¸å…³APIæ¥å£
        """
        try:
            logger.info(f"[WX859] å¼€å§‹å¤„ç†æ–‡ä»¶æ¶ˆæ¯: {cmsg.msg_id}")
            
            # è§£ææ–‡ä»¶æ¶ˆæ¯çš„XMLå†…å®¹
            file_info = self._parse_file_xml(cmsg.content)
            if not file_info:
                logger.error(f"[WX859] æ— æ³•è§£ææ–‡ä»¶æ¶ˆæ¯XML: {cmsg.content}")
                return
            
            # è®¾ç½®æ¶ˆæ¯ç±»å‹ä¸ºæ–‡ä»¶
            cmsg.ctype = ContextType.FILE
            
            # æ„å»ºæ–‡ä»¶ä¿¡æ¯å­—ç¬¦ä¸²ä½œä¸ºcontent
            filename = file_info.get('filename', 'Unknown')
            filesize_str = file_info.get('filesize_str', 'Unknown')
            file_ext = file_info.get('file_ext', 'unknown')
            
            # å°†æ–‡ä»¶ä¿¡æ¯å­˜å‚¨åˆ°æ¶ˆæ¯å¯¹è±¡ä¸­
            cmsg.file_info = file_info
            cmsg.content = f"[æ–‡ä»¶] {filename} ({filesize_str})"
            
            # å¤„ç†ç¾¤èŠæ¶ˆæ¯çš„å‘é€è€…ä¿¡æ¯
            if cmsg.is_group or (hasattr(cmsg, 'from_user_id') and cmsg.from_user_id and cmsg.from_user_id.endswith("@chatroom")):
                cmsg.is_group = True
                logger.debug(f"[WX859] ç¾¤èŠæ–‡ä»¶æ¶ˆæ¯ï¼Œå‘é€è€…: {cmsg.sender_wxid}")
            else:
                cmsg.is_group = False
                logger.debug(f"[WX859] ç§èŠæ–‡ä»¶æ¶ˆæ¯ï¼Œå‘é€è€…: {cmsg.sender_wxid}")
            
            logger.info(f"[WX859] æ–‡ä»¶æ¶ˆæ¯å¤„ç†å®Œæˆ: ID:{cmsg.msg_id} æ¥è‡ª:{cmsg.from_user_id} å‘é€äºº:{cmsg.sender_wxid} æ–‡ä»¶:{filename}")
                
        except Exception as e:
            logger.error(f"[WX859] å¤„ç†æ–‡ä»¶æ¶ˆæ¯å¤±è´¥: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    def _parse_file_xml(self, xml_content: str) -> dict:
        """
        è§£ææ–‡ä»¶æ¶ˆæ¯çš„XMLå†…å®¹
        æå–æ–‡ä»¶åã€å¤§å°ã€ä¸‹è½½é“¾æ¥ç­‰ä¿¡æ¯
        """
        try:
            import xml.etree.ElementTree as ET
            
            if not xml_content or not xml_content.strip():
                logger.warning("[WX859] æ–‡ä»¶æ¶ˆæ¯XMLå†…å®¹ä¸ºç©º")
                return {}
            
            # è§£æXML
            root = ET.fromstring(xml_content)
            
            file_info = {}
            
            # æå–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
            appmsg = root.find('.//appmsg')
            if appmsg is not None:
                # æ–‡ä»¶æ ‡é¢˜/åç§°
                title = appmsg.find('title')
                if title is not None and title.text:
                    file_info['filename'] = title.text
                
                # æ–‡ä»¶æè¿°
                des = appmsg.find('des')
                if des is not None and des.text:
                    file_info['description'] = des.text
                
                # æ–‡ä»¶ç±»å‹
                type_elem = appmsg.find('type')
                if type_elem is not None and type_elem.text:
                    file_info['type'] = type_elem.text
            
            # æå–æ–‡ä»¶é™„ä»¶ä¿¡æ¯
            appattach = root.find('.//appattach')
            if appattach is not None:
                # æ–‡ä»¶å¤§å°
                totallen = appattach.find('totallen')
                if totallen is not None and totallen.text:
                    try:
                        file_info['filesize'] = int(totallen.text)
                        file_info['filesize_str'] = self._format_file_size(int(totallen.text))
                    except ValueError:
                        file_info['filesize_str'] = totallen.text
                
                # é™„ä»¶IDï¼ˆç”¨äºä¸‹è½½ï¼‰
                attachid = appattach.find('attachid')
                if attachid is not None and attachid.text:
                    file_info['attach_id'] = attachid.text
                
                # æ–‡ä»¶æ‰©å±•å
                fileext = appattach.find('fileext')
                if fileext is not None and fileext.text:
                    file_info['file_ext'] = fileext.text
            
            # æå–CDNä¿¡æ¯ï¼ˆç”¨äºä¸‹è½½ï¼‰
            for cdn_field in ['cdnattachurl', 'cdnthumburl', 'aeskey']:
                elem = root.find(f'.//{cdn_field}')
                if elem is not None and elem.text:
                    file_info[cdn_field] = elem.text
            
            # å¦‚æœæ²¡æœ‰æ–‡ä»¶åï¼Œå°è¯•ä»å…¶ä»–å­—æ®µè·å–
            if 'filename' not in file_info:
                # å°è¯•ä»deså­—æ®µè·å–
                if 'description' in file_info:
                    file_info['filename'] = file_info['description']
                # æˆ–è€…ä½¿ç”¨é»˜è®¤åç§°
                else:
                    ext = file_info.get('file_ext', 'unknown')
                    file_info['filename'] = f"æ–‡ä»¶.{ext}"
            
            # æ·»åŠ åŸå§‹XMLå†…å®¹
            file_info['xml_content'] = xml_content
            
            logger.debug(f"[WX859] è§£ææ–‡ä»¶ä¿¡æ¯æˆåŠŸ: {file_info}")
            return file_info
            
        except ET.ParseError as e:
            logger.error(f"[WX859] è§£ææ–‡ä»¶XMLå¤±è´¥: {e}")
            logger.error(f"[WX859] XMLå†…å®¹: {xml_content}")
            return {}
        except Exception as e:
            logger.error(f"[WX859] è§£ææ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return {}

    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        try:
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            elif size_bytes < 1024 * 1024 * 1024:
                return f"{size_bytes / (1024 * 1024):.1f} MB"
            else:
                return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"
        except:
            return str(size_bytes)

    async def download_file_with_cache_check(self, attach_id: str, file_name: str = None) -> dict:
        """
        ğŸ”¥ ä¼˜åŒ–çš„æ–‡ä»¶ä¸‹è½½æ–¹æ³•ï¼Œæ”¯æŒç¼“å­˜æ£€æŸ¥å’Œé‡å¤ä¸‹è½½é˜²æŠ¤
        
        Args:
            attach_id (str): é™„ä»¶ID
            file_name (str): æ–‡ä»¶åï¼ˆå¯é€‰ï¼Œç”¨äºä¿å­˜ï¼‰
            
        Returns:
            dict: ä¸‹è½½ç»“æœï¼ŒåŒ…å«æ–‡ä»¶æ•°æ®æˆ–é”™è¯¯ä¿¡æ¯
        """
        try:
            if not attach_id:
                return {"success": False, "error": "é™„ä»¶IDä¸èƒ½ä¸ºç©º"}
            
            # ğŸ”¥ ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­
            if self._download_cache_check_enabled:
                cached_result = await self._check_file_cache(attach_id, file_name)
                if cached_result:
                    logger.info(f"[WX859] æ–‡ä»¶ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥ä½¿ç”¨: {cached_result.get('cached_filename', 'unknown')}")
                    return cached_result
            
            # ğŸ”¥ ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥æ˜¯å¦å·²æœ‰ç›¸åŒæ–‡ä»¶æ­£åœ¨ä¸‹è½½ï¼ˆä¸‹è½½é”æœºåˆ¶ï¼‰
            if attach_id in self._download_locks:
                logger.info(f"[WX859] æ–‡ä»¶æ­£åœ¨ä¸‹è½½ä¸­ï¼Œç­‰å¾…å®Œæˆ: {attach_id}")
                try:
                    # ç­‰å¾…å…¶ä»–ä¸‹è½½å®Œæˆ
                    await self._download_locks[attach_id]
                    # ä¸‹è½½å®Œæˆåï¼Œå†æ¬¡å°è¯•ä»ç¼“å­˜è·å–
                    cached_result = await self._check_file_cache(attach_id, file_name)
                    if cached_result:
                        logger.info(f"[WX859] ç­‰å¾…ä¸‹è½½å®Œæˆåä»ç¼“å­˜è·å–: {cached_result.get('cached_filename', 'unknown')}")
                        return cached_result
                except Exception as e:
                    logger.warning(f"[WX859] ç­‰å¾…ä¸‹è½½å®Œæˆæ—¶å‡ºé”™: {e}")
            
            # ğŸ”¥ ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œå®é™…ä¸‹è½½
            return await self._do_download_file_with_lock(attach_id, file_name)
            
        except Exception as e:
            logger.error(f"[WX859] ä¸‹è½½æ–‡ä»¶å¼‚å¸¸: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    async def _check_file_cache(self, attach_id: str, file_name: str = None) -> dict:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­"""
        try:
            mapping_file = os.path.join(self.file_cache_dir, "file_mapping.json")
            if not os.path.exists(mapping_file):
                return None
            
            with open(mapping_file, 'r', encoding='utf-8') as f:
                mapping = json.load(f)
            
            if attach_id in mapping:
                cached_info = mapping[attach_id]
                cached_file_path = os.path.join(self.file_cache_dir, cached_info["cached_filename"])
                
                # æ£€æŸ¥ç¼“å­˜æ–‡ä»¶æ˜¯å¦ç¡®å®å­˜åœ¨ä¸”æœ‰æ•ˆ
                if os.path.exists(cached_file_path) and os.path.getsize(cached_file_path) > 0:
                    try:
                        with open(cached_file_path, 'rb') as f:
                            file_data = f.read()
                        
                        # ç¼–ç ä¸ºbase64ä»¥ä¿æŒå…¼å®¹æ€§
                        file_data_b64 = base64.b64encode(file_data).decode('utf-8')
                        
                        return {
                            "success": True,
                            "file_path": cached_file_path,
                            "file_data": file_data_b64,
                            "file_size": len(file_data),
                            "from_cache": True,
                            "cached_filename": cached_info["cached_filename"],
                            "original_filename": cached_info.get("original_filename", file_name or "unknown")
                        }
                    except Exception as read_error:
                        logger.warning(f"[WX859] è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {read_error}")
                        # åˆ é™¤æ— æ•ˆçš„ç¼“å­˜è®°å½•
                        del mapping[attach_id]
                        with open(mapping_file, 'w', encoding='utf-8') as f:
                            json.dump(mapping, f, ensure_ascii=False, indent=2)
                else:
                    # åˆ é™¤æ— æ•ˆçš„ç¼“å­˜è®°å½•
                    logger.warning(f"[WX859] ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œæ¸…ç†ç¼“å­˜è®°å½•: {cached_file_path}")
                    del mapping[attach_id]
                    with open(mapping_file, 'w', encoding='utf-8') as f:
                        json.dump(mapping, f, ensure_ascii=False, indent=2)
            
            return None
        except Exception as e:
            logger.error(f"[WX859] æ£€æŸ¥æ–‡ä»¶ç¼“å­˜æ—¶å‡ºé”™: {e}")
            return None

    async def _do_download_file_with_lock(self, attach_id: str, file_name: str = None) -> dict:
        """æ‰§è¡Œå¸¦é”çš„æ–‡ä»¶ä¸‹è½½"""
        # åˆ›å»ºä¸‹è½½é”
        download_future = asyncio.Future()
        self._download_locks[attach_id] = download_future
        
        try:
            logger.info(f"[WX859] å¼€å§‹å®é™…ä¸‹è½½æ–‡ä»¶: attach_id={attach_id}")
            result = await self._do_actual_download(attach_id, file_name)
            download_future.set_result(result)
            return result
        except Exception as e:
            download_future.set_exception(e)
            raise
        finally:
            # æ¸…ç†ä¸‹è½½é”
            if attach_id in self._download_locks:
                del self._download_locks[attach_id]

    async def _do_actual_download(self, attach_id: str, file_name: str = None) -> dict:
        """æ‰§è¡Œå®é™…çš„æ–‡ä»¶ä¸‹è½½é€»è¾‘"""
        # è°ƒç”¨ä¸‹è½½API
        params = {
            "Wxid": self.wxid,
            "AttachId": attach_id,
            "DataLen": 0,  # å¦‚æœä¸çŸ¥é“æ–‡ä»¶å¤§å°ï¼Œè®¾ä¸º0è®©APIè‡ªåŠ¨å¤„ç†
            "Section": {
                "StartPos": 0,
                "DataLen": 0
            }
        }
        
        result = await self._call_api("/Tools/DownloadFile", params)
        
        if result and result.get("Success", False):
            data = result.get("Data", {})
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†å—ä¸‹è½½
            total_len = data.get("totalLen", 0)
            start_pos = data.get("startPos", 0)
            data_len = data.get("dataLen", 0)
            
            logger.info(f"[WX859] æ–‡ä»¶ä¸‹è½½ä¿¡æ¯: totalLen={total_len}, startPos={start_pos}, dataLen={data_len}")
            
            # è·å–ç¬¬ä¸€å—æ•°æ®
            file_data = None
            if "data" in data and "buffer" in data["data"]:
                file_data = data["data"]["buffer"]
            elif "buffer" in data:
                file_data = data["buffer"]
            
            if file_data and total_len > data_len:
                # éœ€è¦åˆ†å—ä¸‹è½½
                logger.info(f"[WX859] æ£€æµ‹åˆ°å¤§æ–‡ä»¶ï¼Œéœ€è¦åˆ†å—ä¸‹è½½: {total_len} bytes")
                
                # æ”¶é›†æ‰€æœ‰æ•°æ®å—
                all_chunks = [file_data]
                current_pos = start_pos + data_len
                
                while current_pos < total_len:
                    # è®¡ç®—ä¸‹ä¸€å—çš„å¤§å°
                    remaining = total_len - current_pos
                    chunk_size = min(65536, remaining)  # æ¯å—æœ€å¤§64KB
                    
                    logger.info(f"[WX859] ä¸‹è½½æ–‡ä»¶å—: pos={current_pos}, size={chunk_size}")
                    
                    # è¯·æ±‚ä¸‹ä¸€å—
                    chunk_params = {
                        "Wxid": self.wxid,
                        "AttachId": attach_id,
                        "DataLen": chunk_size,
                        "Section": {
                            "StartPos": current_pos,
                            "DataLen": chunk_size
                        }
                    }
                    
                    chunk_result = await self._call_api("/Tools/DownloadFile", chunk_params)
                    
                    if chunk_result and chunk_result.get("Success", False):
                        chunk_data = chunk_result.get("Data", {})
                        chunk_buffer = None
                        
                        if "data" in chunk_data and "buffer" in chunk_data["data"]:
                            chunk_buffer = chunk_data["data"]["buffer"]
                        elif "buffer" in chunk_data:
                            chunk_buffer = chunk_data["buffer"]
                        
                        if chunk_buffer:
                            all_chunks.append(chunk_buffer)
                            current_pos += len(base64.b64decode(chunk_buffer)) if isinstance(chunk_buffer, str) else len(chunk_buffer)
                            logger.info(f"[WX859] æˆåŠŸä¸‹è½½æ–‡ä»¶å—ï¼Œå½“å‰è¿›åº¦: {current_pos}/{total_len}")
                        else:
                            logger.error(f"[WX859] æ–‡ä»¶å—ä¸‹è½½å¤±è´¥: æ— æ•°æ®")
                            break
                    else:
                        error_msg = chunk_result.get("Message", "æœªçŸ¥é”™è¯¯") if chunk_result else "APIè°ƒç”¨å¤±è´¥"
                        logger.error(f"[WX859] æ–‡ä»¶å—ä¸‹è½½å¤±è´¥: {error_msg}")
                        break
                
                # åˆå¹¶æ‰€æœ‰æ•°æ®å—
                if len(all_chunks) > 1:
                    logger.info(f"[WX859] åˆå¹¶ {len(all_chunks)} ä¸ªæ–‡ä»¶å—")
                    
                    # å¦‚æœæ˜¯base64å­—ç¬¦ä¸²ï¼Œå…ˆè§£ç å†åˆå¹¶
                    if isinstance(all_chunks[0], str):
                        decoded_chunks = []
                        for chunk in all_chunks:
                            try:
                                decoded_chunks.append(base64.b64decode(chunk))
                            except Exception as e:
                                logger.error(f"[WX859] è§£ç æ–‡ä»¶å—å¤±è´¥: {e}")
                                return {"success": False, "error": f"æ–‡ä»¶å—è§£ç å¤±è´¥: {e}"}
                        file_data = base64.b64encode(b''.join(decoded_chunks)).decode('utf-8')
                    else:
                        file_data = b''.join(all_chunks)
                    
                    logger.info(f"[WX859] æ–‡ä»¶åˆ†å—ä¸‹è½½å®Œæˆï¼Œæ€»å¤§å°: {len(base64.b64decode(file_data)) if isinstance(file_data, str) else len(file_data)} bytes")
            
            if file_data:
                # å¦‚æœæä¾›äº†æ–‡ä»¶åï¼Œä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
                if file_name:
                    file_path = await self._save_downloaded_file(file_data, file_name)
                    logger.info(f"[WX859] æ–‡ä»¶ä¸‹è½½æˆåŠŸå¹¶ä¿å­˜åˆ°: {file_path}")
                    return {
                        "success": True,
                        "file_path": file_path,
                        "file_data": file_data,
                        "file_size": len(file_data) if isinstance(file_data, (bytes, str)) else 0
                    }
                else:
                    logger.info(f"[WX859] æ–‡ä»¶ä¸‹è½½æˆåŠŸ: å¤§å°={len(file_data) if isinstance(file_data, (bytes, str)) else 'Unknown'}")
                    return {
                        "success": True,
                        "file_data": file_data,
                        "file_size": len(file_data) if isinstance(file_data, (bytes, str)) else 0
                    }
            else:
                logger.error(f"[WX859] ä¸‹è½½æ–‡ä»¶å¤±è´¥: æ— æ³•è·å–æ–‡ä»¶æ•°æ®")
                return {"success": False, "error": "æ— æ³•è·å–æ–‡ä»¶æ•°æ®"}
        else:
            error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯") if result else "APIè°ƒç”¨å¤±è´¥"
            logger.error(f"[WX859] ä¸‹è½½æ–‡ä»¶å¤±è´¥: {error_msg}")
            return {"success": False, "error": error_msg}

    # ğŸ”¥ å‘åå…¼å®¹æ–¹æ³•ï¼Œé¿å…å…¶ä»–åœ°æ–¹è°ƒç”¨download_fileæ—¶å‡ºé”™
    async def download_file(self, attach_id: str, file_name: str = None) -> dict:
        """å‘åå…¼å®¹çš„æ–‡ä»¶ä¸‹è½½æ–¹æ³•ï¼Œå†…éƒ¨è°ƒç”¨ä¼˜åŒ–ç‰ˆæœ¬"""
        return await self.download_file_with_cache_check(attach_id, file_name)

    async def _save_downloaded_file(self, file_data, file_name: str) -> str:
        """ä¿å­˜ä¸‹è½½çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•"""
        try:
            # åˆ›å»ºæ–‡ä»¶ç¼“å­˜ç›®å½•
            file_cache_dir = os.path.join(os.getcwd(), "tmp", "wx859_file_cache")
            if not os.path.exists(file_cache_dir):
                os.makedirs(file_cache_dir, exist_ok=True)
            
            # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
            timestamp = int(time.time())
            safe_filename = self._sanitize_filename(file_name)
            file_path = os.path.join(file_cache_dir, f"{timestamp}_{safe_filename}")
            
            # å¤„ç†æ–‡ä»¶æ•°æ®
            if isinstance(file_data, str):
                # å¦‚æœæ˜¯base64å­—ç¬¦ä¸²ï¼Œå…ˆè§£ç 
                try:
                    file_bytes = base64.b64decode(file_data)
                except:
                    # å¦‚æœä¸æ˜¯base64ï¼Œç›´æ¥ä½œä¸ºæ–‡æœ¬ä¿å­˜
                    file_bytes = file_data.encode('utf-8')
            elif isinstance(file_data, bytes):
                file_bytes = file_data
            else:
                # å…¶ä»–ç±»å‹è½¬ä¸ºå­—ç¬¦ä¸²å†ç¼–ç 
                file_bytes = str(file_data).encode('utf-8')
            
            # ä¿å­˜æ–‡ä»¶
            with open(file_path, 'wb') as f:
                f.write(file_bytes)
            
            logger.info(f"[WX859] æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")
            return file_path
            
        except Exception as e:
            logger.error(f"[WX859] ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            raise

    def _sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤ä¸å®‰å…¨å­—ç¬¦"""
        import re
        # ç§»é™¤æˆ–æ›¿æ¢ä¸å®‰å…¨å­—ç¬¦
        safe_name = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # é™åˆ¶é•¿åº¦
        if len(safe_name) > 100:
            name, ext = os.path.splitext(safe_name)
            safe_name = name[:95] + ext
        return safe_name

    async def upload_file(self, file_path: str) -> dict:
        """
        ä¸Šä¼ æ–‡ä»¶
        å‚è€ƒswagger.jsonä¸­çš„/Tools/UploadFileæ¥å£
        
        Args:
            file_path (str): è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: ä¸Šä¼ ç»“æœ
        """
        try:
            if not os.path.exists(file_path):
                return {"success": False, "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}
            
            logger.info(f"[WX859] å¼€å§‹ä¸Šä¼ æ–‡ä»¶: {file_path}")
            
            # è¯»å–æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
            with open(file_path, 'rb') as f:
                file_data = f.read()
            
            file_base64 = base64.b64encode(file_data).decode('utf-8')
            
            # è°ƒç”¨ä¸Šä¼ API
            params = {
                "Wxid": self.wxid,
                "Base64": file_base64
            }
            
            result = await self._call_api("/Tools/UploadFile", params)
            
            # ğŸ”¥ æ–°å¢ï¼šè¯¦ç»†è®°å½•ä¸Šä¼ ç»“æœï¼Œä¾¿äºè°ƒè¯•
            logger.info(f"[WX859] æ–‡ä»¶ä¸Šä¼ APIè¿”å›ç»“æœ: {json.dumps(result, ensure_ascii=False, indent=2)}")
            
            if result and result.get("Success", False):
                logger.info(f"[WX859] æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_path}")
                
                # ğŸ”¥ æ–°å¢ï¼šè®°å½•è¿”å›æ•°æ®çš„å…·ä½“å­—æ®µ
                data = result.get("Data", {})
                logger.info(f"[WX859] ä¸Šä¼ è¿”å›çš„Dataå­—æ®µ: {json.dumps(data, ensure_ascii=False, indent=2)}")
                
                return {
                    "success": True,
                    "result": result,
                    "file_size": len(file_data)
                }
            else:
                error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯") if result else "APIè°ƒç”¨å¤±è´¥"
                logger.error(f"[WX859] æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {error_msg}")
                return {"success": False, "error": error_msg}
                
        except Exception as e:
            logger.error(f"[WX859] ä¸Šä¼ æ–‡ä»¶å¼‚å¸¸: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    async def send_file_message(self, to_user_id: str, file_path: str) -> dict:
        """
        å‘é€æ–‡ä»¶æ¶ˆæ¯
        å…ˆä¸Šä¼ æ–‡ä»¶ï¼Œç„¶åå‘é€æ–‡ä»¶æ¶ˆæ¯
        
        Args:
            to_user_id (str): æ¥æ”¶è€…ID
            file_path (str): æ–‡ä»¶è·¯å¾„
            
        Returns:
            dict: å‘é€ç»“æœ
        """
        try:
            if not to_user_id:
                return {"success": False, "error": "æ¥æ”¶è€…IDä¸èƒ½ä¸ºç©º"}
            
            if not os.path.exists(file_path):
                return {"success": False, "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"}
            
            logger.info(f"[WX859] å¼€å§‹å‘é€æ–‡ä»¶æ¶ˆæ¯: to={to_user_id}, file={file_path}")
            
            # å…ˆä¸Šä¼ æ–‡ä»¶
            upload_result = await self.upload_file(file_path)
            if not upload_result.get("success", False):
                return {"success": False, "error": f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {upload_result.get('error', 'æœªçŸ¥é”™è¯¯')}"}
            
            # æ„å»ºæ–‡ä»¶æ¶ˆæ¯XML
            file_name = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            file_xml = self._build_file_message_xml(file_name, file_size, upload_result.get("result", {}))
            
            # å‘é€æ–‡ä»¶æ¶ˆæ¯
            send_result = await self._send_app_xml(to_user_id, file_xml, 6)  # type=6 è¡¨ç¤ºæ–‡ä»¶æ¶ˆæ¯
            
            if send_result and send_result.get("Success", False):
                logger.info(f"[WX859] æ–‡ä»¶æ¶ˆæ¯å‘é€æˆåŠŸ: to={to_user_id}, file={file_name}")
                return {"success": True, "result": send_result}
            else:
                error_msg = send_result.get("Message", "æœªçŸ¥é”™è¯¯") if send_result else "å‘é€å¤±è´¥"
                logger.error(f"[WX859] æ–‡ä»¶æ¶ˆæ¯å‘é€å¤±è´¥: {error_msg}")
                return {"success": False, "error": error_msg}
                
        except Exception as e:
            logger.error(f"[WX859] å‘é€æ–‡ä»¶æ¶ˆæ¯å¼‚å¸¸: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    def _build_file_message_xml(self, file_name: str, file_size: int, upload_result: dict) -> str:
        """
        æ„å»ºæ–‡ä»¶æ¶ˆæ¯çš„XMLå†…å®¹
        """
        try:
            # è·å–æ–‡ä»¶æ‰©å±•å
            file_ext = os.path.splitext(file_name)[1].lstrip('.')
            if not file_ext:
                file_ext = "unknown"
            
            # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
            file_size_str = self._format_file_size(file_size)
            
            # ğŸ”¥ ä¼˜åŒ–ï¼šä»ä¸Šä¼ ç»“æœä¸­è·å–å¿…è¦ä¿¡æ¯ï¼Œæ”¯æŒå¤šç§å¯èƒ½çš„å­—æ®µæ ¼å¼
            logger.info(f"[WX859] æ„å»ºæ–‡ä»¶XMLï¼Œä¸Šä¼ ç»“æœ: {json.dumps(upload_result, ensure_ascii=False, indent=2)}")
            
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„ä½ç½®è·å–æ•°æ®
            data = upload_result.get("Data", upload_result)
            
            # ğŸ”¥ æ–°å¢ï¼šä¸“é—¨å¤„ç†859åè®®çš„mediaIdæ ¼å¼
            attach_id = ""
            cdn_url = ""
            aes_key = ""
            
            # æ–¹æ³•1ï¼šç›´æ¥ä»å­—æ®µä¸­è·å–
            attach_id = (data.get("AttachId") or data.get("attachId") or 
                        data.get("attach_id") or data.get("id") or "")
            cdn_url = (data.get("CdnUrl") or data.get("cdnUrl") or 
                      data.get("cdn_url") or data.get("url") or "")
            aes_key = (data.get("AesKey") or data.get("aesKey") or 
                      data.get("aes_key") or data.get("key") or "")
            
            # æ–¹æ³•2ï¼šå¦‚æœä¸Šè¿°æ–¹æ³•å¤±è´¥ï¼Œå°è¯•ä»mediaIdä¸­æå–ä¿¡æ¯ï¼ˆ859åè®®ç‰¹æœ‰ï¼‰
            if not attach_id and not cdn_url and not aes_key:
                media_id = data.get("mediaId", "")
                if media_id:
                    logger.info(f"[WX859] å°è¯•ä»mediaIdæå–æ–‡ä»¶ä¿¡æ¯: {media_id}")
                    
                    # 859åè®®çš„mediaIdé€šå¸¸åŒ…å«æ–‡ä»¶ä¿¡æ¯
                    # å¯¹äºæ–‡ä»¶æ¶ˆæ¯ï¼ŒmediaIdå°±æ˜¯attachId
                    attach_id = media_id
                    
                    # å¯¹äº859åè®®ï¼Œå¦‚æœæ²¡æœ‰cdn_urlï¼Œå¯ä»¥æ„é€ ä¸€ä¸ªåŸºç¡€çš„cdnæ ‡è¯†
                    # åœ¨XMLä¸­ï¼Œå¦‚æœcdn_urlä¸ºç©ºï¼Œå¾®ä¿¡ä¼šä½¿ç”¨å…¶ä»–æ–¹å¼ä¸‹è½½æ–‡ä»¶
                    cdn_url = ""  # 859åè®®å¯èƒ½ä¸éœ€è¦cdn_url
                    aes_key = ""  # 859åè®®å¯èƒ½ä¸éœ€è¦aes_key
                    
                    logger.info(f"[WX859] ä»mediaIdæå–åˆ°æ–‡ä»¶ä¿¡æ¯: attach_id={attach_id}")
            
            # æ–¹æ³•3ï¼šå¦‚æœä»ç„¶æ²¡æœ‰attach_idï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„å­—æ®µ
            if not attach_id:
                possible_id_fields = ["clientAppDataId", "id", "fileId", "MessageId", "localId"]
                for field in possible_id_fields:
                    if field in data and data[field]:
                        attach_id = str(data[field])
                        logger.info(f"[WX859] ä»å­—æ®µ {field} è·å–åˆ°attach_id: {attach_id}")
                        break
            
            logger.info(f"[WX859] æœ€ç»ˆæå–çš„æ–‡ä»¶ä¿¡æ¯: attach_id={attach_id}, cdn_url={cdn_url}, aes_key={aes_key}")
            
            # ğŸ”¥ æ–°å¢ï¼šå³ä½¿æ²¡æœ‰å®Œæ•´çš„æ–‡ä»¶ä¿¡æ¯ï¼Œä¹Ÿè¦æ„å»ºXMLï¼ˆ859åè®®çš„ç‰¹æ®Šå¤„ç†ï¼‰
            # å¯¹äº859åè®®ï¼Œå¾®ä¿¡å¯èƒ½é€šè¿‡å…¶ä»–æ–¹å¼è¯†åˆ«æ–‡ä»¶ï¼Œä¸å®Œå…¨ä¾èµ–cdn_urlå’Œaes_key
            if not attach_id:
                # å¦‚æœå®Œå…¨æ²¡æœ‰æ–‡ä»¶æ ‡è¯†ï¼Œä½¿ç”¨æ–‡ä»¶åå’Œå¤§å°ç”Ÿæˆä¸€ä¸ªä¸´æ—¶ID
                import hashlib
                import time
                temp_id = hashlib.md5(f"{file_name}_{file_size}_{int(time.time())}".encode()).hexdigest()
                attach_id = temp_id
                logger.warning(f"[WX859] æ— æ³•æå–æ–‡ä»¶IDï¼Œç”Ÿæˆä¸´æ—¶ID: {attach_id}")
            
            # æ„å»ºXML
            xml_content = f'''<?xml version="1.0"?>
<msg>
    <appmsg appid="" sdkver="0">
        <title>{file_name}</title>
        <des>{file_size_str}</des>
        <action>view</action>
        <type>6</type>
        <showtype>0</showtype>
        <content></content>
        <url></url>
        <dataurl></dataurl>
        <lowurl></lowurl>
        <lowdataurl></lowdataurl>
        <appattach>
            <totallen>{file_size}</totallen>
            <attachid>{attach_id}</attachid>
            <emoticonmd5></emoticonmd5>
            <fileext>{file_ext}</fileext>
            <cdnattachurl>{cdn_url}</cdnattachurl>
            <cdnthumburl></cdnthumburl>
            <cdnthumblength>0</cdnthumblength>
            <cdnthumbwidth>0</cdnthumbwidth>
            <cdnthumbheight>0</cdnthumbheight>
            <cdnthumbaeskey></cdnthumbaeskey>
            <aeskey>{aes_key}</aeskey>
            <encryver>1</encryver>
            <filekey></filekey>
        </appattach>
        <extinfo></extinfo>
    </appmsg>
    <fromusername></fromusername>
    <scene>0</scene>
    <appinfo>
        <version>1</version>
        <appname></appname>
    </appinfo>
</msg>'''
            
            # ğŸ”¥ æ–°å¢ï¼šè®°å½•æœ€ç»ˆçš„XMLå†…å®¹ï¼ˆæˆªå–å‰200å­—ç¬¦ä»¥é¿å…æ—¥å¿—è¿‡é•¿ï¼‰
            logger.info(f"[WX859] æ„å»ºçš„æ–‡ä»¶XML: {xml_content[:200]}...")
            
            return xml_content
            
        except Exception as e:
            logger.error(f"[WX859] æ„å»ºæ–‡ä»¶æ¶ˆæ¯XMLå¤±è´¥: {e}")
            import traceback
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return ""

    async def forward_file_message(self, to_user_id: str, file_xml: str) -> dict:
        """
        è½¬å‘æ–‡ä»¶æ¶ˆæ¯
        å‚è€ƒswagger.jsonä¸­çš„/Msg/SendCDNFileæ¥å£
        
        Args:
            to_user_id (str): æ¥æ”¶è€…ID
            file_xml (str): æ–‡ä»¶æ¶ˆæ¯çš„XMLå†…å®¹
            
        Returns:
            dict: è½¬å‘ç»“æœ
        """
        try:
            if not to_user_id:
                return {"success": False, "error": "æ¥æ”¶è€…IDä¸èƒ½ä¸ºç©º"}
            
            if not file_xml:
                return {"success": False, "error": "æ–‡ä»¶XMLå†…å®¹ä¸èƒ½ä¸ºç©º"}
            
            logger.info(f"[WX859] å¼€å§‹è½¬å‘æ–‡ä»¶æ¶ˆæ¯: to={to_user_id}")
            
            # è°ƒç”¨è½¬å‘æ–‡ä»¶API
            params = {
                "Wxid": self.wxid,
                "ToWxid": to_user_id,
                "Content": file_xml
            }
            
            result = await self._call_api("/Msg/SendCDNFile", params)
            
            if result and result.get("Success", False):
                logger.info(f"[WX859] æ–‡ä»¶æ¶ˆæ¯è½¬å‘æˆåŠŸ: to={to_user_id}")
                return {"success": True, "result": result}
            else:
                error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯") if result else "APIè°ƒç”¨å¤±è´¥"
                logger.error(f"[WX859] æ–‡ä»¶æ¶ˆæ¯è½¬å‘å¤±è´¥: {error_msg}")
                return {"success": False, "error": error_msg}
                
        except Exception as e:
            logger.error(f"[WX859] è½¬å‘æ–‡ä»¶æ¶ˆæ¯å¼‚å¸¸: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    async def _auto_cache_file(self, cmsg, attach_id: str, filename: str, file_ext: str):
        """ğŸ”¥ ä¼˜åŒ–çš„è‡ªåŠ¨ç¼“å­˜æ–‡ä»¶åˆ°æœ¬åœ°ï¼Œé¿å…é‡å¤ä¸‹è½½"""
        try:
            logger.info(f"[{self.name}] å·²å¯åŠ¨æ–‡ä»¶è‡ªåŠ¨ç¼“å­˜ä»»åŠ¡: {filename}")
            
            # ğŸ”¥ ä½¿ç”¨ä¼˜åŒ–çš„æ–‡ä»¶ä¸‹è½½æ–¹æ³•ï¼Œè‡ªå¸¦ç¼“å­˜æ£€æŸ¥å’Œé‡å¤ä¸‹è½½é˜²æŠ¤
            download_result = await self.download_file_with_cache_check(attach_id, None)
            
            if download_result.get("success", False):
                # æ£€æŸ¥æ˜¯å¦ä»ç¼“å­˜è·å–
                if download_result.get("from_cache", False):
                    logger.info(f"[{self.name}] æ–‡ä»¶å·²åœ¨ç¼“å­˜ä¸­ï¼Œæ— éœ€é‡å¤ç¼“å­˜: {filename}")
                    return
                
                file_data = download_result.get("file_data")
                if file_data:
                    # ğŸ”¥ æ–°æ–¹æ¡ˆï¼šä½¿ç”¨ä¼˜é›…çš„æ–‡ä»¶å‘½åæ ¼å¼ï¼Œé¿å…è¶…é•¿çš„attachid
                    # ç”Ÿæˆç®€æ´çš„ç¼“å­˜æ–‡ä»¶åï¼šæ–‡ä»¶å_æ—¶é—´æˆ³.æ‰©å±•å
                    timestamp = int(time.time())
                    safe_filename = self._sanitize_filename(filename)
                    base_name = os.path.splitext(safe_filename)[0][:30]  # æˆªå–å‰30ä¸ªå­—ç¬¦é¿å…è·¯å¾„è¿‡é•¿
                    safe_ext = file_ext if file_ext else "unknown"
                    cache_filename = f"{base_name}_{timestamp}.{safe_ext}"
                    cache_file_path = os.path.join(self.file_cache_dir, cache_filename)
                    
                    # ä¿å­˜æ–‡ä»¶æ•°æ®
                    if isinstance(file_data, str):
                        # å¦‚æœæ˜¯base64å­—ç¬¦ä¸²ï¼Œå…ˆè§£ç 
                        try:
                            file_bytes = base64.b64decode(file_data)
                        except:
                            file_bytes = file_data.encode('utf-8')
                    elif isinstance(file_data, bytes):
                        file_bytes = file_data
                    else:
                        file_bytes = str(file_data).encode('utf-8')
                    
                    with open(cache_file_path, 'wb') as f:
                        f.write(file_bytes)
                    
                    # ä¿å­˜æ˜ å°„å…³ç³»åˆ°å…±äº«æ˜ å°„æ–‡ä»¶
                    mapping_file = os.path.join(self.file_cache_dir, "file_mapping.json")
                    try:
                        if os.path.exists(mapping_file):
                            with open(mapping_file, 'r', encoding='utf-8') as f:
                                mapping = json.load(f)
                        else:
                            mapping = {}
                        
                        # æ·»åŠ æ˜ å°„å…³ç³»ï¼šattachid -> æ–‡ä»¶ä¿¡æ¯
                        mapping[attach_id] = {
                            "cached_filename": cache_filename,
                            "original_filename": filename,
                            "file_size": len(file_bytes),
                            "cached_time": timestamp,
                            "file_ext": file_ext,
                            "msg_id": cmsg.msg_id,
                            "from_user_id": cmsg.from_user_id,
                            "sender_wxid": cmsg.sender_wxid
                        }
                        
                        with open(mapping_file, 'w', encoding='utf-8') as f:
                            json.dump(mapping, f, ensure_ascii=False, indent=2)
                            
                    except Exception as mapping_error:
                        logger.warning(f"[{self.name}] ä¿å­˜æ–‡ä»¶æ˜ å°„å¤±è´¥: {mapping_error}")
                        # æ˜ å°„å¤±è´¥ä¸å½±å“æ–‡ä»¶ç¼“å­˜
                    
                    logger.info(f"[{self.name}] æ–‡ä»¶è‡ªåŠ¨ç¼“å­˜æˆåŠŸ: {cache_filename} ({len(file_bytes)} bytes)")
                else:
                    logger.error(f"[{self.name}] ä¸‹è½½æ–‡ä»¶æˆåŠŸä½†æ— æ•°æ®: {filename}")
            else:
                error_msg = download_result.get("error", "æœªçŸ¥é”™è¯¯")
                logger.error(f"[{self.name}] è‡ªåŠ¨ç¼“å­˜æ–‡ä»¶ä¸‹è½½å¤±è´¥: {filename}, é”™è¯¯: {error_msg}")
                
        except Exception as e:
            logger.error(f"[{self.name}] è‡ªåŠ¨ç¼“å­˜æ–‡ä»¶å¼‚å¸¸: {e}")
            logger.error(f"[{self.name}] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

    def _format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"

    async def _cleanup_file_cache(self):
        """å¢å¼ºç‰ˆæ–‡ä»¶ç¼“å­˜æ¸…ç† - é›†æˆcache_monitoråŠŸèƒ½"""
        try:
            file_cache_dir = os.path.join(os.getcwd(), "tmp", "wx859_file_cache")
            mapping_file = os.path.join(file_cache_dir, "file_mapping.json")
            
            if not os.path.exists(file_cache_dir):
                logger.debug(f"[{self.name}] æ–‡ä»¶ç¼“å­˜ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†")
                return
            
            logger.info(f"[{self.name}] å¼€å§‹æ–‡ä»¶ç¼“å­˜æ¸…ç†...")
            
            current_time = time.time()
            max_age_seconds = 24 * 60 * 60  # ç¼“å­˜æ–‡ä»¶ä¿ç•™24å°æ—¶
            
            cleaned_files = 0
            freed_size = 0
            invalid_mappings = 0
            
            # æ£€æŸ¥æ˜ å°„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if os.path.exists(mapping_file):
                try:
                    with open(mapping_file, 'r', encoding='utf-8') as f:
                        mapping = json.load(f)
                    
                    # æ¸…ç†æ— æ•ˆå’Œè¿‡æœŸçš„æ˜ å°„è®°å½•
                    for attach_id, info in list(mapping.items()):
                        cached_filename = info.get("cached_filename", "")
                        cached_time = info.get("cached_time", 0)
                        
                        if not cached_filename:
                            del mapping[attach_id]
                            invalid_mappings += 1
                            continue
                            
                        file_path = os.path.join(file_cache_dir, cached_filename)
                        
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
                        if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
                            # åˆ é™¤æ— æ•ˆç¼“å­˜è®°å½•
                            del mapping[attach_id]
                            invalid_mappings += 1
                            
                            # å¦‚æœæ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©ºï¼Œåˆ é™¤æ–‡ä»¶
                            if os.path.exists(file_path):
                                try:
                                    file_size = os.path.getsize(file_path)
                                    os.remove(file_path)
                                    cleaned_files += 1
                                    freed_size += file_size
                                    logger.debug(f"[{self.name}] åˆ é™¤æ— æ•ˆæ–‡ä»¶: {cached_filename}")
                                except Exception as e:
                                    logger.warning(f"[{self.name}] åˆ é™¤æ— æ•ˆæ–‡ä»¶å¤±è´¥: {cached_filename}, é”™è¯¯: {e}")
                        
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¿‡æœŸ
                        elif current_time - cached_time > max_age_seconds:
                            try:
                                file_size = os.path.getsize(file_path)
                                os.remove(file_path)
                                del mapping[attach_id]
                                cleaned_files += 1
                                freed_size += file_size
                                logger.debug(f"[{self.name}] åˆ é™¤è¿‡æœŸæ–‡ä»¶: {cached_filename}")
                            except Exception as e:
                                logger.warning(f"[{self.name}] åˆ é™¤è¿‡æœŸæ–‡ä»¶å¤±è´¥: {cached_filename}, é”™è¯¯: {e}")
                    
                    # ä¿å­˜æ›´æ–°åçš„æ˜ å°„æ–‡ä»¶
                    if invalid_mappings > 0 or cleaned_files > 0:
                        with open(mapping_file, 'w', encoding='utf-8') as f:
                            json.dump(mapping, f, ensure_ascii=False, indent=2)
                        
                except Exception as e:
                    logger.error(f"[{self.name}] å¤„ç†æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
            
            # æ¸…ç†æ²¡æœ‰æ˜ å°„è®°å½•çš„å­¤ç«‹æ–‡ä»¶
            orphaned_files = 0
            orphaned_size = 0
            
            for filename in os.listdir(file_cache_dir):
                if filename == "file_mapping.json":
                    continue
                    
                file_path = os.path.join(file_cache_dir, filename)
                try:
                    if os.path.isfile(file_path):
                        file_age = current_time - os.path.getmtime(file_path)
                        if file_age > max_age_seconds:
                            file_size = os.path.getsize(file_path)
                            os.remove(file_path)
                            orphaned_files += 1
                            orphaned_size += file_size
                            logger.debug(f"[{self.name}] åˆ é™¤å­¤ç«‹æ–‡ä»¶: {filename}")
                except Exception as e:
                    logger.warning(f"[{self.name}] åˆ é™¤å­¤ç«‹æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {e}")
            
            # è®°å½•æ¸…ç†ç»“æœ
            total_cleaned = cleaned_files + orphaned_files
            total_freed = freed_size + orphaned_size
            
            if total_cleaned > 0 or invalid_mappings > 0:
                logger.info(f"[{self.name}] æ–‡ä»¶ç¼“å­˜æ¸…ç†å®Œæˆ: "
                          f"åˆ é™¤æ–‡ä»¶ {total_cleaned} ä¸ª, "
                          f"æ¸…ç†æ— æ•ˆæ˜ å°„ {invalid_mappings} ä¸ª, "
                          f"é‡Šæ”¾ç©ºé—´ {self._format_file_size(total_freed)}")
            else:
                logger.debug(f"[{self.name}] æ–‡ä»¶ç¼“å­˜æ¸…ç†å®Œæˆï¼Œæ— éœ€æ¸…ç†ä»»ä½•æ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"[{self.name}] æ–‡ä»¶ç¼“å­˜æ¸…ç†å¼‚å¸¸: {e}")
            import traceback
            logger.error(f"[{self.name}] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")


    async def _download_image(self, cmsg):
        """ä¸‹è½½å›¾ç‰‡å¹¶è®¾ç½®æœ¬åœ°è·¯å¾„"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å›¾ç‰‡è·¯å¾„
            if hasattr(cmsg, 'image_path') and cmsg.image_path and os.path.exists(cmsg.image_path):
                logger.info(f"[WX859] å›¾ç‰‡å·²å­˜åœ¨ï¼Œè·¯å¾„: {cmsg.image_path}")
                return True

            # åˆ›å»ºä¸´æ—¶ç›®å½•
            tmp_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp", "wx859_img_cache")
            os.makedirs(tmp_dir, exist_ok=True)

            # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨ç›¸åŒçš„å›¾ç‰‡æ–‡ä»¶
            msg_id = cmsg.msg_id
            existing_files = [f for f in os.listdir(tmp_dir) if f.startswith(f"img_{msg_id}_")]

            if existing_files:
                # æ‰¾åˆ°æœ€æ–°çš„æ–‡ä»¶
                latest_file = sorted(existing_files, key=lambda x: os.path.getmtime(os.path.join(tmp_dir, x)), reverse=True)[0]
                existing_path = os.path.join(tmp_dir, latest_file)

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
                if os.path.exists(existing_path) and os.path.getsize(existing_path) > 0:
                    try:
                        from PIL import Image
                        try:
                            # å°è¯•æ‰“å¼€å›¾ç‰‡æ–‡ä»¶
                            with Image.open(existing_path) as img:
                                # è·å–å›¾ç‰‡æ ¼å¼å’Œå¤§å°
                                img_format = img.format
                                img_size = img.size
                                logger.info(f"[WX859] å›¾ç‰‡å·²å­˜åœ¨ä¸”æœ‰æ•ˆ: æ ¼å¼={img_format}, å¤§å°={img_size}")

                                # è®¾ç½®å›¾ç‰‡æœ¬åœ°è·¯å¾„
                                cmsg.image_path = existing_path
                                cmsg.content = existing_path
                                cmsg.ctype = ContextType.IMAGE
                                cmsg._prepared = True

                                logger.info(f"[WX859] ä½¿ç”¨å·²å­˜åœ¨çš„å›¾ç‰‡æ–‡ä»¶: {existing_path}")
                                return True
                        except Exception as img_err:
                            logger.warning(f"[WX859] å·²å­˜åœ¨çš„å›¾ç‰‡æ–‡ä»¶æ— æ•ˆï¼Œé‡æ–°ä¸‹è½½: {img_err}")
                    except ImportError:
                        # å¦‚æœPILåº“æœªå®‰è£…ï¼Œå‡è®¾æ–‡ä»¶æœ‰æ•ˆ
                        if os.path.getsize(existing_path) > 10000:  # è‡³å°‘10KB
                            cmsg.image_path = existing_path
                            cmsg.content = existing_path
                            cmsg.ctype = ContextType.IMAGE
                            cmsg._prepared = True

                            logger.info(f"[WX859] ä½¿ç”¨å·²å­˜åœ¨çš„å›¾ç‰‡æ–‡ä»¶: {existing_path}")
                            return True

            # ç”Ÿæˆå›¾ç‰‡æ–‡ä»¶å
            image_filename = f"img_{cmsg.msg_id}_{int(time.time())}.jpg"
            image_path = os.path.join(tmp_dir, image_filename)

            # ç›´æ¥ä½¿ç”¨åˆ†æ®µä¸‹è½½æ–¹æ³•ï¼Œä¸å†å°è¯•ä½¿ç”¨GetMsgImage
            logger.info(f"[WX859] ä½¿ç”¨åˆ†æ®µä¸‹è½½æ–¹æ³•è·å–å›¾ç‰‡")
            result = await self._download_image_by_chunks(cmsg, image_path)
            return result

        except Exception as e:
            logger.error(f"[WX859] ä¸‹è½½å›¾ç‰‡è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            logger.error(traceback.format_exc())
            return False

# FILE_PATH: channel/wx859/wx859_channel.py
# MODIFIED_LINES_START
    async def _download_image_by_chunks(self, cmsg: WX859Message, image_path: str): # Added type hints
        """ä½¿ç”¨åˆ†æ®µä¸‹è½½æ–¹æ³•è·å–å›¾ç‰‡, å¹¶åœ¨æˆåŠŸåç¼“å­˜."""
        import traceback
        import asyncio
        import base64 # Ensure base64 is imported
        import aiohttp # Ensure aiohttp is imported
        from io import BytesIO
        from PIL import Image, UnidentifiedImageError
        import shutil 
        import os 
        from bridge.context import ContextType 
        from common.log import logger # Ensure logger is imported
        from config import conf # Ensure conf is imported


        # --- MODIFICATION BLOCK START ---
        authoritative_total_len = -1 # -1 indicates unknown, 0 is a valid length
        api_total_len_confirmed = False
        # --- MODIFICATION BLOCK END ---

        try:
            # 1. ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
            target_dir = os.path.dirname(image_path)
            os.makedirs(target_dir, exist_ok=True)

            # 2. è·å–APIé…ç½®åŠè®¡ç®—åˆ†å—ä¿¡æ¯
            api_host = conf().get("wx859_api_host", "127.0.0.1")
            api_port = conf().get("wx859_api_port", 9011) 
            # å›ºå®šä½¿ç”¨859åè®®
            api_path_prefix = "/api"            
            data_len_from_xml_str = '0'
            if hasattr(cmsg, 'image_info') and isinstance(cmsg.image_info, dict):
                data_len_from_xml_str = cmsg.image_info.get('length', '0')
            elif hasattr(cmsg, 'img_length'): # Fallback for older cmsg structure
                data_len_from_xml_str = cmsg.img_length
            
            try:
                data_len_from_xml = int(data_len_from_xml_str)
                if data_len_from_xml < 0: data_len_from_xml = 0 # Ensure non-negative
            except ValueError:
                data_len_from_xml = 0
            
            # --- MODIFICATION BLOCK START ---
            authoritative_total_len = data_len_from_xml # Initial estimate
            # --- MODIFICATION BLOCK END ---

            if data_len_from_xml <= 0:
                 logger.warning(f"[{self.name}] Image length is {data_len_from_xml} from XML for cmsg {cmsg.msg_id}. Will attempt to get authoritative length from API.")

            chunk_size = 65536
            # --- MODIFICATION BLOCK START ---
            # num_chunks is now an estimate, actual download loop driven by authoritative_total_len or empty chunk
            num_chunks_estimate = (authoritative_total_len + chunk_size - 1) // chunk_size if authoritative_total_len > 0 else 1
            logger.info(f"[{self.name}] å¼€å§‹åˆ†æ®µä¸‹è½½å›¾ç‰‡ (cmsg_id: {cmsg.msg_id}, aeskey: {getattr(cmsg, 'img_aeskey', 'N/A')}) è‡³: {image_path}ï¼ŒXMLé¢„æœŸæ€»å¤§å°: {data_len_from_xml if data_len_from_xml > 0 else 'Unknown'} Bï¼Œé¢„ä¼°åˆ† {num_chunks_estimate} æ®µ")
            # --- MODIFICATION BLOCK END ---

            all_chunks_data_list = []
            download_stream_successful = True # Assume success until an error occurs
            actual_downloaded_size = 0
            
            # --- MODIFICATION BLOCK START ---
            current_chunk_index = 0
            max_chunks_to_try = 2000 # Approx 128MB, safety break for unexpected loops
            
            while True:
                start_pos = actual_downloaded_size
                current_chunk_size_to_request = chunk_size

                if api_total_len_confirmed and authoritative_total_len >= 0: # If we have an authoritative length
                    if start_pos >= authoritative_total_len:
                        logger.info(f"[{self.name}] All data presumed downloaded based on authoritative_total_len ({authoritative_total_len} B) for cmsg {cmsg.msg_id}. Total downloaded: {actual_downloaded_size} B.")
                        break 
                    if start_pos + current_chunk_size_to_request > authoritative_total_len:
                        current_chunk_size_to_request = authoritative_total_len - start_pos
                    if current_chunk_size_to_request <= 0: # Should mean download is complete
                        logger.info(f"[{self.name}] Calculated current_chunk_size_to_request <= 0 ({current_chunk_size_to_request} B) with authoritative_total_len. Download complete for cmsg {cmsg.msg_id}.")
                        break
                elif current_chunk_index > 0 and authoritative_total_len < 0 and not api_total_len_confirmed:
                    # If after the first chunk, we still don't have a length, this is an issue.
                    # Log a warning and proceed, hoping for an empty chunk to terminate.
                    logger.warning(f"[{self.name}] No authoritative total length after first chunk for cmsg {cmsg.msg_id}. Continuing download, will stop on empty chunk.")
                    # api_total_len_confirmed could be set to True here to stop trying to get it,
                    # but we'll let it try once more in case the API returns it later (unlikely).

                if current_chunk_index >= max_chunks_to_try:
                    logger.error(f"[{self.name}] Reached max_chunks_to_try ({max_chunks_to_try}) for cmsg {cmsg.msg_id}. Aborting download. Downloaded: {actual_downloaded_size} B.")
                    download_stream_successful = False
                    break

                params = {
                    "MsgId": int(cmsg.msg_id),
                    "ToWxid": cmsg.from_user_id,
                    "Wxid": self.wxid,
                    "DataLen": authoritative_total_len if api_total_len_confirmed and authoritative_total_len >= 0 else 0, # Send 0 if not yet confirmed or unknown
                    "CompressType": 0,
                    "Section": {"StartPos": start_pos, "DataLen": current_chunk_size_to_request}
                }
                if hasattr(cmsg, 'img_aeskey') and cmsg.img_aeskey:
                    params["Aeskey"] = cmsg.img_aeskey
            # --- MODIFICATION BLOCK END ---

                api_url = f"http://{api_host}:{api_port}{api_path_prefix}/Tools/DownloadImg"
                # --- MODIFICATION BLOCK START ---
                logger.debug(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}): URL={api_url}, Params={params}")
                # --- MODIFICATION BLOCK END ---

                try:
                    async with aiohttp.ClientSession() as session:
                        async with session.post(api_url, json=params, timeout=aiohttp.ClientTimeout(total=30)) as response:
                            if response.status != 200:
                                full_error_text = await response.text()
                                logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) å¤±è´¥, HTTPçŠ¶æ€ç : {response.status}, Response: {full_error_text[:300]}")
                                download_stream_successful = False; break
                            
                            try:
                                result = await response.json()
                            except aiohttp.ContentTypeError:
                                raw_response_text = await response.text()
                                logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) API Error: Non-JSON response. Status: {response.status}. Response text (first 300 chars): {raw_response_text[:300]}")
                                download_stream_successful = False; break

                            # --- MODIFICATION BLOCK START ---
                            # Enhanced API Response Handling - Business Layer
                            api_call_succeeded_business = False # Tracks business logic success (BaseResponse.ret == 0 etc.)
                            error_message_from_api = "Unknown API error"
                            
                            base_response = result.get("BaseResponse")
                            if isinstance(base_response, dict):
                                api_ret_code = base_response.get("ret")
                                error_msg_detail = base_response.get("errMsg", {}).get("string", "") if isinstance(base_response.get("errMsg"), dict) else base_response.get("errMsg", "")
                                if api_ret_code == 0:
                                    api_call_succeeded_business = True
                                    if not result.get("Success", True): # Overall Success flag might be false
                                        api_call_succeeded_business = False
                                        error_message_from_api = result.get("Message", error_msg_detail or "API Success=false after BaseResponse.ret=0")
                                else: # ret is non-zero or None
                                    error_message_from_api = error_msg_detail or f"API error with ret code {api_ret_code}"
                                    logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) APIæŠ¥å‘Šä¸šåŠ¡é”™è¯¯ (BaseResponse): ret={api_ret_code}, errMsg='{error_message_from_api}'. FullResult: {str(result)[:300]}")
                                    download_stream_successful = False; break 
                            elif not result.get("Success", False): # No BaseResponse, rely on overall Success flag
                                error_message_from_api = result.get("Message", "API Success flag is false and no BaseResponse.")
                                logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) APIæŠ¥å‘Šå¤±è´¥ (Success flag, no BaseResponse): {error_message_from_api}. FullResult: {str(result)[:300]}")
                                download_stream_successful = False; break
                            else: # No BaseResponse, Success is true or missing (implies true)
                                api_call_succeeded_business = True

                            if not api_call_succeeded_business: # Safeguard break
                                logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) æœ€ç»ˆåˆ¤æ–­ä¸ºAPIä¸šåŠ¡è°ƒç”¨å¤±è´¥. Message: {error_message_from_api}. FullResult: {str(result)[:300]}")
                                download_stream_successful = False; break
                            
                            # Try to get authoritative totalLen if not yet confirmed
                            if not api_total_len_confirmed:
                                data_payload_for_len = result.get("Data")
                                if isinstance(data_payload_for_len, dict):
                                    api_reported_len_str = data_payload_for_len.get("totalLen") # API often uses totalLen
                                    if api_reported_len_str is not None: # Can be 0
                                        try:
                                            api_reported_len = int(api_reported_len_str)
                                            if api_reported_len >= 0:
                                                logger.info(f"[{self.name}] API reported totalLen: {api_reported_len} B for cmsg {cmsg.msg_id}. XML was: {data_len_from_xml} B.")
                                                authoritative_total_len = api_reported_len
                                                api_total_len_confirmed = True
                                                num_chunks_estimate = (authoritative_total_len + chunk_size - 1) // chunk_size if authoritative_total_len > 0 else 1 # Re-estimate for logging
                                                # If API returns totalLen 0, and it's the first chunk, this might be an empty image
                                                if authoritative_total_len == 0 and current_chunk_index == 0:
                                                    logger.info(f"[{self.name}] API confirmed totalLen=0 for cmsg {cmsg.msg_id} on first chunk.")
                                            else:
                                                logger.warning(f"[{self.name}] API reported invalid negative totalLen: {api_reported_len} for cmsg {cmsg.msg_id}. Ignoring.")
                                        except ValueError:
                                            logger.warning(f"[{self.name}] API reported non-integer totalLen: '{api_reported_len_str}' for cmsg {cmsg.msg_id}. Ignoring.")
                                    else: # totalLen not in Data payload
                                        logger.info(f"[{self.name}] API response for cmsg {cmsg.msg_id} did not contain 'totalLen' in 'Data' payload on chunk {current_chunk_index + 1}. Original XML length {data_len_from_xml} will be used if positive.")
                                else: # Data payload not a dict
                                    logger.info(f"[{self.name}] API response 'Data' field is not a dictionary for cmsg {cmsg.msg_id}. Cannot get totalLen. Original XML length {data_len_from_xml} will be used if positive.")
                                
                                if not api_total_len_confirmed and current_chunk_index == 0: # If still not confirmed after first chunk
                                    logger.warning(f"[{self.name}] Failed to get authoritative totalLen from API's first chunk response for cmsg {cmsg.msg_id}. Will rely on XML length ({data_len_from_xml} B) if >0, or stop on empty chunk.")
                                    api_total_len_confirmed = True # Stop trying to get it, use XML or empty chunk logic

                            chunk_base64 = None
                            data_payload = result.get("Data")
                            if isinstance(data_payload, dict):
                                if "buffer" in data_payload and isinstance(data_payload["buffer"], (str, bytes)):
                                    chunk_base64 = data_payload["buffer"]
                                elif "data" in data_payload and isinstance(data_payload.get("data"), dict) and \
                                     "buffer" in data_payload["data"] and isinstance(data_payload["data"]["buffer"], (str, bytes)):
                                    chunk_base64 = data_payload["data"]["buffer"]
                            elif isinstance(data_payload, str) and data_payload: # "Data" field itself is a base64 string
                                chunk_base64 = data_payload
                            
                            if not chunk_base64: # Fallback if not in "Data"
                                for field in ["data", "buffer", "chunk"]:
                                    potential_data_at_root = result.get(field)
                                    if isinstance(potential_data_at_root, (str, bytes)) and potential_data_at_root:
                                        chunk_base64 = potential_data_at_root; break
                            
                            if not chunk_base64: # Still no data
                                # If authoritative_total_len is 0 and confirmed, and this is the first chunk, it's a valid empty image.
                                if api_total_len_confirmed and authoritative_total_len == 0 and current_chunk_index == 0:
                                    logger.info(f"[{self.name}] API confirmed totalLen=0 and returned no data for first chunk of cmsg {cmsg.msg_id}. Valid empty image.")
                                    download_stream_successful = True # Mark as success for empty image
                                    break # Exit loop, all_chunks_data_list will be empty.
                                else:
                                    logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) æˆåŠŸè·å–APIå“åº”ä½†æœªèƒ½æå–åˆ°æœ‰æ•ˆå›¾ç‰‡æ•°æ®. Response: {str(result)[:300]}")
                                    download_stream_successful = False
                                break
                            # --- MODIFICATION BLOCK END ---
                            
                            try:
                                if isinstance(chunk_base64, bytes):
                                    chunk_data_bytes = chunk_base64
                                elif isinstance(chunk_base64, str):
                                    clean_base64 = chunk_base64.strip()
                                    padding_needed = (4 - len(clean_base64) % 4) % 4
                                    clean_base64 += '=' * padding_needed
                                    chunk_data_bytes = base64.b64decode(clean_base64)
                                else:
                                    logger.error(f"[{self.name}] é€»è¾‘é”™è¯¯: chunk_base64 åœ¨è§£ç å‰æ—¢ä¸æ˜¯å­—ç¬¦ä¸²ä¹Ÿä¸æ˜¯å­—èŠ‚. Type: {type(chunk_base64)}. Value: {str(chunk_base64)[:100]}")
                                    download_stream_successful = False; break

                                # --- MODIFICATION BLOCK START ---
                                if not chunk_data_bytes:
                                    # If authoritative_total_len confirmed and > 0, an empty chunk here might be an error or premature end.
                                    if api_total_len_confirmed and authoritative_total_len > 0 and actual_downloaded_size < authoritative_total_len:
                                        logger.warning(f"[{self.name}] Decoded empty chunk {current_chunk_index + 1} for cmsg {cmsg.msg_id} but expected more data (got {actual_downloaded_size}/{authoritative_total_len} B). Assuming end of stream.")
                                    # If authoritative_total_len is unknown (-1) or 0 (and confirmed), an empty chunk means end of data.
                                    elif (authoritative_total_len < 0 or (api_total_len_confirmed and authoritative_total_len == 0)):
                                        logger.info(f"[{self.name}] Decoded empty chunk {current_chunk_index + 1} for cmsg {cmsg.msg_id} (authoritative_total_len: {authoritative_total_len}). Download stream ended.")
                                    # Else: (e.g. authoritative_total_len > 0 but not confirmed, or some other edge case)
                                    # This might be an unexpected empty chunk. The outer loop break conditions will handle it.
                                    # download_stream_successful remains true for now, subsequent verification will fail if incomplete.
                                    break # Break here, as there's no more data in this chunk.
                                
                                if chunk_data_bytes:
                                    all_chunks_data_list.append(chunk_data_bytes)
                                    actual_downloaded_size += len(chunk_data_bytes)
                                    logger.debug(f"[{self.name}] ç¬¬ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) æ®µè§£ç æˆåŠŸï¼Œå¤§å°: {len(chunk_data_bytes)} B. Total so far: {actual_downloaded_size} B / {authoritative_total_len if authoritative_total_len >=0 else 'Unknown'} B")
                                # --- MODIFICATION BLOCK END ---

                            except Exception as decode_err:
                                logger.error(f"[{self.name}] ç¬¬ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) æ®µBase64è§£ç æˆ–å¤„ç†å¤±è´¥: {decode_err}. Data (å¤´100): {str(chunk_base64)[:100]}")
                                download_stream_successful = False; break
                except asyncio.TimeoutError:
                    logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) è¶…æ—¶ã€‚")
                    download_stream_successful = False; break
                except Exception as api_err:
                    logger.error(f"[{self.name}] ä¸‹è½½åˆ†æ®µ {current_chunk_index + 1} (cmsg {cmsg.msg_id}) å‘ç”ŸAPIè°ƒç”¨é”™è¯¯: {api_err}\\n{traceback.format_exc()}")
                    download_stream_successful = False; break
                
                # --- MODIFICATION BLOCK START ---
                current_chunk_index += 1
                # Check again if download should complete based on authoritative length
                if api_total_len_confirmed and authoritative_total_len >= 0 and actual_downloaded_size >= authoritative_total_len:
                    logger.info(f"[{self.name}] Downloaded size ({actual_downloaded_size} B) meets or exceeds authoritative_total_len ({authoritative_total_len} B) for cmsg {cmsg.msg_id}. Finalizing.")
                    break
                # --- MODIFICATION BLOCK END ---
            
            # 4. æ•°æ®å†™å…¥ã€åˆ·æ–°ä¸åŒæ­¥
            file_written_successfully = False
            if download_stream_successful and all_chunks_data_list: 
                try:
                    with open(image_path, "wb") as f_write:
                        for chunk_piece in all_chunks_data_list:
                            f_write.write(chunk_piece)
                        f_write.flush()
                        if hasattr(os, 'fsync'):
                            try: os.fsync(f_write.fileno())
                            except OSError: pass 
                    
                    final_size_on_disk = os.path.getsize(image_path)
                    logger.info(f"[{self.name}] æ‰€æœ‰åˆ†å—æˆåŠŸå†™å…¥å¹¶åˆ·æ–°åˆ°ç£ç›˜: {image_path}, å®é™…å¤§å°: {final_size_on_disk} B (Downloaded: {actual_downloaded_size} B)")
                    if final_size_on_disk == 0 and actual_downloaded_size > 0 :
                        logger.error(f"[{self.name}] è­¦å‘Šï¼šæ•°æ®å·²ä¸‹è½½ ({actual_downloaded_size}B) ä½†å†™å…¥æ–‡ä»¶åå¤§å°ä¸º0ï¼Path: {image_path}")
                        file_written_successfully = False
                    elif final_size_on_disk == 0 and actual_downloaded_size == 0:
                        logger.info(f"[{self.name}] ä¸‹è½½å®Œæˆï¼Œä½†æœªæ”¶åˆ°ä»»ä½•æ•°æ®ä¸”æ–‡ä»¶å¤§å°ä¸º0 (å¯èƒ½ä¸ºç©ºå›¾ç‰‡æˆ–APIæŒ‡ç¤ºæ— å†…å®¹): {image_path}")
                        file_written_successfully = True 
                    # --- MODIFICATION BLOCK START ---
                    elif api_total_len_confirmed and authoritative_total_len > 0 and final_size_on_disk < authoritative_total_len:
                        logger.warning(f"[{self.name}] æ–‡ä»¶å†™å…¥å®Œæˆ ({final_size_on_disk} B), ä½†å°äºAPIæŠ¥å‘Šçš„æ€»é•¿åº¦ ({authoritative_total_len} B) for cmsg {cmsg.msg_id}. Path: {image_path}")
                        # Potentially still successful if server sent less data than initially stated but indicated end-of-stream
                        file_written_successfully = True # Let PIL verification decide
                    # --- MODIFICATION BLOCK END ---
                    else:
                        file_written_successfully = True

                except IOError as io_err_write:
                    logger.error(f"[{self.name}] å†™å…¥æˆ–åˆ·æ–°å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {io_err_write}, Path: {image_path}")
                except Exception as e_write:
                    logger.error(f"[{self.name}] å†™å…¥æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e_write}, Path: {image_path}\\n{traceback.format_exc()}")

            elif not all_chunks_data_list and download_stream_successful:
                logger.warning(f"[{self.name}] æ‰€æœ‰åˆ†å—ä¸‹è½½APIè°ƒç”¨æˆåŠŸï¼Œä½†æœªæ”¶é›†åˆ°ä»»ä½•æ•°æ®å— for {image_path}. æ–‡ä»¶å°†ä¸ºç©ºæˆ–ä¸å­˜åœ¨ã€‚")
                # This case covers when API confirms totalLen=0 and returns no data for first chunk.
                if api_total_len_confirmed and authoritative_total_len == 0:
                    logger.info(f"[{self.name}] Confirmed empty image (totalLen=0 from API) for cmsg {cmsg.msg_id}, path {image_path}")
                    # Create an empty file to satisfy PIL check for empty image.
                    try:
                        open(image_path, 'w').close()
                        file_written_successfully = True
                    except IOError as e_io_empty:
                        logger.error(f"[{self.name}] Failed to create placeholder empty file {image_path}: {e_io_empty}")
                        download_stream_successful = False # Cannot proceed with empty file logic
                elif os.path.exists(image_path) and os.path.getsize(image_path) == 0: # Should not be reached if above handles totalLen=0
                    file_written_successfully = True 
                else: 
                    download_stream_successful = False

            # 5. å›¾ç‰‡éªŒè¯é˜¶æ®µ å’Œ é‡å‘½å
            final_verified_path = None
            if file_written_successfully: #Proceed to verification only if file write attempt was considered successful
                await asyncio.sleep(0.1) 
                try:
                    if os.path.getsize(image_path) == 0:
                        if actual_downloaded_size == 0 and (api_total_len_confirmed and authoritative_total_len == 0): # Explicitly confirmed empty
                            logger.info(f"[{self.name}] Downloaded image file is empty (0 bytes), and 0 bytes were downloaded. API confirmed empty. Valid empty image: {image_path}")
                            if hasattr(cmsg, 'img_aeskey') and cmsg.img_aeskey:
                                final_filename_empty_aeskey = f"{cmsg.img_aeskey}.empty"
                                final_empty_path_aeskey = os.path.join(target_dir, final_filename_empty_aeskey)
                                try:
                                    if os.path.exists(final_empty_path_aeskey) and final_empty_path_aeskey != image_path: 
                                        os.remove(final_empty_path_aeskey)
                                    shutil.move(image_path, final_empty_path_aeskey) # Use shutil.move for robustness
                                    logger.info(f"[{self.name}] Renamed empty image from {image_path} to {final_empty_path_aeskey} using aeskey.")
                                    final_verified_path = final_empty_path_aeskey
                                except (OSError, shutil.Error) as e_rename_empty_aes:
                                    logger.error(f"[{self.name}] Failed to rename empty image {image_path} to use aeskey: {e_rename_empty_aes}")
                                    final_verified_path = image_path 
                            else:
                                logger.warning(f"[{self.name}] Empty image downloaded but no cmsg.img_aeskey available for msg {cmsg.msg_id}. Keeping original path: {image_path}")
                                final_verified_path = image_path
                            
                            cmsg.image_path = final_verified_path
                            cmsg.content = final_verified_path 
                            cmsg.ctype = ContextType.IMAGE 
                            cmsg._prepared = True
                            return True 
                        else: 
                            raise UnidentifiedImageError("Downloaded image file is empty despite data being received or API not confirming empty.")

                    with open(image_path, "rb") as f_read_verify: image_bytes_for_verify = f_read_verify.read()
                    if not image_bytes_for_verify: raise UnidentifiedImageError("Downloaded image file read as empty for verification.")

                    with Image.open(BytesIO(image_bytes_for_verify)) as img:
                        img_format_detected = img.format 
                        img_size_pil = img.size # Renamed to avoid conflict with os.path.getsize
                    logger.info(f"[{self.name}] å›¾ç‰‡(cmsg {cmsg.msg_id})éªŒè¯æˆåŠŸ (PIL): æ ¼å¼={img_format_detected}, å¤§å°={img_size_pil}, åˆå§‹è·¯å¾„={image_path}")

                    import imghdr 
                    actual_ext_imghdr = imghdr.what(None, h=image_bytes_for_verify) 
                    
                    if actual_ext_imghdr:
                        actual_ext = actual_ext_imghdr.lower()
                        if actual_ext == 'jpeg': actual_ext = 'jpg' 
                        logger.info(f"[{self.name}] imghdr detected extension: .{actual_ext} for cmsg {cmsg.msg_id}")
                    elif img_format_detected: 
                        actual_ext = img_format_detected.lower()
                        if actual_ext == 'jpeg': actual_ext = 'jpg'
                        logger.info(f"[{self.name}] imghdr failed, using PIL detected extension: .{actual_ext} for cmsg {cmsg.msg_id}")
                    else:
                        actual_ext = "jpg" 
                        logger.warning(f"[{self.name}] Could not determine image type via PIL or imghdr for cmsg {cmsg.msg_id}. Defaulting to '.jpg'.")

                    if hasattr(cmsg, 'img_aeskey') and cmsg.img_aeskey:
                        final_filename_aeskey = f"{cmsg.img_aeskey}.{actual_ext}"
                        final_new_path_aeskey = os.path.join(target_dir, final_filename_aeskey)
                        try:
                            if os.path.exists(final_new_path_aeskey) and final_new_path_aeskey != image_path:
                                os.remove(final_new_path_aeskey) 
                            shutil.move(image_path, final_new_path_aeskey) # Use shutil.move
                            logger.info(f"[{self.name}] Renamed cached image from {image_path} to {final_new_path_aeskey} using aeskey.")
                            final_verified_path = final_new_path_aeskey
                        except (OSError, shutil.Error) as e_rename_aes:
                            logger.error(f"[{self.name}] Failed to rename cached image {image_path} to use aeskey {final_new_path_aeskey}: {e_rename_aes}. Using original path.")
                            final_verified_path = image_path 
                    else: 
                        logger.warning(f"[{self.name}] No cmsg.img_aeskey found for msg {cmsg.msg_id}. Keeping original cache name: {image_path}")
                        final_verified_path = image_path 
                    
                    cmsg.image_path = final_verified_path
                    cmsg.content = final_verified_path 
                    cmsg.ctype = ContextType.IMAGE
                    cmsg._prepared = True
                    return True 

                except UnidentifiedImageError as unident_err:
                    logger.error(f"[{self.name}] å›¾ç‰‡éªŒè¯å¤±è´¥ (PILæ— æ³•è¯†åˆ«æ ¼å¼) for cmsg {cmsg.msg_id}: {unident_err}, æ–‡ä»¶: {image_path}")
                    if os.path.exists(image_path): os.remove(image_path)
                except ImportError: 
                    logger.warning(f"[{self.name}] PIL (Pillow) æˆ– imghdr åº“æœªå®‰è£…ï¼Œæ— æ³•å¯¹å›¾ç‰‡è¿›è¡Œä¸¥æ ¼éªŒè¯: {image_path}")
                    fsize = os.path.getsize(image_path) if os.path.exists(image_path) else 0
                    if fsize > 100: 
                        logger.info(f"[{self.name}] å›¾ç‰‡ä¸‹è½½å®Œæˆ (æ— ä¸¥æ ¼éªŒè¯ï¼Œå¤§å°: {fsize}B)ï¼Œè·¯å¾„: {image_path}")
                        if hasattr(cmsg, 'img_aeskey') and cmsg.img_aeskey:
                            final_name_no_pil_aes = f"{cmsg.img_aeskey}.jpg" 
                            final_new_path_no_pil_aes = os.path.join(target_dir, final_name_no_pil_aes)
                            try:
                                if os.path.exists(final_new_path_no_pil_aes) and final_new_path_no_pil_aes != image_path: 
                                    os.remove(final_new_path_no_pil_aes)
                                shutil.move(image_path, final_new_path_no_pil_aes) # Use shutil.move
                                final_verified_path = final_new_path_no_pil_aes
                                logger.info(f"[{self.name}] Renamed (no PIL) cached image from {image_path} to {final_verified_path} using aeskey.")
                            except (OSError, shutil.Error): 
                                final_verified_path = image_path
                                logger.error(f"[{self.name}] Failed to rename (no PIL) cached image {image_path} to use aeskey. Keeping original.")
                        else: 
                            final_verified_path = image_path
                            logger.warning(f"[{self.name}] No PIL and no aeskey. Keeping original name (no PIL): {image_path}")
                        
                        cmsg.image_path = final_verified_path
                        cmsg.content = final_verified_path
                        cmsg.ctype = ContextType.IMAGE
                        cmsg._prepared = True
                        return True
                    else:
                        logger.warning(f"[{self.name}] æ— ä¸¥æ ¼éªŒè¯ä¸”æ–‡ä»¶å¤§å° ({fsize}B) è¿‡å°/ä¸º0ï¼Œè§†ä¸ºæ— æ•ˆ: {image_path}")
                        if os.path.exists(image_path): os.remove(image_path)
                except Exception as pil_verify_err: 
                    logger.error(f"[{self.name}] å›¾ç‰‡éªŒè¯æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ for cmsg {cmsg.msg_id}: {pil_verify_err}, æ–‡ä»¶: {image_path}\\n{traceback.format_exc()}")
                    if os.path.exists(image_path): os.remove(image_path)
            
            logger.error(f"[{self.name}] å›¾ç‰‡ä¸‹è½½æˆ–éªŒè¯æœªèƒ½æˆåŠŸ for cmsg {cmsg.msg_id} (Path: {image_path}). download_stream_ok={download_stream_successful}, file_written_ok={file_written_successfully}, data_collected={bool(all_chunks_data_list)}.")
            if os.path.exists(image_path):
                try: os.remove(image_path); logger.info(f"[{self.name}] å·²åˆ é™¤ä¸‹è½½å¤±è´¥æˆ–éªŒè¯å¤±è´¥çš„å›¾ç‰‡æ–‡ä»¶: {image_path}")
                except Exception as e_rm_fail: logger.error(f"[{self.name}] åˆ é™¤å¤±è´¥çš„å›¾ç‰‡æ–‡ä»¶æ—¶å‡ºé”™ {image_path}: {e_rm_fail}")
            
            if cmsg: cmsg._prepared = False
            return False

        except Exception as outer_e: 
            logger.critical(f"[{self.name}] _download_image_by_chunks å‘ç”Ÿä¸¥é‡æ„å¤–é”™è¯¯ for cmsg {cmsg.msg_id}, path {image_path if 'image_path' in locals() else 'Unknown'}: {outer_e}\\n{traceback.format_exc()}")
            path_to_clean = image_path if 'image_path' in locals() and os.path.exists(image_path) else None
            if path_to_clean:
                try: os.remove(path_to_clean); logger.info(f"[{self.name}] æ„å¤–é”™è¯¯åï¼Œå·²å°è¯•åˆ é™¤å›¾ç‰‡æ–‡ä»¶: {path_to_clean}")
                except Exception as e_rm_outer: logger.error(f"[{self.name}] æ„å¤–é”™è¯¯åï¼Œåˆ é™¤å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {e_rm_outer}")
            if cmsg: cmsg._prepared = False
            return False
# MODIFIED_LINES_END
        
    async def _download_image_with_details(self, image_meta: dict, target_path: str) -> bool:
        """
        Downloads an image using detailed metadata, typically for referenced images.
        Uses chunked download.

        :param image_meta: Dict containing keys like 'msg_id_for_download', 'data_len', 
                           'aeskey', 'downloader_wxid', 'original_sender_wxid'.
        :param target_path: Full path where the image should be saved.
        :return: True if download and verification are successful, False otherwise.
        """
        import traceback
        import asyncio
        from io import BytesIO
        from PIL import Image, UnidentifiedImageError

        logger.info(f"[{self.name}] Attempting download with details: {image_meta} to {target_path}")

        try:
            # 1. Pre-check: Validate target_path and create directory
            tmp_dir = os.path.dirname(target_path)
            os.makedirs(tmp_dir, exist_ok=True)

            # 2. Get API config and calculate chunk info
            api_host = conf().get("wx859_api_host", "127.0.0.1")
            # For image downloads, often a specific media port is used, check if it's configured
            api_port = conf().get("wx859_api_port", conf().get("wx859_api_port", 9011)) 
            # å›ºå®šä½¿ç”¨859åè®®
            api_path_prefix = "/api"
            
            data_len_str = image_meta.get('data_len', '0')
            try:
                data_len = int(data_len_str)
            except ValueError:
                logger.error(f"[{self.name}] Invalid data_len '{data_len_str}' in image_meta. Using default 0.")
                data_len = 0
            
            if data_len <= 0: # If data_len is 0 or invalid, try a default or log an error
                logger.warning(f"[{self.name}] data_len is {data_len}. Download might be problematic or rely on API to handle it.")
                # Fallback or error handling for zero data_len might be needed depending on API behavior

            chunk_size = 65536  # 64KB
            num_chunks = (data_len + chunk_size - 1) // chunk_size if data_len > 0 else 1
            if data_len == 0 and num_chunks == 1: # Special case for potentially unknown length but expecting at least one chunk
                 logger.info(f"[{self.name}] data_len is 0, attempting to download as a single chunk of default size or as determined by API.")


            logger.info(f"[{self.name}] Downloading referenced image to: {target_path}, Total Size: {data_len} B, Chunks: {num_chunks}")

            # 3. Chunked download logic
            all_chunks_data_list = []
            download_stream_successful = True
            actual_downloaded_size = 0

            for i in range(num_chunks):
                start_pos = i * chunk_size
                current_chunk_size = min(chunk_size, data_len - start_pos) if data_len > 0 else chunk_size # Default to chunk_size if data_len is unknown
                
                if data_len > 0 and current_chunk_size <= 0: # Ensure we don't try to download 0 bytes if data_len was positive
                    logger.debug(f"[{self.name}] Calculated current_chunk_size <=0 with positive data_len. Breaking chunk loop. StartPos: {start_pos}, DataLen: {data_len}")
                    break

                # Ensure msg_id_for_download is an integer for the API call
                msg_id_for_api = None
                try:
                    msg_id_for_api = int(image_meta['msg_id_for_download'])
                except (ValueError, TypeError) as e:
                    logger.error(f"[{self.name}] RefDownload Chunk {i+1} Error: 'msg_id_for_download' ({image_meta.get('msg_id_for_download')}) is not a valid integer: {e}")
                    download_stream_successful = False
                    break

                params = {
                    "MsgId": msg_id_for_api, # MODIFIED: Use the integer version
                    "ToWxid": image_meta.get('original_sender_wxid'), # The user who originally sent the image
                    "Wxid": image_meta.get('downloader_wxid', self.wxid), # The WXID doing the download (our bot)
                    "DataLen": data_len, 
                    "CompressType": 0, 
                    "Section": {"StartPos": start_pos, "DataLen": current_chunk_size}
                }
                # Add aeskey if present and non-empty
                if image_meta.get('aeskey'):
                    params["Aeskey"] = image_meta['aeskey']

                api_url = f"http://{api_host}:{api_port}{api_path_prefix}/Tools/DownloadImg"
                logger.debug(f"[{self.name}] RefDownload Chunk {i+1}/{num_chunks}: URL={api_url}, Params={params}")

                try:
                    async with aiohttp.ClientSession() as session:
                        # Increased timeout for potentially slow media downloads
                        async with session.post(api_url, json=params, timeout=aiohttp.ClientTimeout(total=30)) as response:
                            if response.status != 200:
                                full_error_text = await response.text()
                                logger.error(f"[{self.name}] RefDownload Chunk {i+1} HTTP Error: {response.status}, Response: {full_error_text[:500]}")
                                download_stream_successful = False
                                break
                            
                            try:
                                result = await response.json()
                            except aiohttp.ContentTypeError:
                                raw_response_text = await response.text()
                                logger.error(f"[{self.name}] RefDownload Chunk {i+1} API Error: Non-JSON response. Status: {response.status}. Response text (first 500 chars): {raw_response_text[:500]}")
                                download_stream_successful = False
                                break
                            
                            if not result or not isinstance(result, dict):
                                logger.error(f"[{self.name}] RefDownload Chunk {i+1} API Error: Invalid or empty JSON response. FullResult: {result}")
                                download_stream_successful = False
                                break

                            if not result.get("Success", False):
                                logger.error(f"[{self.name}] RefDownload Chunk {i+1} API Error: {result.get('Message', 'Unknown API error')}, FullResult: {result}")
                                download_stream_successful = False
                                break
                            
                            data_payload = result.get("Data", {})
                            chunk_base64 = None
                            if isinstance(data_payload, dict):
                                if "buffer" in data_payload: chunk_base64 = data_payload["buffer"]
                                elif "data" in data_payload and isinstance(data_payload.get("data"), dict) and "buffer" in data_payload["data"]: chunk_base64 = data_payload["data"]["buffer"]
                                else: 
                                    for field in ["Chunk", "Image", "Data", "FileData"]: # Common field names
                                        if field in data_payload: chunk_base64 = data_payload.get(field); break
                            elif isinstance(data_payload, str): # Direct base64 string
                                chunk_base64 = data_payload
                            
                            if not chunk_base64 and isinstance(result, dict): # Fallback to check root result
                                 for field in ["data", "Data", "FileData", "Image"]:
                                     if field in result and result.get(field): chunk_base64 = result.get(field); break

                            if not chunk_base64:
                                logger.error(f"[{self.name}] RefDownload Chunk {i+1} Error: No image data found in API response. Response: {str(result)[:200]}")
                                download_stream_successful = False
                                break
                            
                            try:
                                if not isinstance(chunk_base64, str):
                                    if isinstance(chunk_base64, bytes):
                                        try: chunk_base64 = chunk_base64.decode('utf-8')
                                        except UnicodeDecodeError: raise ValueError("chunk_base64 is bytes but cannot be utf-8 decoded.")
                                    else: raise ValueError(f"chunk_base64 is not str or bytes: {type(chunk_base64)}")
                                
                                clean_base64 = chunk_base64.strip()
                                padding = (4 - len(clean_base64) % 4) % 4
                                clean_base64 += '=' * padding
                                chunk_data_bytes = base64.b64decode(clean_base64)
                                all_chunks_data_list.append(chunk_data_bytes)
                                actual_downloaded_size += len(chunk_data_bytes)
                                logger.debug(f"[{self.name}] RefDownload Chunk {i+1}/{num_chunks} decoded, size: {len(chunk_data_bytes)} B. Total so far: {actual_downloaded_size} B")
                            except Exception as decode_err:
                                logger.error(f"[{self.name}] RefDownload Chunk {i+1}/{num_chunks} Base64 decode error: {decode_err}. Data (first 100): {str(chunk_base64)[:100]}")
                                download_stream_successful = False
                                break
                except asyncio.TimeoutError:
                    logger.error(f"[{self.name}] RefDownload Chunk {i+1} timed out.")
                    download_stream_successful = False
                    break
                except Exception as api_call_err:
                    logger.error(f"[{self.name}] RefDownload Chunk {i+1} API call error: {api_call_err}\n{traceback.format_exc()}")
                    download_stream_successful = False
                    break
            
            # 4. Data writing, flushing, and syncing
            file_written_successfully = False
            if download_stream_successful and all_chunks_data_list:
                try:
                    with open(target_path, "wb") as f_write:
                        for chunk_piece in all_chunks_data_list:
                            f_write.write(chunk_piece)
                        f_write.flush()
                        if hasattr(os, 'fsync'): # fsync might not be available on all OS (e.g. some Windows setups)
                            try:
                                os.fsync(f_write.fileno())
                            except OSError as e_fsync:
                                logger.warning(f"[{self.name}] os.fsync failed for {target_path}: {e_fsync}. Continuing without fsync.")
                        else:
                            logger.debug(f"[{self.name}] os.fsync not available on this system.")

                    final_file_size = os.path.getsize(target_path)
                    logger.info(f"[{self.name}] RefDownload: All chunks written to disk: {target_path}, Actual Final Size: {final_file_size} B (Expected: {data_len} B, Downloaded: {actual_downloaded_size} B)")
                    if final_file_size == 0 and actual_downloaded_size > 0:
                        logger.error(f"[{self.name}] RefDownload WARNING: Data downloaded ({actual_downloaded_size}B) but written file size is 0! Path: {target_path}")
                    else:
                        file_written_successfully = True
                except IOError as io_err_write_final:
                    logger.error(f"[{self.name}] RefDownload: Failed to write or flush image file: {io_err_write_final}, Path: {target_path}")
                except Exception as e_write_final:
                    logger.error(f"[{self.name}] RefDownload: Unknown error during file write: {e_write_final}, Path: {target_path}\n{traceback.format_exc()}")
            elif not all_chunks_data_list and download_stream_successful:
                logger.warning(f"[{self.name}] RefDownload: API calls successful, but no data chunks collected for {target_path}.")
            
            # 5. Image Verification Stage
            if file_written_successfully:
                await asyncio.sleep(0.1) # Brief pause to ensure file system operations complete
                try:
                    with open(target_path, "rb") as f_read_verify_final:
                        image_bytes_for_verify_final = f_read_verify_final.read()
                    
                    if not image_bytes_for_verify_final:
                        logger.error(f"[{self.name}] RefDownload: Image file empty after download and read for verification: {target_path}")
                        raise UnidentifiedImageError("Downloaded image file is empty for verification.")

                    with Image.open(BytesIO(image_bytes_for_verify_final)) as img_final:
                        img_format_final = img_final.format
                        img_size_final = img_final.size
                        logger.info(f"[{self.name}] RefDownload: Image verification successful (PIL): Format={img_format_final}, Size={img_size_final}, Path={target_path}")
                        return True
                except UnidentifiedImageError as unident_err_final:
                    logger.error(f"[{self.name}] RefDownload: Image verification failed (PIL UnidentifiedImageError): {unident_err_final}, File: {target_path}")
                    if os.path.exists(target_path): os.remove(target_path)
                    return False
                except ImportError: # Should have been caught earlier, but as a safeguard
                    logger.warning("[WX859] RefDownload: PIL (Pillow) library not installed, cannot perform strict image verification.")
                    fsize_final_no_pil = os.path.getsize(target_path) if os.path.exists(target_path) else 0
                    if fsize_final_no_pil > 1000: # Heuristic: >1KB might be a valid small image
                        logger.info(f"[{self.name}] RefDownload: Image download likely complete (No PIL verification, size: {fsize_final_no_pil}B), Path: {target_path}")
                        return True
                    else:
                        logger.warning(f"[{self.name}] RefDownload: PIL not installed AND file size ({fsize_final_no_pil}B) is too small. Invalid: {target_path}")
                        if os.path.exists(target_path): os.remove(target_path)
                        return False
                except Exception as pil_verify_err_final:
                    logger.error(f"[{self.name}] RefDownload: Unknown PIL verification error: {pil_verify_err_final}, File: {target_path}\n{traceback.format_exc()}")
                    if os.path.exists(target_path): os.remove(target_path)
                    return False
            
            # 6. Final Failure Path (if not returned True already)
            logger.error(f"[{self.name}] RefDownload: Image download or verification failed. StreamOK={download_stream_successful}, WrittenOK={file_written_successfully}, DataCollected={bool(all_chunks_data_list)}. Path: {target_path}")
            if os.path.exists(target_path): # Cleanup if file exists but process failed
                try:
                    os.remove(target_path)
                    logger.info(f"[{self.name}] RefDownload: Deleted failed/unverified image file: {target_path}")
                except Exception as e_remove_cleanup:
                    logger.error(f"[{self.name}] RefDownload: Error deleting failed image file: {e_remove_cleanup}, Path: {target_path}")
            return False

        except Exception as outer_e_details:
            logger.critical(f"[{self.name}] _download_image_with_details: Critical unexpected error: {outer_e_details}\n{traceback.format_exc()}")
            path_to_cleanup_outer = target_path
            if path_to_cleanup_outer and os.path.exists(path_to_cleanup_outer):
                try: os.remove(path_to_cleanup_outer)
                except Exception as e_remove_critical: logger.error(f"[{self.name}] Critical error: Failed to cleanup {path_to_cleanup_outer}: {e_remove_critical}")
            return False

    def _get_image(self, msg_id):
        """è·å–å›¾ç‰‡æ•°æ®"""
        # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
        tmp_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp", "wx859_img_cache")

        # æŸ¥æ‰¾åŒ¹é…çš„å›¾ç‰‡æ–‡ä»¶
        if os.path.exists(tmp_dir):
            for filename in os.listdir(tmp_dir):
                if filename.startswith(f"img_{msg_id}_"):
                    image_path = os.path.join(tmp_dir, filename)
                    try:
                        # éªŒè¯å›¾ç‰‡æ–‡ä»¶æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å›¾ç‰‡æ ¼å¼
                        try:
                            from PIL import Image
                            try:
                                # å°è¯•æ‰“å¼€å›¾ç‰‡æ–‡ä»¶
                                with Image.open(image_path) as img:
                                    # è·å–å›¾ç‰‡æ ¼å¼å’Œå¤§å°
                                    img_format = img.format
                                    img_size = img.size
                                    logger.info(f"[WX859] å›¾ç‰‡éªŒè¯æˆåŠŸ: æ ¼å¼={img_format}, å¤§å°={img_size}")
                            except Exception as img_err:
                                logger.error(f"[WX859] å›¾ç‰‡éªŒè¯å¤±è´¥ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„å›¾ç‰‡æ–‡ä»¶: {img_err}")
                                # å°è¯•ä¿®å¤å›¾ç‰‡æ–‡ä»¶
                                try:
                                    # è¯»å–æ–‡ä»¶å†…å®¹
                                    with open(image_path, "rb") as f:
                                        img_data = f.read()

                                    # å°è¯•æŸ¥æ‰¾JPEGæ–‡ä»¶å¤´å’Œå°¾éƒ¨æ ‡è®°
                                    jpg_header = b'\xff\xd8'
                                    jpg_footer = b'\xff\xd9'

                                    if img_data.startswith(jpg_header) and img_data.endswith(jpg_footer):
                                        logger.info(f"[WX859] å›¾ç‰‡æ–‡ä»¶æœ‰æ•ˆçš„JPEGå¤´å°¾æ ‡è®°ï¼Œä½†å†…éƒ¨å¯èƒ½æœ‰æŸå")
                                    else:
                                        # æŸ¥æ‰¾JPEGå¤´éƒ¨æ ‡è®°çš„ä½ç½®
                                        header_pos = img_data.find(jpg_header)
                                        if header_pos >= 0:
                                            # æŸ¥æ‰¾JPEGå°¾éƒ¨æ ‡è®°çš„ä½ç½®
                                            footer_pos = img_data.rfind(jpg_footer)
                                            if footer_pos > header_pos:
                                                # æå–æœ‰æ•ˆçš„JPEGæ•°æ®
                                                valid_data = img_data[header_pos:footer_pos+2]
                                                # é‡å†™æ–‡ä»¶
                                                with open(image_path, "wb") as f:
                                                    f.write(valid_data)
                                                logger.info(f"[WX859] å°è¯•ä¿®å¤å›¾ç‰‡æ–‡ä»¶ï¼Œæå–äº† {len(valid_data)} å­—èŠ‚çš„æœ‰æ•ˆJPEGæ•°æ®")
                                                # è¿”å›ä¿®å¤åçš„æ•°æ®
                                                return valid_data
                                except Exception as fix_err:
                                    logger.error(f"[WX859] å°è¯•ä¿®å¤å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {fix_err}")
                        except ImportError:
                            logger.warning(f"[WX859] PILåº“æœªå®‰è£…ï¼Œæ— æ³•éªŒè¯å›¾ç‰‡æœ‰æ•ˆæ€§")

                        # è¯»å–å›¾ç‰‡æ–‡ä»¶
                        with open(image_path, "rb") as f:
                            image_data = f.read()
                            logger.info(f"[WX859] æˆåŠŸè¯»å–å›¾ç‰‡æ–‡ä»¶: {image_path}, å¤§å°: {len(image_data)} å­—èŠ‚")
                            return image_data
                    except Exception as e:
                        logger.error(f"[WX859] è¯»å–å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {e}")
                        return None

        logger.error(f"[WX859] æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: msg_id={msg_id}")
        return None

    def _process_voice_message(self, cmsg):
        """å¤„ç†è¯­éŸ³æ¶ˆæ¯"""
        import xml.etree.ElementTree as ET
        import re
        
        cmsg.ctype = ContextType.VOICE
        
        # ä¿å­˜åŸå§‹å†…å®¹ï¼Œé¿å…ä¿®æ”¹
        original_content = cmsg.content
        
        # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºXMLæ ¼å¼
        is_xml_content = original_content.strip().startswith("<?xml") or original_content.strip().startswith("<msg")
        
        # é¦–å…ˆå°è¯•ä»XMLä¸­æå–å‘é€è€…ä¿¡æ¯
        if is_xml_content:
            logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šå°è¯•ä»XMLæå–å‘é€è€…")
            try:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»XMLå­—ç¬¦ä¸²ä¸­æå–fromusernameå±æ€§æˆ–å…ƒç´ 
                match = re.search(r'fromusername\s*=\s*["\'](.*?)["\']', original_content)
                if match:
                    cmsg.sender_wxid = match.group(1)
                    logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šä»XMLå±æ€§æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                else:
                    # å°è¯•ä»å…ƒç´ ä¸­æå–
                    match = re.search(r'<fromusername>(.*?)</fromusername>', original_content)
                    if match:
                        cmsg.sender_wxid = match.group(1)
                        logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šä»XMLå…ƒç´ æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                    else:
                        logger.debug("[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šæœªæ‰¾åˆ°fromusername")
                        
                        # å°è¯•ä½¿ç”¨ElementTreeè§£æ
                        try:
                            root = ET.fromstring(original_content)
                            # å°è¯•æŸ¥æ‰¾è¯­éŸ³å…ƒç´ çš„fromusernameå±æ€§
                            voice_element = root.find('voicemsg')
                            if voice_element is not None and 'fromusername' in voice_element.attrib:
                                cmsg.sender_wxid = voice_element.attrib['fromusername']
                                logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šä½¿ç”¨ElementTreeæå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                        except Exception as e:
                            logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šä½¿ç”¨ElementTreeè§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šæå–å‘é€è€…å¤±è´¥: {e}")
                
        # å¦‚æœæ— æ³•ä»XMLæå–ï¼Œå†å°è¯•ä¼ ç»Ÿçš„åˆ†å‰²æ–¹æ³•
        if not cmsg.sender_wxid and (cmsg.is_group or cmsg.from_user_id.endswith("@chatroom")):
            cmsg.is_group = True
            split_content = original_content.split(":\n", 1)
            if len(split_content) > 1:
                cmsg.sender_wxid = split_content[0]
                logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šä½¿ç”¨åˆ†å‰²æ–¹æ³•æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
            else:
                # å¤„ç†æ²¡æœ‰æ¢è¡Œçš„æƒ…å†µ
                split_content = original_content.split(":", 1)
                if len(split_content) > 1:
                    cmsg.sender_wxid = split_content[0]
                    logger.debug(f"[WX859] è¯­éŸ³æ¶ˆæ¯ï¼šä½¿ç”¨å†’å·åˆ†å‰²æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
        
        # å¯¹äºç§èŠæ¶ˆæ¯ï¼Œä½¿ç”¨from_user_idä½œä¸ºå‘é€è€…ID
        if not cmsg.sender_wxid and not cmsg.is_group:
            cmsg.sender_wxid = cmsg.from_user_id
            cmsg.is_group = False
        
        # è®¾ç½®actual_user_idå’Œactual_user_nickname
        cmsg.actual_user_id = cmsg.sender_wxid or cmsg.from_user_id
        cmsg.actual_user_nickname = cmsg.sender_wxid or cmsg.from_user_id
        
        # è§£æè¯­éŸ³ä¿¡æ¯ (ä¿ç•™æ­¤åŠŸèƒ½ä»¥è·å–è¯­éŸ³URLç­‰ä¿¡æ¯)
        try:
            root = ET.fromstring(original_content)
            voice_element = root.find('voicemsg')
            if voice_element is not None:
                cmsg.voice_info = {
                    'voiceurl': voice_element.get('voiceurl'),
                    'length': voice_element.get('length')
                }
                logger.debug(f"è§£æè¯­éŸ³XMLæˆåŠŸ: voiceurl={cmsg.voice_info['voiceurl']}, length={cmsg.voice_info['length']}")
        except Exception as e:
            logger.debug(f"è§£æè¯­éŸ³æ¶ˆæ¯å¤±è´¥: {e}, å†…å®¹: {original_content[:100]}")
            cmsg.voice_info = {}
            
        # ç¡®ä¿ä¿ç•™åŸå§‹XMLå†…å®¹
        cmsg.content = original_content
        
        # æœ€ç»ˆæ£€æŸ¥ï¼Œç¡®ä¿å‘é€è€…ä¸æ˜¯XMLå†…å®¹
        if not cmsg.sender_wxid or "<" in cmsg.sender_wxid:
            cmsg.sender_wxid = "æœªçŸ¥å‘é€è€…"
            cmsg.actual_user_id = cmsg.sender_wxid
            cmsg.actual_user_nickname = cmsg.sender_wxid
        
        # è¾“å‡ºæ—¥å¿—ï¼Œæ˜¾ç¤ºå®Œæ•´XMLå†…å®¹
        logger.info(f"æ”¶åˆ°è¯­éŸ³æ¶ˆæ¯: ID:{cmsg.msg_id} æ¥è‡ª:{cmsg.from_user_id} å‘é€äºº:{cmsg.sender_wxid}\nXMLå†…å®¹: {cmsg.content}")

    def _process_video_message(self, cmsg):
        """å¤„ç†è§†é¢‘æ¶ˆæ¯"""
        import xml.etree.ElementTree as ET
        import re
        
        cmsg.ctype = ContextType.VIDEO
        
        # ä¿å­˜åŸå§‹å†…å®¹ï¼Œé¿å…ä¿®æ”¹
        original_content = cmsg.content
        
        # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºXMLæ ¼å¼
        is_xml_content = original_content.strip().startswith("<?xml") or original_content.strip().startswith("<msg")
        
        # é¦–å…ˆå°è¯•ä»XMLä¸­æå–å‘é€è€…ä¿¡æ¯
        if is_xml_content:
            logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šå°è¯•ä»XMLæå–å‘é€è€…")
            try:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»XMLå­—ç¬¦ä¸²ä¸­æå–fromusernameå±æ€§æˆ–å…ƒç´ 
                match = re.search(r'fromusername\s*=\s*["\'](.*?)["\']', original_content)
                if match:
                    cmsg.sender_wxid = match.group(1)
                    logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šä»XMLå±æ€§æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                else:
                    # å°è¯•ä»å…ƒç´ ä¸­æå–
                    match = re.search(r'<fromusername>(.*?)</fromusername>', original_content)
                    if match:
                        cmsg.sender_wxid = match.group(1)
                        logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šä»XMLå…ƒç´ æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                    else:
                        logger.debug("[WX859] è§†é¢‘æ¶ˆæ¯ï¼šæœªæ‰¾åˆ°fromusername")
                        
                        # å°è¯•ä½¿ç”¨ElementTreeè§£æ
                        try:
                            root = ET.fromstring(original_content)
                            # å°è¯•æŸ¥æ‰¾videoå…ƒç´ çš„fromusernameå±æ€§
                            video_element = root.find('videomsg')
                            if video_element is not None and 'fromusername' in video_element.attrib:
                                cmsg.sender_wxid = video_element.attrib['fromusername']
                                logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šä½¿ç”¨ElementTreeæå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                        except Exception as e:
                            logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šä½¿ç”¨ElementTreeè§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šæå–å‘é€è€…å¤±è´¥: {e}")
                
        # å¦‚æœæ— æ³•ä»XMLæå–ï¼Œå†å°è¯•ä¼ ç»Ÿçš„åˆ†å‰²æ–¹æ³•
        if not cmsg.sender_wxid and (cmsg.is_group or cmsg.from_user_id.endswith("@chatroom")):
            cmsg.is_group = True
            split_content = original_content.split(":\n", 1)
            if len(split_content) > 1:
                cmsg.sender_wxid = split_content[0]
                logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šä½¿ç”¨åˆ†å‰²æ–¹æ³•æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
            else:
                # å¤„ç†æ²¡æœ‰æ¢è¡Œçš„æƒ…å†µ
                split_content = original_content.split(":", 1)
                if len(split_content) > 1:
                    cmsg.sender_wxid = split_content[0]
                    logger.debug(f"[WX859] è§†é¢‘æ¶ˆæ¯ï¼šä½¿ç”¨å†’å·åˆ†å‰²æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
        
        # å¯¹äºç§èŠæ¶ˆæ¯ï¼Œä½¿ç”¨from_user_idä½œä¸ºå‘é€è€…ID
        if not cmsg.sender_wxid and not cmsg.is_group:
            cmsg.sender_wxid = cmsg.from_user_id
            cmsg.is_group = False
            
        # è®¾ç½®actual_user_idå’Œactual_user_nickname
        cmsg.actual_user_id = cmsg.sender_wxid or cmsg.from_user_id
        cmsg.actual_user_nickname = cmsg.sender_wxid or cmsg.from_user_id
            
        # ç¡®ä¿ä¿ç•™åŸå§‹XMLå†…å®¹
        cmsg.content = original_content
        
        # æœ€ç»ˆæ£€æŸ¥ï¼Œç¡®ä¿å‘é€è€…ä¸æ˜¯XMLå†…å®¹
        if not cmsg.sender_wxid or "<" in cmsg.sender_wxid:
            cmsg.sender_wxid = "æœªçŸ¥å‘é€è€…"
            cmsg.actual_user_id = cmsg.sender_wxid
            cmsg.actual_user_nickname = cmsg.sender_wxid
        
        # è¾“å‡ºæ—¥å¿—ï¼Œæ˜¾ç¤ºå®Œæ•´XMLå†…å®¹
        logger.info(f"æ”¶åˆ°è§†é¢‘æ¶ˆæ¯: ID:{cmsg.msg_id} æ¥è‡ª:{cmsg.from_user_id} å‘é€äºº:{cmsg.sender_wxid}\nXMLå†…å®¹: {cmsg.content}")

    def _process_emoji_message(self, cmsg):
        """å¤„ç†è¡¨æƒ…æ¶ˆæ¯"""
        import xml.etree.ElementTree as ET
        import re
        
        cmsg.ctype = ContextType.TEXT  # è¡¨æƒ…æ¶ˆæ¯é€šå¸¸ä¹Ÿç”¨TEXTç±»å‹
        
        # ä¿å­˜åŸå§‹å†…å®¹ï¼Œé¿å…ä¿®æ”¹
        original_content = cmsg.content
        
        # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºXMLæ ¼å¼
        is_xml_content = original_content.strip().startswith("<?xml") or original_content.strip().startswith("<msg")
        
        # é¦–å…ˆå°è¯•ä»XMLä¸­æå–å‘é€è€…ä¿¡æ¯
        if is_xml_content:
            logger.debug(f"[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šå°è¯•ä»XMLæå–å‘é€è€…")
            try:
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»XMLä¸­æå–fromusernameå±æ€§
                match = re.search(r'fromusername\s*=\s*["\'](.*?)["\']', original_content)
                if match:
                    cmsg.sender_wxid = match.group(1)
                    logger.debug(f"[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šä»XMLæå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                else:
                    logger.debug("[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šæœªæ‰¾åˆ°fromusernameå±æ€§")
                    
                    # å°è¯•ä½¿ç”¨ElementTreeè§£æ
                    try:
                        root = ET.fromstring(original_content)
                        emoji_element = root.find('emoji')
                        if emoji_element is not None and 'fromusername' in emoji_element.attrib:
                            cmsg.sender_wxid = emoji_element.attrib['fromusername']
                            logger.debug(f"[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šä½¿ç”¨ElementTreeæå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
                    except Exception as e:
                        logger.debug(f"[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šä½¿ç”¨ElementTreeè§£æå¤±è´¥: {e}")
            except Exception as e:
                logger.debug(f"[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šæå–å‘é€è€…å¤±è´¥: {e}")
                
        # å¦‚æœæ— æ³•ä»XMLæå–ï¼Œå†å°è¯•ä¼ ç»Ÿçš„åˆ†å‰²æ–¹æ³•
        if not cmsg.sender_wxid and (cmsg.is_group or cmsg.from_user_id.endswith("@chatroom")):
            cmsg.is_group = True
            split_content = original_content.split(":\n", 1)
            if len(split_content) > 1:
                cmsg.sender_wxid = split_content[0]
                logger.debug(f"[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šä½¿ç”¨åˆ†å‰²æ–¹æ³•æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
            else:
                # å¤„ç†æ²¡æœ‰æ¢è¡Œçš„æƒ…å†µ
                split_content = original_content.split(":", 1)
                if len(split_content) > 1:
                    cmsg.sender_wxid = split_content[0]
                    logger.debug(f"[WX859] è¡¨æƒ…æ¶ˆæ¯ï¼šä½¿ç”¨å†’å·åˆ†å‰²æå–çš„å‘é€è€…ID: {cmsg.sender_wxid}")
        
        # å¯¹äºç§èŠæ¶ˆæ¯ï¼Œä½¿ç”¨from_user_idä½œä¸ºå‘é€è€…ID
        if not cmsg.sender_wxid and not cmsg.is_group:
            cmsg.sender_wxid = cmsg.from_user_id
            cmsg.is_group = False
            
        # è®¾ç½®actual_user_idå’Œactual_user_nickname
        cmsg.actual_user_id = cmsg.sender_wxid or cmsg.from_user_id
        cmsg.actual_user_nickname = cmsg.sender_wxid or cmsg.from_user_id
            
        # ç¡®ä¿ä¿ç•™åŸå§‹XMLå†…å®¹
        cmsg.content = original_content
        
        # æœ€ç»ˆæ£€æŸ¥ï¼Œç¡®ä¿å‘é€è€…ä¸æ˜¯XMLå†…å®¹
        if not cmsg.sender_wxid or "<" in cmsg.sender_wxid:
            cmsg.sender_wxid = "æœªçŸ¥å‘é€è€…"
            cmsg.actual_user_id = cmsg.sender_wxid
            cmsg.actual_user_nickname = cmsg.sender_wxid
        
        # è¾“å‡ºæ—¥å¿—ï¼Œæ˜¾ç¤ºå®Œæ•´XMLå†…å®¹
        logger.info(f"æ”¶åˆ°è¡¨æƒ…æ¶ˆæ¯: ID:{cmsg.msg_id} æ¥è‡ª:{cmsg.from_user_id} å‘é€äºº:{cmsg.sender_wxid} \nXMLå†…å®¹: {cmsg.content}")

    def _process_xml_message(self, cmsg: WX859Message):
        """
        å¤„ç† XML ç±»å‹çš„æ¶ˆæ¯ï¼Œä¸»è¦æ˜¯ Type 57 å¼•ç”¨å’Œ Type 5 åˆ†äº«é“¾æ¥ã€‚
        ä¼šä¿®æ”¹ cmsg çš„ ctype å’Œ content å±æ€§ã€‚
        """
        import xml.etree.ElementTree as ET
        import re 
        import asyncio 
        import os 
        import time 
        import traceback
        import tempfile 
        import threading 
        from bridge.context import ContextType 

        # åˆå§‹åŒ–msg_xmlå˜é‡ï¼Œé¿å…UnboundLocalError
        msg_xml = None
        
        # å¤„ç†ç¾¤èŠæ¶ˆæ¯ä¸­çš„å‘é€è€…å‰ç¼€é—®é¢˜
        xml_content = cmsg.content
        if cmsg.is_group and ":" in xml_content and xml_content.startswith("wxid_"):
            # ç¾¤èŠæ¶ˆæ¯æ ¼å¼: "wxid_xxx:\n<?xml version..."
            # éœ€è¦å»æ‰å‘é€è€…å‰ç¼€ï¼Œåªä¿ç•™XMLéƒ¨åˆ†
            lines = xml_content.split('\n', 1)
            if len(lines) > 1 and lines[1].strip().startswith('<?xml'):
                xml_content = lines[1]
                logger.debug(f"[{self.name}] ç¾¤èŠæ¶ˆæ¯å»é™¤å‘é€è€…å‰ç¼€åçš„XML: {xml_content[:100]}...")
        
        try:
            msg_xml = ET.fromstring(xml_content)
            appmsg = msg_xml.find("appmsg")

            # 1. å¤„ç†å¼•ç”¨æ¶ˆæ¯ (Type 57)
            if appmsg is not None and appmsg.findtext("type") == "57":
                refermsg = appmsg.find("refermsg")
                if refermsg is not None:
                    refer_type = refermsg.findtext("type")
                    title = appmsg.findtext("title") # User's question part / command
                    displayname = refermsg.findtext("displayname") # Quoter's display name

                    # 1.1 å¤„ç†æ–‡æœ¬å¼•ç”¨ (refermsg type=1)
                    if refer_type == "1":
                        quoted_text = refermsg.findtext("content")
                        if title and displayname and quoted_text:
                            prompt = (
                                f"ç”¨æˆ·é’ˆå¯¹ä»¥ä¸‹æ¶ˆæ¯æé—®ï¼š\"{title}\"\n\n"
                                f"è¢«å¼•ç”¨çš„æ¶ˆæ¯æ¥è‡ª\"{displayname}\"ï¼š\n\"{quoted_text}\"\n\n"
                                f"è¯·åŸºäºè¢«å¼•ç”¨çš„æ¶ˆæ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"
                            )
                            cmsg.content = prompt
                            cmsg.is_processed_text_quote = True 
                            cmsg.ctype = ContextType.TEXT 
                            logger.info(f"[{self.name}] Processed text quote msg {cmsg.msg_id}. Set type to TEXT.")
                            return 

                    # 1.2 å¤„ç†type=49çš„å¼•ç”¨æ¶ˆæ¯ï¼ˆèŠå¤©è®°å½•ã€æ–‡ä»¶ç­‰ï¼‰
                    elif refer_type == "49":
                        quoted_content_raw = refermsg.findtext("content")
                        if quoted_content_raw:
                            try:
                                inner_xml_root = ET.fromstring(quoted_content_raw)
                                inner_appmsg = inner_xml_root.find("appmsg")
                                
                                if inner_appmsg is not None:
                                    inner_type = inner_appmsg.findtext("type")
                                    
                                    # å¤„ç†èŠå¤©è®°å½•å¼•ç”¨ (inner appmsg type=19)
                                    if inner_type == "19": 
                                        chat_record_desc = inner_appmsg.findtext("des") 
                                        if title and displayname and chat_record_desc:
                                            prompt = (
                                                f"ç”¨æˆ·é’ˆå¯¹ä»¥ä¸‹èŠå¤©è®°å½•æé—®ï¼š\"{title}\"\n\n"
                                                f"è¢«å¼•ç”¨çš„èŠå¤©è®°å½•æ¥è‡ª\"{displayname}\"ï¼š\nï¼ˆæ‘˜è¦ï¼š{chat_record_desc}ï¼‰\n\n"
                                                f"è¯·åŸºäºè¢«å¼•ç”¨çš„èŠå¤©è®°å½•å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼ˆæ³¨æ„ï¼šèŠå¤©è®°å½•å¯èƒ½åŒ…å«å¤šæ¡æ¶ˆæ¯ï¼‰ã€‚"
                                            )
                                            cmsg.content = prompt
                                            cmsg.is_processed_text_quote = True 
                                            cmsg.ctype = ContextType.TEXT
                                            logger.info(f"[{self.name}] Processed chat record quote msg {cmsg.msg_id}. Set type to TEXT.")
                                            return 
                                    
                                    # å¤„ç†æ–‡ä»¶å¼•ç”¨ (inner appmsg type=6 or 74)
                                    elif inner_type in ["6", "74"]:
                                        # æå–æ–‡ä»¶ä¿¡æ¯
                                        file_title = inner_appmsg.findtext("title")
                                        inner_appattach = inner_appmsg.find("appattach")
                                        
                                        if inner_appattach is not None:
                                            file_attachid = inner_appattach.findtext("attachid")
                                            file_ext = inner_appattach.findtext("fileext")
                                            file_size = inner_appattach.findtext("totallen")
                                            
                                            if file_attachid and hasattr(self, 'file_cache_dir') and self.file_cache_dir:
                                                logger.debug(f"[{self.name}] Msg {cmsg.msg_id} (Type 57 quote, refer_type=49) references file with attachid: {file_attachid}. User command: '{title}'. Original file: {file_title}")
                                                
                                                # ğŸ”¥ æ–°æ–¹æ¡ˆï¼šä½¿ç”¨æ˜ å°„è¡¨æŸ¥æ‰¾æ–‡ä»¶
                                                found_cached_path = None
                                                mapping_file = os.path.join(self.file_cache_dir, "file_mapping.json")
                                                
                                                # é¦–å…ˆå°è¯•ä»æ˜ å°„è¡¨ä¸­æŸ¥æ‰¾
                                                if os.path.exists(mapping_file):
                                                    try:
                                                        with open(mapping_file, 'r', encoding='utf-8') as f:
                                                            mapping = json.load(f)
                                                        
                                                        # ç²¾ç¡®åŒ¹é…
                                                        if file_attachid in mapping:
                                                            cached_filename = mapping[file_attachid]['cached_filename']
                                                            potential_path = os.path.join(self.file_cache_dir, cached_filename)
                                                            if os.path.exists(potential_path):
                                                                found_cached_path = potential_path
                                                                logger.info(f"[{self.name}] æ˜ å°„è¡¨ç²¾ç¡®åŒ¹é…æ‰¾åˆ°ç¼“å­˜æ–‡ä»¶: {potential_path}")
                                                        
                                                        # å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
                                                        if not found_cached_path:
                                                            for stored_attachid, file_info in mapping.items():
                                                                # æ¯”è¾ƒattachidçš„ç›¸ä¼¼åº¦ï¼ˆå‰50ä¸ªå­—ç¬¦ï¼‰
                                                                if (len(file_attachid) > 50 and len(stored_attachid) > 50 and 
                                                                    file_attachid[:50] == stored_attachid[:50]):
                                                                    cached_filename = file_info['cached_filename']
                                                                    potential_path = os.path.join(self.file_cache_dir, cached_filename)
                                                                    if os.path.exists(potential_path):
                                                                        found_cached_path = potential_path
                                                                        logger.info(f"[{self.name}] æ˜ å°„è¡¨æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°ç¼“å­˜æ–‡ä»¶: {potential_path}")
                                                                        break
                                                                
                                                                # ä¹Ÿå°è¯•é€šè¿‡æ–‡ä»¶ååŒ¹é…
                                                                if (file_title and 
                                                                    file_info.get('original_filename') == file_title):
                                                                    cached_filename = file_info['cached_filename']
                                                                    potential_path = os.path.join(self.file_cache_dir, cached_filename)
                                                                    if os.path.exists(potential_path):
                                                                        found_cached_path = potential_path
                                                                        logger.info(f"[{self.name}] æ˜ å°„è¡¨æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°ç¼“å­˜æ–‡ä»¶: {potential_path}")
                                                                        break
                                                        
                                                    except Exception as e:
                                                        logger.warning(f"[{self.name}] è¯»å–æ–‡ä»¶æ˜ å°„è¡¨å¤±è´¥: {e}")
                                                
                                                # å¦‚æœæ˜ å°„è¡¨æŸ¥æ‰¾å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•
                                                if not found_cached_path:
                                                    logger.debug(f"[{self.name}] æ˜ å°„è¡¨æŸ¥æ‰¾å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿæ–¹æ³•æŸ¥æ‰¾æ–‡ä»¶")
                                                    possible_extensions = [file_ext] if file_ext else ['.pdf', '.docx', '.xlsx', '.txt', '.jpg', '.png']
                                                    
                                                    # éå†ç¼“å­˜ç›®å½•æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
                                                    try:
                                                        import glob
                                                        for filename in os.listdir(self.file_cache_dir):
                                                            if filename.endswith('.json'):  # è·³è¿‡æ˜ å°„æ–‡ä»¶
                                                                continue
                                                            
                                                            # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«æ–‡ä»¶æ ‡é¢˜
                                                            if file_title and file_title.lower() in filename.lower():
                                                                potential_path = os.path.join(self.file_cache_dir, filename)
                                                                if os.path.exists(potential_path):
                                                                    found_cached_path = potential_path
                                                                    logger.info(f"[{self.name}] ä¼ ç»Ÿæ–¹æ³•é€šè¿‡æ–‡ä»¶åæ‰¾åˆ°ç¼“å­˜æ–‡ä»¶: {potential_path}")
                                                                    break
                                                    except Exception as glob_error:
                                                        logger.warning(f"[{self.name}] ä¼ ç»Ÿæ–‡ä»¶æŸ¥æ‰¾è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {glob_error}")
                                                
                                                if found_cached_path:
                                                    logger.info(f"[{self.name}] Found cached file for attachid {file_attachid} at {found_cached_path} for msg {cmsg.msg_id}")
                                                    
                                                    cmsg.content = title if title else ""
                                                    cmsg.ctype = ContextType.TEXT
                                                    cmsg.original_user_question = title if title else ""
                                                    cmsg.referenced_file_path = found_cached_path
                                                    cmsg.is_processed_file_quote = True
                                                    
                                                    if displayname:
                                                        cmsg.quoter_display_name = displayname
                                                    cmsg.quoted_file_id = file_attachid
                                                    cmsg.quoted_file_title = file_title
                                                    cmsg.quoted_file_ext = file_ext
                                                    
                                                    # å°è¯•ä»æ˜ å°„è¡¨ä¸­è·å–æ–‡ä»¶å…ƒä¿¡æ¯
                                                    try:
                                                        if os.path.exists(mapping_file):
                                                            with open(mapping_file, 'r', encoding='utf-8') as f:
                                                                mapping = json.load(f)
                                                            
                                                            # æŸ¥æ‰¾å¯¹åº”çš„å…ƒä¿¡æ¯
                                                            for stored_attachid, file_info in mapping.items():
                                                                if (stored_attachid == file_attachid or 
                                                                    file_info.get('cached_filename') == os.path.basename(found_cached_path)):
                                                                    cmsg.quoted_file_meta = file_info
                                                                    break
                                                    except Exception as meta_error:
                                                        logger.warning(f"[{self.name}] è¯»å–æ–‡ä»¶å…ƒä¿¡æ¯å¤±è´¥: {meta_error}")
                                                    
                                                    logger.info(f"[{self.name}] Successfully processed referenced file (from cache) for msg {cmsg.msg_id}. Set ctype=TEXT. Path: {cmsg.referenced_file_path}")
                                                    return  # åœæ­¢è¿›ä¸€æ­¥å¤„ç†
                                                else:
                                                    logger.warning(f"[{self.name}] Referenced file with attachid {file_attachid} not found in cache ({self.file_cache_dir}) for msg {cmsg.msg_id}.")
                                            else:
                                                if not file_attachid:
                                                    logger.warning(f"[{self.name}] Referenced file in msg {cmsg.msg_id} has no attachid, cannot look up in cache.")
                                                if not (hasattr(self, 'file_cache_dir') and self.file_cache_dir):
                                                    logger.error(f"[{self.name}] File cache directory not configured. Cannot look up referenced file for msg {cmsg.msg_id}")
                                    # å¤„ç†å¾®ä¿¡å…¬ä¼—å·æ–‡ç« å¼•ç”¨ (inner appmsg type=5)
                                    elif inner_type == "5":
                                        article_url = inner_appmsg.findtext("url")
                                        article_title = inner_appmsg.findtext("title")
                                        article_des = inner_appmsg.findtext("des")
                                        
                                        if article_url and title and displayname:
                                            # ä¿®å¤URLåè®®å¤„ç†é€»è¾‘
                                            if not article_url.startswith("http"):
                                                if article_url.startswith("//"):
                                                    article_url = "https:" + article_url
                                                else:
                                                    article_url = "https://" + article_url
                                            
                                            # æ„å»ºå¼•ç”¨å¾®ä¿¡å…¬ä¼—å·æ–‡ç« çš„æç¤ºä¿¡æ¯
                                            # å°†ç”¨æˆ·æŒ‡ä»¤æ”¾åœ¨æœ€å‰é¢ï¼Œä¾¿äºæ’ä»¶è¯†åˆ«
                                            prompt = (
                                                f"{title}\n"
                                                f"æ ‡é¢˜ï¼š{article_title}\n"
                                                f"æè¿°ï¼š{article_des}\n"
                                                f"é“¾æ¥ï¼š{article_url}\n"
                                                f"å‘é€è€…ï¼š\"{displayname}\""
                                            )
                                            
                                            cmsg.content = prompt
                                            cmsg.is_processed_text_quote = True
                                            cmsg.ctype = ContextType.TEXT
                                            
                                            # ä¿å­˜åŸå§‹XMLå†…å®¹ï¼Œä¾›è±†åŒ…æ’ä»¶ä½¿ç”¨
                                            cmsg.original_xml_content = xml_content
                                            
                                            logger.info(f"[{self.name}] Processed WeChat article quote msg {cmsg.msg_id}. Article: {article_title}, URL: {article_url[:100]}...")
                                            return
                                    
                                    # å…¶ä»–ç±»å‹çš„type=49å¼•ç”¨æ¶ˆæ¯
                                    else:
                                        logger.debug(f"[{self.name}] Type 49 refermsg with inner appmsg type '{inner_type}' not specifically handled for msg {cmsg.msg_id}")
                                        
                            except ET.ParseError:
                                logger.debug(f"[{self.name}] Inner XML parsing failed for type 49 refermsg content in msg {cmsg.msg_id}")
                            except Exception as e_inner:
                                logger.warning(f"[{self.name}] Error processing inner XML for type 49 refermsg in msg {cmsg.msg_id}: {e_inner}")
                    
                    # MODIFICATION START: Handling for referenced image (refer_type == '3' implied by finding 'img' node)
                    elif refer_type == "3" and (quoted_content_raw := refermsg.findtext("content")): 
                        # This 'elif' specifically targets Type 3 (image) references if an explicit check for refer_type is desired.
                        # The original code relied on finding an 'img' node within the quoted_content_raw.
                        
                        original_image_svrid = refermsg.findtext("svrid") # Still useful for logging/context
                        
                        try:
                            inner_xml_root = ET.fromstring(quoted_content_raw)
                            img_node = inner_xml_root.find("img")

                            if img_node is not None:
                                extracted_refer_aeskey = img_node.get("aeskey")
                                # title and displayname are already defined above for Type 57

                                if extracted_refer_aeskey and hasattr(self, 'image_cache_dir') and self.image_cache_dir:
                                    logger.debug(f"[{self.name}] Msg {cmsg.msg_id} (Type 57 quote) references image with aeskey: {extracted_refer_aeskey}. User command: '{title}'. Original svrid: {original_image_svrid}")
                                    
                                    found_cached_path = None
                                    # Try common extensions or the extension determined during caching
                                    # Assuming caching logic (Phase A3) saves with original extension or defaults to .jpg
                                    # Let's try common ones, prioritising .jpg
                                    possible_extensions = ['.jpg', '.jpeg', '.png', '.gif'] 
                                    # A more robust way would be to store file extension along with aeskey if it can vary
                                    # or ensure a consistent extension like .jpg during caching.
                                    
                                    for ext in possible_extensions:
                                        # Ensure consistent naming with caching logic (Phase A3)
                                        # Example: cached_file_name = f"{cmsg.img_aeskey}{file_extension}"
                                        potential_path = os.path.join(self.image_cache_dir, f"{extracted_refer_aeskey}{ext}")
                                        if os.path.exists(potential_path):
                                            found_cached_path = potential_path
                                            break
                                    
                                    if found_cached_path:
                                        logger.info(f"[{self.name}] Found cached image for aeskey {extracted_refer_aeskey} at {found_cached_path} for msg {cmsg.msg_id}")
                                        
                                        cmsg.content = title if title else "" 
                                        cmsg.ctype = ContextType.TEXT
                                        cmsg.original_user_question = title if title else "" 
                                        cmsg.referenced_image_path = found_cached_path
                                        cmsg.is_processed_image_quote = True 
                                        
                                        if displayname:
                                            cmsg.quoter_display_name = displayname
                                        cmsg.quoted_image_id = extracted_refer_aeskey # Using aeskey as a quoted image identifier
                                        
                                        logger.info(f"[{self.name}] Successfully processed referenced image (from cache) for msg {cmsg.msg_id}. Set ctype=TEXT. Path: {cmsg.referenced_image_path}")
                                        return # Crucial: stop further processing of this XML
                                    else:
                                        logger.warning(f"[{self.name}] Referenced image with aeskey {extracted_refer_aeskey} not found in cache ({self.image_cache_dir}) for msg {cmsg.msg_id}. Fallback: No API download configured for this path.")
                                        # If you had a working API download as fallback, it would go here.
                                        # For now, if not in cache, it will be treated as an unhandled Type 57 quote.

                                else: # extracted_refer_aeskey is None or image_cache_dir not set
                                    if not extracted_refer_aeskey:
                                        logger.warning(f"[{self.name}] Referenced image in msg {cmsg.msg_id} has no aeskey in its XML, cannot look up in cache.")
                                    if not (hasattr(self, 'image_cache_dir') and self.image_cache_dir):
                                         logger.error(f"[{self.name}] Image cache directory not configured. Cannot look up referenced image for msg {cmsg.msg_id}")

                            # else: img_node was None (not an image reference within the content)
                            # This case would also fall through.

                        except ET.ParseError as e_parse_inner:
                            logger.debug(f"[{self.name}] Failed to parse inner XML for referenced msg content in msg {cmsg.msg_id}: {e_parse_inner}. Content: {quoted_content_raw[:100] if quoted_content_raw else 'None'}")
                        except Exception as e_proc_ref_img: 
                            logger.error(f"[{self.name}] Error processing potential image reference in msg {cmsg.msg_id}: {e_proc_ref_img}\n{traceback.format_exc()}")
                    # MODIFICATION END
                    

                    # Fallback for unhandled Type 57 messages (if not text, chat record, image quote, or file quote)
                    if not (hasattr(cmsg, 'is_processed_text_quote') and cmsg.is_processed_text_quote or \
                            hasattr(cmsg, 'is_processed_image_quote') and cmsg.is_processed_image_quote or \
                            hasattr(cmsg, 'is_processed_file_quote') and cmsg.is_processed_file_quote):
                        logger.debug(f"[{self.name}] Unhandled Type 57 refermsg (type='{refer_type}') in msg {cmsg.msg_id}. Title: '{title}'. Will be treated as generic XML.")
                        if title:
                             cmsg.content = f"ç”¨æˆ·å¼•ç”¨äº†ä¸€ä¸ªæ¶ˆæ¯å¹¶æé—®ï¼š\"{title}\" (ç±»å‹ï¼š{refer_type}ï¼Œæœªç‰¹æ®Šå¤„ç†)"
                        else:
                             cmsg.content = f"ç”¨æˆ·å¼•ç”¨äº†ä¸€ä¸ªæœªå¤„ç†ç±»å‹çš„æ¶ˆæ¯ (ç±»å‹ï¼š{refer_type})"
                        cmsg.ctype = ContextType.XML 

            elif appmsg is not None and appmsg.findtext("type") == "5":
                url = appmsg.findtext("url")
                link_title = appmsg.findtext("title") 
                if url:
                    # ä¿®å¤URLåè®®å¤„ç†é€»è¾‘
                    if not url.startswith("http"):
                        if url.startswith("//"):
                            url = "https:" + url  # å¯¹äº//å¼€å¤´çš„URLï¼Œæ·»åŠ httpsåè®®
                        else:
                            url = "https://" + url  # å¯¹äºå…¶ä»–æƒ…å†µï¼Œæ·»åŠ å®Œæ•´çš„https://
                    if "." in url and " " not in url: # Basic URL validation
                        cmsg.content = url 
                        cmsg.ctype = ContextType.SHARING 
                        logger.info(f"[{self.name}] Processed sharing link msg {cmsg.msg_id}. URL: {url}, Title: {link_title}")
                        return 
                    else:
                         logger.warning(f"[{self.name}] Invalid URL extracted from sharing link msg {cmsg.msg_id}: {url}")
                else:
                    logger.warning(f"[{self.name}] Sharing link msg {cmsg.msg_id} has no URL.")
            
            # å¤„ç†æ–‡ä»¶æ¶ˆæ¯ (Type 6 å’Œ Type 74)
            elif appmsg is not None and appmsg.findtext("type") in ["6", "74"]:
                file_title = appmsg.findtext("title")
                file_type = appmsg.findtext("type")
                appattach = appmsg.find("appattach")
                
                if appattach is not None:
                    file_ext = appattach.findtext("fileext")
                    file_size = appattach.findtext("totallen")
                    
                    logger.info(f"[{self.name}] æ£€æµ‹åˆ°æ–‡ä»¶æ¶ˆæ¯ (type={file_type}): {file_title}, æ‰©å±•å: {file_ext}, å¤§å°: {file_size} bytes")
                    
                    # å°†æ–‡ä»¶æ¶ˆæ¯è®¾ç½®ä¸ºFILEç±»å‹
                    cmsg.ctype = ContextType.FILE
                    cmsg.content = file_title or "æœªçŸ¥æ–‡ä»¶"
                    
                    # ä¿å­˜æ–‡ä»¶ç›¸å…³ä¿¡æ¯åˆ°æ¶ˆæ¯å¯¹è±¡
                    cmsg.file_title = file_title
                    cmsg.file_ext = file_ext
                    cmsg.file_size = int(file_size) if file_size and file_size.isdigit() else 0
                    cmsg.file_type = file_type
                    
                    # ä¿å­˜å®Œæ•´çš„XMLå†…å®¹ï¼Œä¾›åç»­ä¸‹è½½ä½¿ç”¨
                    cmsg.file_xml_content = xml_content
                    
                    # ä¸ºè±†åŒ…æ’ä»¶å…¼å®¹æ€§ï¼Œåˆ›å»ºfile_infoå­—å…¸
                    cmsg.file_info = {
                        'filename': file_title,
                        'filesize': int(file_size) if file_size and file_size.isdigit() else 0,
                        'file_ext': file_ext,
                        'file_type': file_type,
                        'attach_id': '',  # æš‚æ—¶ä¸ºç©ºï¼Œåç»­å¯ä»¥ä»XMLä¸­æå–
                        'xml_content': xml_content
                    }
                    
                    # å°è¯•ä»XMLä¸­æå–attach_idæˆ–å…¶ä»–ä¸‹è½½ç›¸å…³ä¿¡æ¯
                    attachid = appattach.findtext("attachid")
                    cdnattachurl = appattach.findtext("cdnattachurl")
                    filekey = appattach.findtext("filekey")
                    aeskey = appattach.findtext("aeskey")
                    fileuploadtoken = appattach.findtext("fileuploadtoken")
                    
                    if attachid:
                        cmsg.file_info['attach_id'] = attachid
                    if cdnattachurl:
                        cmsg.file_info['cdnattachurl'] = cdnattachurl
                    if filekey:
                        cmsg.file_info['filekey'] = filekey
                    if aeskey:
                        cmsg.file_info['aeskey'] = aeskey
                    if fileuploadtoken:
                        cmsg.file_info['fileuploadtoken'] = fileuploadtoken
                    
                    logger.info(f"[{self.name}] æ–‡ä»¶æ¶ˆæ¯å·²å¤„ç†ä¸ºFILEç±»å‹: {cmsg.msg_id}")
                    
                    # ğŸ”¥ æ–°å¢ï¼šè‡ªåŠ¨ç¼“å­˜æ–‡ä»¶åˆ°æœ¬åœ°
                    if attachid:
                        # åœ¨åå°çº¿ç¨‹ä¸­å¼‚æ­¥ä¸‹è½½å¹¶ç¼“å­˜æ–‡ä»¶
                        def cache_file_async():
                            try:
                                import asyncio
                                asyncio.run(self._auto_cache_file(cmsg, attachid, file_title, file_ext))
                            except Exception as cache_error:
                                logger.error(f"[{self.name}] è‡ªåŠ¨ç¼“å­˜æ–‡ä»¶å¤±è´¥: {cache_error}")
                        
                        import threading
                        threading.Thread(target=cache_file_async, daemon=True).start()
                        logger.info(f"[{self.name}] å·²å¯åŠ¨æ–‡ä»¶è‡ªåŠ¨ç¼“å­˜ä»»åŠ¡: {file_title}")
                    else:
                        logger.warning(f"[{self.name}] æ–‡ä»¶æ¶ˆæ¯ç¼ºå°‘attachidï¼Œæ— æ³•è‡ªåŠ¨ç¼“å­˜: {cmsg.msg_id}")
                    
                    return
                else:
                    logger.warning(f"[{self.name}] æ–‡ä»¶æ¶ˆæ¯ {cmsg.msg_id} ç¼ºå°‘appattachä¿¡æ¯")
            
            # Check if any processing flag was set or if it's a sharing link
            processed_flags_true = (hasattr(cmsg, 'is_processed_text_quote') and cmsg.is_processed_text_quote) or \
                                   (hasattr(cmsg, 'is_processed_image_quote') and cmsg.is_processed_image_quote)
            is_sharing_link = hasattr(cmsg, 'ctype') and cmsg.ctype == ContextType.SHARING

            if not (processed_flags_true or is_sharing_link):

                if appmsg is not None: # Only default to XML if it was an appmsg
                    cmsg.ctype = ContextType.XML 
                    logger.debug(f"[{self.name}] XML message {cmsg.msg_id} (appmsg type: {appmsg.findtext('type') if appmsg is not None else 'N/A'}) not specifically processed. Final ctype={cmsg.ctype}.")
                # else: If not an appmsg, its ctype should have been determined earlier or it's not XML.
        
        except ET.ParseError: # Error parsing the main cmsg.content
            logger.debug(f"[{self.name}] Failed to parse content as XML for msg {cmsg.msg_id}. Content: {str(cmsg.content)[:200]}... Assuming not XML or malformed.")
            # Do not return here, let it fall through. If ctype not set, it might be handled by caller.
            # Or, if it's guaranteed to be XML if this method is called, then this is an error state.
            pass


        except Exception as e:
            logger.error(f"[{self.name}] Unexpected error processing XML message {cmsg.msg_id}: {e}\n{traceback.format_exc()}")
            # Fallback ctype if an unexpected error occurs
            if not hasattr(cmsg, 'ctype') or cmsg.ctype == ContextType.XML: # Avoid overriding if already set to TEXT etc.
                 cmsg.ctype = ContextType.TEXT # Default to TEXT to show error to user potentially
                 cmsg.content = "[XMLæ¶ˆæ¯å¤„ç†æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯]"
            return # Return on unhandled exception to prevent further issues

        # Group message sender processing - this seems out of place if msg_xml parsing failed.
        # This should ideally be higher up or only if msg_xml was successfully parsed.
        # However, to match the original structure provided:
        if msg_xml is not None and cmsg.is_group and not (hasattr(cmsg, 'actual_user_id') and cmsg.actual_user_id):
            try:
                 # 'fromusername' is usually on the root <msg> for group messages if it's the raw XML
                 sender_id_xml = msg_xml.get('fromusername') 
                 if sender_id_xml:
                     cmsg.sender_wxid = sender_id_xml # This might be the group ID itself
                     cmsg.actual_user_id = sender_id_xml # This needs to be the actual sender in group
                     logger.debug(f"[{self.name}] Attempted to extract sender_wxid '{sender_id_xml}' from group XML msg {cmsg.msg_id}")
                     # This logic for group sender needs careful review based on actual XML structure for group messages.
                     # Often, for group messages, the sender is in a different field or part of a CDATA section.
            except Exception as e_sender:
                logger.error(f"[{self.name}] Error extracting sender from group XML msg {cmsg.msg_id}: {e_sender}")
        
        processed_text_quote_status = getattr(cmsg, 'is_processed_text_quote', False)
        processed_image_quote_status = getattr(cmsg, 'is_processed_image_quote', False)
        current_ctype = getattr(cmsg, 'ctype', 'Unknown') # Default to 'Unknown' if not set
        logger.debug(f"[{self.name}] Finished _process_xml_message for {cmsg.msg_id}. Final ctype={current_ctype}, is_text_quote={processed_text_quote_status}, is_image_quote={processed_image_quote_status}")

    def _process_system_message(self, cmsg):
        """å¤„ç†ç³»ç»Ÿæ¶ˆæ¯"""
        # ç§»é™¤é‡å¤å¯¼å…¥çš„ET
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‹ä¸€æ‹æ¶ˆæ¯
        if "<pat" in cmsg.content:
            try:
                root = ET.fromstring(cmsg.content)
                pat = root.find("pat")
                if pat is not None:
                    cmsg.ctype = ContextType.PAT  # ä½¿ç”¨è‡ªå®šä¹‰ç±»å‹
                    patter = pat.find("fromusername").text if pat.find("fromusername") is not None else ""
                    patted = pat.find("pattedusername").text if pat.find("pattedusername") is not None else ""
                    pat_suffix = pat.find("patsuffix").text if pat.find("patsuffix") is not None else ""
                    cmsg.pat_info = {
                        "patter": patter,
                        "patted": patted,
                        "suffix": pat_suffix
                    }
                    
                    # è®¾ç½®actual_user_idå’Œactual_user_nickname
                    cmsg.sender_wxid = patter
                    cmsg.actual_user_id = patter
                    cmsg.actual_user_nickname = patter
                    
                    # æ—¥å¿—è¾“å‡º
                    logger.info(f"æ”¶åˆ°æ‹ä¸€æ‹æ¶ˆæ¯: ID:{cmsg.msg_id} æ¥è‡ª:{cmsg.from_user_id} å‘é€äºº:{cmsg.sender_wxid} æ‹è€…:{patter} è¢«æ‹:{patted} åç¼€:{pat_suffix}")
                    return
            except Exception as e:
                logger.debug(f"[WX859] è§£ææ‹ä¸€æ‹æ¶ˆæ¯å¤±è´¥: {e}")
        
        # å¦‚æœä¸æ˜¯ç‰¹æ®Šç³»ç»Ÿæ¶ˆæ¯ï¼ŒæŒ‰æ™®é€šç³»ç»Ÿæ¶ˆæ¯å¤„ç†
        cmsg.ctype = ContextType.SYSTEM
        
        # è®¾ç½®ç³»ç»Ÿæ¶ˆæ¯çš„actual_user_idå’Œactual_user_nicknameä¸ºç³»ç»Ÿ
        cmsg.sender_wxid = "ç³»ç»Ÿæ¶ˆæ¯"
        cmsg.actual_user_id = "ç³»ç»Ÿæ¶ˆæ¯"
        cmsg.actual_user_nickname = "ç³»ç»Ÿæ¶ˆæ¯"
        
        logger.info(f"æ”¶åˆ°ç³»ç»Ÿæ¶ˆæ¯: ID:{cmsg.msg_id} æ¥è‡ª:{cmsg.from_user_id} å‘é€äºº:{cmsg.sender_wxid} å†…å®¹:{cmsg.content}")

    def _is_likely_base64_for_log(self, s: str) -> bool:
        """
        åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦å¯èƒ½æ˜¯base64ç¼–ç  (ç”¨äºæ—¥å¿—è®°å½•ç›®çš„)ã€‚
        ç›´æ¥æ”¹ç¼–è‡ª gemini_image.py ä¸­çš„ _is_likely_base64ã€‚
        """
        if not isinstance(s, str): # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
            return False
        # base64ç¼–ç é€šå¸¸åªåŒ…å«A-Z, a-z, 0-9, +, /, =
        if not s or len(s) < 50:  # å¤ªçŸ­çš„å­—ç¬¦ä¸²ä¸å¤ªå¯èƒ½æ˜¯éœ€è¦æˆªæ–­çš„base64
            return False
            
        # æ£€æŸ¥å­—ç¬¦æ˜¯å¦ç¬¦åˆbase64ç¼–ç 
        base64_chars_set = set("ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=")
        non_base64_count = 0
        for char_value in s: # s æ˜¯å­—ç¬¦ä¸²ï¼Œchar_value æ˜¯å­—ç¬¦
            if char_value not in base64_chars_set and char_value != '=': # '=' æ˜¯å¡«å……å­—ç¬¦
                non_base64_count += 1
        
        if non_base64_count < len(s) * 0.05 and len(s) > 100:
            return True
        return False

    def _create_loggable_params(self, data: any) -> any:
        """
        åˆ›å»ºå‚æ•°çš„å®‰å…¨ç‰ˆæœ¬ï¼Œç”¨äºæ—¥å¿—è®°å½•ã€‚
        å°†å¯èƒ½çš„base64æ•°æ®æ›¿æ¢ä¸ºé•¿åº¦å’Œé¢„è§ˆæŒ‡ç¤ºå™¨ã€‚
        æ­¤å‡½æ•°é€šè¿‡æ„å»ºæ–°çš„å­—å…¸/åˆ—è¡¨æ¥ç¡®ä¿åŸå§‹æ•°æ®ä¸è¢«ä¿®æ”¹ã€‚
        """
        if isinstance(data, dict):
            new_dict = {}
            for key, value in data.items():
                new_dict[key] = self._create_loggable_params(value) # é€’å½’è°ƒç”¨
            return new_dict
        elif isinstance(data, list):
            new_list = []
            for item in data:
                new_list.append(self._create_loggable_params(item)) # é€’å½’è°ƒç”¨
            return new_list
        elif isinstance(data, bytes): # <--- æ–°å¢å¯¹ bytes ç±»å‹çš„å¤„ç†
            return f"<binary_bytes_data len={len(data)} bytes>"
        elif isinstance(data, str):
            if self._is_likely_base64_for_log(data):
                # æˆªæ–­å¹¶æ·»åŠ é•¿åº¦æŒ‡ç¤ºå™¨ï¼Œç±»ä¼¼ gemini_image.py çš„åšæ³•
                return f"{data[:20]}... [base64_len:{len(data)} chars]"
            else:
                return data # å¦‚æœä¸æ˜¯base64æˆ–å¤ªçŸ­ï¼Œè¿”å›åŸå­—ç¬¦ä¸²
        else:
            # å¯¹äºå…¶ä»–æ•°æ®ç±»å‹ (å¦‚ int, float, bool, None ç­‰) è¿”å›åŸæ ·
            return data

    async def _call_api(self, endpoint, params, retry_count=0, max_retries=2):
        """è°ƒç”¨APIæ¥å£
        
        Args:
            endpoint (str): APIç«¯ç‚¹ï¼Œå¦‚ "/Login/LoginGetQR"
            params (dict): APIå‚æ•°å­—å…¸
            retry_count (int, optional): å½“å‰é‡è¯•æ¬¡æ•°. Defaults to 0.
            max_retries (int, optional): æœ€å¤§é‡è¯•æ¬¡æ•°. Defaults to 2.
            
        Returns:
            dict: APIå“åº”ç»“æœ
        """
        try:
            import aiohttp
            
            # è·å–APIé…ç½®
            api_host = conf().get("wx859_api_host", "127.0.0.1")
            api_port = conf().get("wx859_api_port", 8059)
            # å›ºå®šä½¿ç”¨859åè®®ï¼Œæ ¹æ®swagger.jsonå®šä¹‰ï¼Œä½¿ç”¨/apiå‰ç¼€
            api_path_prefix = "/api"

            # ç¡®ä¿endpointæ ¼å¼æ­£ç¡® - æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦å¹¶ç¡®ä¿å¼€å¤´æœ‰/
            if endpoint:
                # æ›¿æ¢åæ–œæ ä¸ºæ­£æ–œæ ï¼Œç¡®ä¿è·¨å¹³å°å…¼å®¹
                endpoint = endpoint.replace('\\', '/')
                # ç¡®ä¿å¼€å¤´æœ‰ä¸€ä¸ªæ–œæ 
                if not endpoint.startswith('/'):
                    endpoint = '/' + endpoint
            
            # æ„å»ºå®Œæ•´çš„API URL
            url = f"http://{api_host}:{api_port}{api_path_prefix}{endpoint}"
            
            # è®°å½•è¯¦ç»†çš„APIè°ƒç”¨ä¿¡æ¯
            logger.debug(f"[WX859] APIè°ƒç”¨: {url}")

            loggable_params = self._create_loggable_params(params)
            logger.debug(f"[WX859] è¯·æ±‚å‚æ•°: {json.dumps(loggable_params, ensure_ascii=False)}")
            
            # åˆ¤æ–­æ˜¯å¦æ˜¯éœ€è¦ä½¿ç”¨è¡¨å•æ•°æ®çš„è¯·æ±‚
            need_form_data = False
            form_endpoints = ["/Login/AutoHeartBeat", "/Login/LoginTwiceAutoAuth", "/Login/LoginCheckQR", "/Login/GetCacheInfo"]
            for form_endpoint in form_endpoints:
                if endpoint.endswith(form_endpoint):
                    need_form_data = True
                    logger.debug(f"[WX859] æ£€æµ‹åˆ°éœ€è¦ä½¿ç”¨è¡¨å•æ•°æ®çš„ç«¯ç‚¹: {endpoint}")
                    break
                    
            # æ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ—¥å¿—
            if need_form_data:
                logger.debug(f"[WX859] ä½¿ç”¨è¡¨å•æ•°æ®æäº¤")
                content_type = "application/x-www-form-urlencoded"
                # å°†å­—å…¸è½¬æ¢ä¸ºè¡¨å•æ ¼å¼
                if isinstance(params, dict):
                    import urllib.parse
                    form_data = {}
                    # ä¿ç•™æ‰€æœ‰åŸå§‹å‚æ•°ï¼Œä½†ç¡®ä¿ä»¥å°å†™å’Œå¤§å†™æ–¹å¼æä¾›wxid
                    for key, value in params.items():
                        form_data[key] = value
                    
                    # ç¡®ä¿åŒæ—¶æä¾›wxidå’ŒWxidä¸¤ç§å½¢å¼ï¼Œå¢åŠ å…¼å®¹æ€§
                    if "wxid" in params and "Wxid" not in params:
                        form_data["Wxid"] = params["wxid"]
                    elif "Wxid" in params and "wxid" not in params:
                        form_data["wxid"] = params["Wxid"]
                    
                    # ç¼–ç å‚æ•°
                    data = urllib.parse.urlencode(form_data)
                    logger.debug(f"[WX859] è¡¨å•æ•°æ®: {data}")
                else:
                    data = params
            else:
                logger.debug(f"[WX859] ä½¿ç”¨JSONæ•°æ®æäº¤")
                content_type = "application/json"
                data = params
            
            # å‘é€è¯·æ±‚ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
            async with aiohttp.ClientSession() as session:
                headers = {"Content-Type": content_type}
                try:
                    # æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©ä¸åŒçš„è¯·æ±‚æ–¹å¼
                    if content_type == "application/x-www-form-urlencoded":
                        logger.debug(f"[WX859] å‘é€è¡¨å•è¯·æ±‚: {url}")
                        async with session.post(url, data=data, headers=headers, timeout=60) as response:
                            if response.status == 200:
                                # è¯»å–å“åº”å†…å®¹
                                text = await response.text()
                                logger.debug(f"[WX859] æ”¶åˆ°å“åº”: {text}")
                                
                                try:
                                    # å°è¯•è§£æä¸ºJSON
                                    result = await response.json(content_type=None)
                                    logger.debug(f"[WX859] è§£æä¸ºJSON: {json.dumps(result, ensure_ascii=False)}")
                                except Exception as json_err:
                                    logger.error(f"[WX859] JSONè§£æå¤±è´¥: {json_err}, åŸå§‹å†…å®¹: {text}")
                                    # è¿”å›é”™è¯¯å“åº”
                                    return {"Success": False, "Message": f"JSONè§£æé”™è¯¯: {str(json_err)}", "RawResponse": text}
                                
                                # æ£€æŸ¥æ˜¯å¦æœ‰tokenè¿‡æœŸé—®é¢˜
                                if retry_count < max_retries and isinstance(params, dict):
                                    wxid = params.get("wxid", params.get("Wxid", ""))
                                    device_id = params.get("device_id", params.get("DeviceId", ""))
                                    
                                    if wxid:
                                        processed_result = await self._process_api_response(result, wxid, device_id)
                                        
                                        # å¦‚æœéœ€è¦é‡è¯•ï¼ˆtokenåˆ·æ–°æˆåŠŸï¼‰
                                        if isinstance(processed_result, dict) and processed_result.get("__retry_needed__", False):
                                            logger.info(f"[WX859] é‡è¯•APIè¯·æ±‚: {endpoint}, é‡è¯•æ¬¡æ•°: {retry_count + 1}")
                                            # é€’å½’è°ƒç”¨ï¼Œä½†å¢åŠ é‡è¯•è®¡æ•°
                                            return await self._call_api(endpoint, params, retry_count + 1, max_retries)
                                
                                return result
                            else:
                                # å¤„ç†éæˆåŠŸçŠ¶æ€ç 
                                error_text = await response.text()
                                logger.error(f"[WX859] APIè¯·æ±‚å¤±è´¥: {response.status} - {error_text[:200]}")
                                return {"Success": False, "Message": f"HTTPé”™è¯¯ {response.status}", "ErrorDetail": error_text[:500]}
                    else:  # JSONæ ¼å¼
                        logger.debug(f"[WX859] å‘é€JSONè¯·æ±‚: {url}")
                        async with session.post(url, json=data, headers=headers, timeout=60) as response:
                            if response.status == 200: 
                                # è¯»å–å“åº”å†…å®¹
                                text = await response.text()
                                #logger.debug(f"[WX859] æ”¶åˆ°å“åº”: {text}")
                                
                                try:
                                    # å°è¯•è§£æä¸ºJSON
                                    result = await response.json(content_type=None)
                                    #logger.debug(f"[WX859] è§£æä¸ºJSON: {json.dumps(result, ensure_ascii=False)}")
                                except Exception as json_err:
                                    logger.error(f"[WX859] JSONè§£æå¤±è´¥: {json_err}, åŸå§‹å†…å®¹: {text}")
                                    # è¿”å›é”™è¯¯å“åº”
                                    return {"Success": False, "Message": f"JSONè§£æé”™è¯¯: {str(json_err)}", "RawResponse": text}
                                
                                # æ£€æŸ¥æ˜¯å¦æœ‰tokenè¿‡æœŸé—®é¢˜
                                if retry_count < max_retries and isinstance(params, dict):
                                    wxid = params.get("wxid", params.get("Wxid", ""))
                                    device_id = params.get("device_id", params.get("DeviceId", ""))
                                    
                                    if wxid:
                                        processed_result = await self._process_api_response(result, wxid, device_id)
                                        
                                        # å¦‚æœéœ€è¦é‡è¯•ï¼ˆtokenåˆ·æ–°æˆåŠŸï¼‰
                                        if isinstance(processed_result, dict) and processed_result.get("__retry_needed__", False):
                                            logger.info(f"[WX859] é‡è¯•APIè¯·æ±‚: {endpoint}, é‡è¯•æ¬¡æ•°: {retry_count + 1}")
                                            # é€’å½’è°ƒç”¨ï¼Œä½†å¢åŠ é‡è¯•è®¡æ•°
                                            return await self._call_api(endpoint, params, retry_count + 1, max_retries)
                                
                                return result
                            else:
                                # å¤„ç†éæˆåŠŸçŠ¶æ€ç 
                                error_text = await response.text()
                                logger.error(f"[WX859] APIè¯·æ±‚å¤±è´¥: {response.status} - {error_text[:200]}")
                                return {"Success": False, "Message": f"HTTPé”™è¯¯ {response.status}", "ErrorDetail": error_text[:500]}
                except aiohttp.ClientError as client_err:
                    # å®¢æˆ·ç«¯è¿æ¥é”™è¯¯
                    logger.error(f"[WX859] HTTPè¯·æ±‚é”™è¯¯: {client_err}")
                    return {"Success": False, "Message": f"HTTPè¯·æ±‚é”™è¯¯: {str(client_err)}"}
                        
        except aiohttp.ClientError as e:
            # å¤„ç†è¿æ¥é”™è¯¯
            logger.error(f"[WX859] APIè¿æ¥é”™è¯¯: {str(e)}")
            return {"Success": False, "Message": f"APIè¿æ¥é”™è¯¯: {str(e)}"}
        except asyncio.TimeoutError:
            # å¤„ç†è¶…æ—¶é”™è¯¯
            logger.error(f"[WX859] APIè¯·æ±‚è¶…æ—¶")
            return {"Success": False, "Message": "APIè¯·æ±‚è¶…æ—¶"}
        except Exception as e:
            # å¤„ç†å…¶ä»–é”™è¯¯
            logger.error(f"[WX859] è°ƒç”¨APIæ—¶å‡ºé”™: {str(e)}")
            import traceback
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return {"Success": False, "Message": f"APIè°ƒç”¨é”™è¯¯: {str(e)}"}

    async def _send_message(self, to_user_id, content, msg_type=1):
        """å‘é€æ¶ˆæ¯çš„å¼‚æ­¥æ–¹æ³•"""
        try:
            # ç§»é™¤ignore_protectionå‚æ•°ï¼Œä½¿ç”¨æ­£ç¡®çš„APIå‚æ•°æ ¼å¼
            if not to_user_id:
                logger.error("[WX859] å‘é€æ¶ˆæ¯å¤±è´¥: æ¥æ”¶è€…IDä¸ºç©º")
                return None
                
            # æ ¹æ®APIæ–‡æ¡£è°ƒæ•´å‚æ•°æ ¼å¼
            params = {
                "ToWxid": to_user_id,
                "Content": content,
                "Type": msg_type,
                "Wxid": self.wxid,   # å‘é€è€…wxidå‚æ•°åä½¿ç”¨å¤§å†™
                "At": ""             # ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä¸@ä»»ä½•äºº
            }
            
            # ä½¿ç”¨è‡ªå®šä¹‰çš„APIè°ƒç”¨æ–¹æ³•
            result = await self._call_api("/Msg/SendTxt", params)
            
            # æ£€æŸ¥ç»“æœ
            if result and isinstance(result, dict):
                success = result.get("Success", False)
                if not success:
                    error_msg = result.get("Message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"[WX859] å‘é€æ¶ˆæ¯APIè¿”å›é”™è¯¯: {error_msg}")
            
            return result
        except Exception as e:
            logger.error(f"[WX859] å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
            return None

    async def _send_image(self, to_user_id, image_source, context=None):
        """å‘é€å›¾ç‰‡çš„å¼‚æ­¥æ–¹æ³•ï¼Œæ”¯æŒæ–‡ä»¶è·¯å¾„ã€BytesIOå¯¹è±¡æˆ–BufferedReaderå¯¹è±¡""" # <--- æ›´æ–°æ–‡æ¡£å­—ç¬¦ä¸²
        try:
            image_base64 = None
            if isinstance(image_source, str):
                # å¤„ç†æ–‡ä»¶è·¯å¾„
                image_path = image_source
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if not os.path.exists(image_path):
                    logger.error(f"[WX859] å‘é€å›¾ç‰‡å¤±è´¥: æ–‡ä»¶ä¸å­˜åœ¨ {image_path}")
                    return None
                # è¯»å–å›¾ç‰‡æ–‡ä»¶å¹¶è¿›è¡ŒBase64ç¼–ç 
                with open(image_path, "rb") as f:
                    image_data = f.read()
                    image_base64 = base64.b64encode(image_data).decode('utf-8')
            elif isinstance(image_source, io.BytesIO):
                # å¤„ç†BytesIOå¯¹è±¡
                image_data = image_source.getvalue()
                if not image_data:
                    logger.error("[WX859] å‘é€å›¾ç‰‡å¤±è´¥: BytesIOå¯¹è±¡ä¸ºç©º")
                    return None
                image_base64 = base64.b64encode(image_data).decode('utf-8')

            elif isinstance(image_source, bytes):
                # å¤„ç†byteså¯¹è±¡
                logger.debug("[WX859] å¤„ç† bytes ç±»å‹çš„å›¾ç‰‡æº")
                image_data = image_source
                if not image_data:
                    logger.error("[WX859] å‘é€å›¾ç‰‡å¤±è´¥: bytes å¯¹è±¡ä¸ºç©º")
                    return None
                image_base64 = base64.b64encode(image_data).decode('utf-8')

            # --- æ–°å¢å¤„ç† BufferedReader çš„åˆ†æ”¯ ---
            elif isinstance(image_source, io.BufferedReader):
                # å¤„ç† BufferedReader å¯¹è±¡ - æ”¹ä¸ºè·å–è·¯å¾„å¹¶é‡æ–°è¯»å–
                try:
                    image_path = image_source.name
                    if not image_path:
                        logger.error("[WX859] å‘é€å›¾ç‰‡å¤±è´¥: BufferedReaderå¯¹è±¡æ²¡æœ‰nameå±æ€§")
                        return None
                    
                    # ç¡®ä¿æ–‡ä»¶ä»ç„¶å­˜åœ¨
                    if not os.path.exists(image_path):
                        logger.error(f"[WX859] å‘é€å›¾ç‰‡å¤±è´¥: æ–‡ä»¶å·²è¢«åˆ é™¤æˆ–ä¸å­˜åœ¨äºè·¯å¾„ {image_path}")
                        return None
                        
                    # é‡æ–°æ‰“å¼€æ–‡ä»¶è¯»å–
                    logger.debug(f"[WX859] ä»BufferedReaderè·å–è·¯å¾„å¹¶é‡æ–°æ‰“å¼€: {image_path}")
                    with open(image_path, "rb") as f:
                        image_data = f.read()
                        if not image_data:
                            logger.error(f"[WX859] å‘é€å›¾ç‰‡å¤±è´¥: ä»è·¯å¾„ {image_path} è¯»å–çš„æ•°æ®ä¸ºç©º")
                            return None
                        image_base64 = base64.b64encode(image_data).decode('utf-8')
                        
                except AttributeError:
                    logger.error("[WX859] å‘é€å›¾ç‰‡å¤±è´¥: æ— æ³•ä»BufferedReaderå¯¹è±¡è·å–nameå±æ€§")
                    return None
                except FileNotFoundError:
                    logger.error(f"[WX859] å‘é€å›¾ç‰‡å¤±è´¥: æ–‡ä»¶åœ¨é‡æ–°æ‰“å¼€æ—¶æœªæ‰¾åˆ° {image_path}")
                    return None
                except Exception as read_err:
                        logger.error(f"[WX859] å¤„ç†BufferedReaderè·¯å¾„å¹¶è¯»å–æ–‡ä»¶æ—¶å¤±è´¥: {read_err}")
                        logger.error(traceback.format_exc()) # æ·»åŠ traceback
                        return None
            # --- ç»“æŸæ–°å¢åˆ†æ”¯ ---
            else:
                logger.error(f"[WX859] å‘é€å›¾ç‰‡å¤±è´¥: ä¸æ”¯æŒçš„å›¾ç‰‡æºç±»å‹ {type(image_source)}")
                return None

            # --- åç»­æ£€æŸ¥æ¥æ”¶è€…IDå’Œå‘é€APIçš„é€»è¾‘ä¿æŒä¸å˜ ---
            # æ£€æŸ¥æ¥æ”¶è€…ID
            if not to_user_id:
                logger.error("[WX859] å‘é€å›¾ç‰‡å¤±è´¥: æ¥æ”¶è€…IDä¸ºç©º")
                return None

            # ... (çœç•¥åç»­æœªä¿®æ”¹çš„ä»£ç ) ...

            # æ„å»ºAPIå‚æ•° - ä½¿ç”¨æ­£ç¡®çš„å‚æ•°æ ¼å¼
            params = {
                "ToWxid": to_user_id,
                "Base64": image_base64,
                "Wxid": self.wxid
            }

            # è°ƒç”¨API - ä½¿ç”¨æ­£ç¡®çš„APIç«¯ç‚¹
            result = await self._call_api("/Msg/UploadImg", params)

            # ... (çœç•¥åç»­æœªä¿®æ”¹çš„ä»£ç ) ...
            return result
        except Exception as e:
            logger.error(f"[WX859] å‘é€å›¾ç‰‡å¤±è´¥: {e}")
            # æ·»åŠ  traceback æ–¹ä¾¿è°ƒè¯•
            logger.error(traceback.format_exc())
            return None

    async def _prepare_video_and_thumb(self, video_url: str, session_id: str) -> dict:
        """
        å¼‚æ­¥ä¸‹è½½è§†é¢‘ï¼Œæ™ºèƒ½æå–é«˜è´¨é‡çš„ç¼©ç•¥å›¾å’Œæ—¶é•¿ã€‚
        è¯¥ç‰ˆæœ¬ç»è¿‡ä¼˜åŒ–ï¼Œå¯ä»¥è§£å†³å› ç¼©ç•¥å›¾é—®é¢˜å¯¼è‡´çš„è§†é¢‘å‘é€å¤±è´¥ã€‚

        :param video_url: è§†é¢‘çš„URL.
        :param session_id: å½“å‰ä¼šè¯çš„ID.
        :return: åŒ…å« video_path, thumb_path, duration çš„å­—å…¸.
        """
        tmp_dir = TmpDir().path()
        unique_id = str(uuid.uuid4())
        video_file_name = f"tmp_video_{session_id}_{unique_id}.mp4"
        video_file_path = os.path.join(tmp_dir, video_file_name)
        thumb_file_name = f"tmp_thumb_{session_id}_{unique_id}.jpg"
        thumb_file_path = os.path.join(tmp_dir, thumb_file_name)

        # 1. ä¸‹è½½è§†é¢‘æ–‡ä»¶
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(video_url, timeout=aiohttp.ClientTimeout(total=120)) as resp: # å¢åŠ è¶…æ—¶åˆ°120ç§’
                    if resp.status == 200:
                        with open(video_file_path, 'wb') as f:
                            while True:
                                chunk = await resp.content.read(8192) # å¢åŠ å—å¤§å°
                                if not chunk:
                                    break
                                f.write(chunk)
                        logger.debug(f"[WX859] è§†é¢‘ä¸‹è½½æˆåŠŸ: {video_file_path}")
                    else:
                        logger.error(f"[WX859] è§†é¢‘ä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {resp.status}, URL: {video_url}")
                        return None
        except Exception as e:
            logger.error(f"[WX859] ä¸‹è½½è§†é¢‘æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            if os.path.exists(video_file_path):
                os.remove(video_file_path)
            return None

        # 2. æå–è§†é¢‘ä¿¡æ¯å’Œç”Ÿæˆç¼©ç•¥å›¾
        duration = 0
        thumb_generated = False
        cap = None
        try:
            cap = cv2.VideoCapture(video_file_path)
            if not cap.isOpened():
                logger.error(f"[WX859] OpenCVæ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_file_path}")
                return {"video_path": video_file_path, "thumb_path": None, "duration": 0}

            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            if fps > 0 and frame_count > 0:
                duration = int(frame_count / fps)
            else:
                logger.warning(f"[WX859] æ— æ³•è·å–æœ‰æ•ˆçš„è§†é¢‘å¸§ç‡æˆ–æ€»å¸§æ•°: {video_file_path}")

            # æ™ºèƒ½é€‰æ‹©æˆªå›¾ä½ç½®ï¼Œé¿å…ç‰‡å¤´é»‘å±
            positions_to_try = [0.1, 0.3, 0.01] # å°è¯•è§†é¢‘10%, 30%, 1%çš„ä½ç½®
            frame_to_save = None

            for pos in positions_to_try:
                frame_pos = int(frame_count * pos)
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_pos)
                ret, frame = cap.read()
                if ret:
                    # ç®€å•æ£€æŸ¥å¸§æ˜¯å¦ä¸ºå…¨é»‘
                    if frame.any():
                        frame_to_save = frame
                        logger.info(f"[WX859] æˆåŠŸåœ¨è§†é¢‘ {pos*100:.0f}% ä½ç½®æˆªå–åˆ°æœ‰æ•ˆå¸§")
                        break
            
            # å¦‚æœæ‰€æœ‰ä½ç½®éƒ½å¤±è´¥ï¼Œå°è¯•ç¬¬ä¸€å¸§ä½œä¸ºå¤‡é€‰
            if frame_to_save is None:
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                ret, frame = cap.read()
                if ret:
                    frame_to_save = frame
                    logger.warning(f"[WX859] æœªæ‰¾åˆ°ç†æƒ³å¸§ï¼Œä½¿ç”¨è§†é¢‘ç¬¬ä¸€å¸§ä½œä¸ºå¤‡é€‰")

            # ä½¿ç”¨Pillowå¤„ç†å¹¶ä¿å­˜ç¼©ç•¥å›¾ï¼ˆå‚è€ƒgewechat_channel.pyï¼Œä¿æŒåŸå§‹æ¯”ä¾‹ï¼‰
            if frame_to_save is not None:
                # OpenCVçš„é¢œè‰²é€šé“æ˜¯BGR, Pillowæ˜¯RGB, éœ€è¦è½¬æ¢
                rgb_frame = cv2.cvtColor(frame_to_save, cv2.COLOR_BGR2RGB)
                img = Image.fromarray(rgb_frame)
                
                # è·å–åŸå§‹å›¾ç‰‡å°ºå¯¸
                original_width, original_height = img.size
                logger.debug(f"[WX859] åŸå§‹å¸§å°ºå¯¸: {original_width}x{original_height}")
                
                # å‚è€ƒgewechat_channel.pyçš„åšæ³•ï¼šä¿æŒåŸå›¾å°ºå¯¸ï¼Œä¸å¼ºåˆ¶ç¼©æ”¾ä¸ºæ­£æ–¹å½¢
                # ä½†ä¸ºäº†é¿å…ç¼©ç•¥å›¾è¿‡å¤§ï¼Œè®¾ç½®æœ€å¤§å°ºå¯¸é™åˆ¶
                max_size = 480  # æœ€å¤§è¾¹é•¿ï¼Œå‚è€ƒgewechatçš„é»˜è®¤å°ºå¯¸
                
                # å¦‚æœå›¾ç‰‡ä»»ä¸€è¾¹è¶…è¿‡æœ€å¤§å°ºå¯¸ï¼Œè¿›è¡Œç­‰æ¯”ç¼©æ”¾
                if original_width > max_size or original_height > max_size:
                    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹ï¼Œä¿æŒå®½é«˜æ¯”
                    scale = min(max_size / original_width, max_size / original_height)
                    new_width = int(original_width * scale)
                    new_height = int(original_height * scale)
                    
                    # ä½¿ç”¨é«˜è´¨é‡é‡é‡‡æ ·æ–¹æ³•ç¼©æ”¾å›¾ç‰‡
                    img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                    logger.info(f"[WX859] ç¼©æ”¾ç¼©ç•¥å›¾å°ºå¯¸: {original_width}x{original_height} -> {new_width}x{new_height}")
                else:
                    # å°ºå¯¸åˆé€‚ï¼Œä¿æŒåŸå§‹å°ºå¯¸
                    new_width, new_height = original_width, original_height
                    logger.info(f"[WX859] ä¿æŒåŸå§‹ç¼©ç•¥å›¾å°ºå¯¸: {new_width}x{new_height}")
                
                # åº”ç”¨å›¾åƒå¢å¼ºå¤„ç†
                from PIL import ImageFilter, ImageEnhance
                try:
                    # è½»å¾®é”åŒ–ï¼Œæå‡æ¸…æ™°åº¦
                    img = img.filter(ImageFilter.UnsharpMask(radius=0.8, percent=110, threshold=3))
                    
                    # å¢å¼ºå¯¹æ¯”åº¦
                    enhancer = ImageEnhance.Contrast(img)
                    img = enhancer.enhance(1.08)
                    
                    # å¢å¼ºè‰²å½©é¥±å’Œåº¦
                    enhancer = ImageEnhance.Color(img)
                    img = enhancer.enhance(1.03)
                    
                    logger.debug(f"[WX859] å·²åº”ç”¨å›¾åƒå¢å¼ºå¤„ç†")
                except Exception as e:
                    logger.debug(f"[WX859] å›¾ç‰‡å¢å¼ºå¤„ç†å¤±è´¥: {e}")
                
                # ä¿å­˜é«˜è´¨é‡ç¼©ç•¥å›¾ï¼Œå‚è€ƒgewechatçš„è´¨é‡è®¾ç½®
                img.save(thumb_file_path, 'JPEG', quality=95, optimize=True, progressive=False)
                thumb_generated = True
                logger.info(f"[WX859] æˆåŠŸç”ŸæˆåŸå§‹æ¯”ä¾‹é«˜è´¨é‡ç¼©ç•¥å›¾: {thumb_file_path} ({new_width}x{new_height}). æ—¶é•¿: {duration}s")
            else:
                logger.error(f"[WX859] æ— æ³•ä»è§†é¢‘ä¸­è¯»å–ä»»ä½•æœ‰æ•ˆå¸§ç”¨äºç”Ÿæˆç¼©ç•¥å›¾: {video_file_path}")

        except Exception as e:
            logger.error(f"[WX859] å¤„ç†è§†é¢‘æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
            return {"video_path": video_file_path, "thumb_path": None, "duration": duration}
        finally:
            if cap:
                cap.release()
        
        return {
            "video_path": video_file_path,
            "thumb_path": thumb_file_path if thumb_generated else None,
            "duration": duration
        }

    async def send_video(self, to_wxid: str, video_url: str, session_id: str):
        """
        ä¸‹è½½è§†é¢‘URLï¼Œå‡†å¤‡è§†é¢‘è·¯å¾„ã€ç¼©ç•¥å›¾è·¯å¾„å’Œæ—¶é•¿ï¼Œ
        ç„¶åä½¿ç”¨Base64ç¼–ç æ–¹å¼å‘é€ï¼ˆå‚è€ƒxxxbot_channel.pyçš„æˆåŠŸå®ç°ï¼‰ã€‚
        """
        logger.info(f"[WX859] Preparing video from URL: {video_url} for recipient {to_wxid} (session: {session_id})")
        prepared_video_info = await self._prepare_video_and_thumb(video_url, session_id)

        if not prepared_video_info or not prepared_video_info.get("video_path"):
            logger.error(f"[WX859] Failed to prepare video and thumbnail for URL: {video_url}")
            return None 

        video_path = prepared_video_info["video_path"]
        thumb_path = prepared_video_info.get("thumb_path")
        duration = prepared_video_info.get("duration", 10)

        if not os.path.exists(video_path):
            logger.error(f"[WX859] Prepared video file does not exist after _prepare_video_and_thumb: {video_path}")
            return None

        try:
            logger.info(f"[WX859] Using Base64 method for video sending. ToWxid: {to_wxid}, VideoPath: {video_path}, ThumbPath: {thumb_path if thumb_path else 'None'}")
            
            # å‚è€ƒxxxbot_channel.pyçš„å®ç°ï¼šä½¿ç”¨Base64ç¼–ç æ–¹å¼å‘é€
            import base64
            
            # è¯»å–è§†é¢‘æ–‡ä»¶ä¸ºBase64
            with open(video_path, 'rb') as f:
                video_base64 = base64.b64encode(f.read()).decode('utf-8')
            
            # è¯»å–ç¼©ç•¥å›¾æ–‡ä»¶ä¸ºBase64ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            thumb_data = ""
            if thumb_path and os.path.exists(thumb_path):
                with open(thumb_path, 'rb') as f:
                    thumb_data = base64.b64encode(f.read()).decode('utf-8')
                logger.info(f"[WX859] ç¼©ç•¥å›¾Base64å¤§å°: {len(thumb_data)}")
            else:
                logger.warning(f"[WX859] ç¼©ç•¥å›¾ä¸å­˜åœ¨ï¼Œå°†å‘é€ç©ºç¼©ç•¥å›¾")
            
            logger.info(f"[WX859] è§†é¢‘Base64å¤§å°: {len(video_base64)}, æ—¶é•¿: {duration}ç§’")
            
            # æ„é€ è¯·æ±‚æ•°æ®ï¼ˆå‚è€ƒxxxbot_channel.pyçš„æ ¼å¼ï¼‰
            data = {
                "Wxid": self.wxid,
                "ToWxid": to_wxid,
                "Base64": "data:video/mp4;base64," + video_base64,
                "ImageBase64": "data:image/jpeg;base64," + thumb_data if thumb_data else "",
                "PlayLength": duration
            }
            
            # ä½¿ç”¨_call_apiæ–¹æ³•å‘é€è¯·æ±‚
            logger.info(f"[WX859] å‘é€è§†é¢‘è¯·æ±‚ï¼Œæ•°æ®å¤§å°: {len(video_base64)//1024}KB")
            
            result = await self._call_api("/Msg/SendVideo", data)
            
            if result and isinstance(result, dict):
                if result.get("Success"):
                    logger.info(f"[WX859] è§†é¢‘å‘é€æˆåŠŸ: ToWxid={to_wxid}")
                    return {"Success": True, "Data": result.get("Data", {}), "Msg": "Video sent successfully"}
                else:
                    error_msg = result.get("Message", "Unknown error")
                    logger.error(f"[WX859] è§†é¢‘å‘é€å¤±è´¥: {error_msg}")
                    return {"Success": False, "Msg": error_msg}
            else:
                logger.error(f"[WX859] è§†é¢‘å‘é€è¿”å›æ— æ•ˆç»“æœ: {result}")
                return {"Success": False, "Msg": "Invalid API response"}

        except Exception as e:
            logger.error(f"[WX859] Exception when sending video to {to_wxid}: {e}", exc_info=True)
            return {"Success": False, "Msg": str(e)}
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(video_path):
                try:
                    os.remove(video_path)
                    logger.debug(f"[WX859] Cleaned up temp video file: {video_path}")
                except Exception as e_clean:
                    logger.warning(f"[WX859] Failed to clean up temp video file {video_path}: {e_clean}")
            if thumb_path and os.path.exists(thumb_path):
                try:
                    os.remove(thumb_path)
                    logger.debug(f"[WX859] Cleaned up temp thumb file: {thumb_path}")
                except Exception as e_clean:
                    logger.warning(f"[WX859] Failed to clean up temp thumb file {thumb_path}: {e_clean}")

    def send(self, reply: Reply, context: Context):
        """å‘é€æ¶ˆæ¯"""
        # è·å–æ¥æ”¶è€…ID
        receiver = context.get("receiver")
        if not receiver:
            # å¦‚æœcontextä¸­æ²¡æœ‰æ¥æ”¶è€…ï¼Œå°è¯•ä»æ¶ˆæ¯å¯¹è±¡ä¸­è·å–
            msg = context.get("msg")
            if msg and hasattr(msg, "from_user_id"):
                receiver = msg.from_user_id
        
        if not receiver:
            logger.error("[WX859] å‘é€æ¶ˆæ¯å¤±è´¥: æ— æ³•ç¡®å®šæ¥æ”¶è€…ID")
            return
            
        loop = asyncio.new_event_loop()
        
        if reply.type == ReplyType.TEXT:
            reply.content = remove_markdown_symbol(reply.content)
            result = loop.run_until_complete(self._send_message(receiver, reply.content))
            if result and isinstance(result, dict) and result.get("Success", False):
                logger.info(f"[WX859] å‘é€æ–‡æœ¬æ¶ˆæ¯æˆåŠŸ: æ¥æ”¶è€…: {receiver}")
                if conf().get("log_level", "INFO") == "DEBUG":
                    logger.debug(f"[WX859] æ¶ˆæ¯å†…å®¹: {reply.content[:50]}...")
            else:
                logger.warning(f"[WX859] å‘é€æ–‡æœ¬æ¶ˆæ¯å¯èƒ½å¤±è´¥: æ¥æ”¶è€…: {receiver}, ç»“æœ: {result}")
        
        elif reply.type == ReplyType.ERROR or reply.type == ReplyType.INFO:
            reply.content = remove_markdown_symbol(reply.content)
            result = loop.run_until_complete(self._send_message(receiver, reply.content))
            if result and isinstance(result, dict) and result.get("Success", False):
                logger.info(f"[WX859] å‘é€æ¶ˆæ¯æˆåŠŸ: æ¥æ”¶è€…: {receiver}")
                if conf().get("log_level", "INFO") == "DEBUG":
                    logger.debug(f"[WX859] æ¶ˆæ¯å†…å®¹: {reply.content[:50]}...")
            else:
                logger.warning(f"[WX859] å‘é€æ¶ˆæ¯å¯èƒ½å¤±è´¥: æ¥æ”¶è€…: {receiver}, ç»“æœ: {result}")
        
        elif reply.type == ReplyType.IMAGE_URL:
            # ä»ç½‘ç»œä¸‹è½½å›¾ç‰‡å¹¶å‘é€
            img_url = reply.content
            logger.debug(f"[WX859] å¼€å§‹ä¸‹è½½å›¾ç‰‡, url={img_url}")
            try:
                pic_res = requests.get(img_url, stream=True)
                # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ä¿å­˜å›¾ç‰‡
                tmp_path = os.path.join(get_appdata_dir(), f"tmp_img_{int(time.time())}.png")
                with open(tmp_path, 'wb') as f:
                    for block in pic_res.iter_content(1024):
                        f.write(block)
                
                # ä½¿ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰æ–¹æ³•å‘é€å›¾ç‰‡
                result = loop.run_until_complete(self._send_image(receiver, tmp_path))
                
                if result and isinstance(result, dict) and result.get("Success", False):
                    logger.info(f"[WX859] å‘é€å›¾ç‰‡æˆåŠŸ: æ¥æ”¶è€…: {receiver}")
                else:
                    logger.warning(f"[WX859] å‘é€å›¾ç‰‡å¯èƒ½å¤±è´¥: æ¥æ”¶è€…: {receiver}, ç»“æœ: {result}")
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                try:
                    os.remove(tmp_path)
                except Exception as e:
                    logger.debug(f"[WX859] åˆ é™¤ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶å¤±è´¥: {e}")
            except Exception as e:
                logger.error(f"[WX859] å‘é€å›¾ç‰‡å¤±è´¥: {e}")
        
        elif reply.type == ReplyType.IMAGE: # æ·»åŠ å¤„ç† ReplyType.IMAGE
            image_input = reply.content
            # ç§»é™¤ os.path.exists æ£€æŸ¥ï¼Œäº¤ç”± _send_image å¤„ç†
            # ä½¿ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰æ–¹æ³•å‘é€æœ¬åœ°å›¾ç‰‡æˆ–BytesIO
            result = loop.run_until_complete(self._send_image(receiver, image_input))
            
            if result and isinstance(result, dict) and result.get("Success", False):
                logger.info(f"[WX859] å‘é€å›¾ç‰‡æˆåŠŸ: æ¥æ”¶è€…: {receiver}")
            else:
                logger.warning(f"[WX859] å‘é€å›¾ç‰‡å¯èƒ½å¤±è´¥: æ¥æ”¶è€…: {receiver}, ç»“æœ: {result}")
                
        elif reply.type == ReplyType.APP:
            xml_content = reply.content
            logger.info(f"[WX859] APP message raw content type: {type(xml_content)}, content length: {len(xml_content)}")
            if conf().get("log_level", "INFO") == "DEBUG":
                 logger.debug(f"[WX859] APP XML Content: {xml_content[:500]}") # Log more content for debugging

            if not isinstance(xml_content, str):
                logger.error(f"[WX859] send app message failed: content must be XML string, got type={type(xml_content)}")
                return
            if not xml_content.strip():
                logger.error("[WX859] send app message failed: content is empty string")
                return
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯MessageTailæ’ä»¶å¤„ç†è¿‡çš„æ¶ˆæ¯ï¼Œå¦‚æœæ˜¯åˆ™ç›´æ¥å‘é€åŸå§‹XML
            if hasattr(reply, '_messagetail_processed') and reply._messagetail_processed:
                logger.info("[WX859] æ£€æµ‹åˆ°MessageTailæ’ä»¶æ ‡è®°ï¼Œè·³è¿‡XMLè§£æç›´æ¥å‘é€")
                # MessageTailæ’ä»¶å·²ç»ç”Ÿæˆäº†å®Œæ•´çš„XMLï¼Œç›´æ¥ä½¿ç”¨SendAppå‘é€
                # å¼ºåˆ¶è®¾ç½®app_typeä¸º5ï¼ˆå›¾ç‰‡ç±»å‹ï¼‰ï¼Œé¿å…è§£æXMLä¸­çš„typeæ ‡ç­¾
                app_type = 5
                result = loop.run_until_complete(self._send_app_xml(receiver, xml_content, app_type))
                if result and isinstance(result, dict) and result.get("Success", False):
                    logger.info(f"[WX859] MessageTailå›¾ç‰‡æ¶ˆæ¯å‘é€æˆåŠŸ: æ¥æ”¶è€…: {receiver}, Type: {app_type}")
                else:
                    logger.warning(f"[WX859] MessageTailå›¾ç‰‡æ¶ˆæ¯å‘é€å¤±è´¥: æ¥æ”¶è€…: {receiver}, Type: {app_type}, ç»“æœ: {result}")
                return
            
            # Extract app_type from XML content
            app_type = 3 # Default to 3 (music type from log example) if not found
            try:
                # Using regex to find <type>integer_value</type>
                match = re.search(r"<type>\s*(\d+)\s*</type>", xml_content, re.IGNORECASE)
                if match:
                    app_type = int(match.group(1))
                    logger.info(f"[WX859] Extracted app_type from XML: {app_type}")
                else:
                    logger.warning(f"[WX859] Could not find <type> tag in XML, using default app_type: {app_type}. XML: {xml_content[:300]}...")
            except Exception as e_parse_type:
                logger.error(f"[WX859] Error parsing app_type from XML: {e_parse_type}, using default: {app_type}. XML: {xml_content[:300]}...")
            
            result = loop.run_until_complete(self._send_app_xml(receiver, xml_content, app_type))
            if result and isinstance(result, dict) and result.get("Success", False):
                logger.info(f"[WX859] å‘é€App XMLæ¶ˆæ¯æˆåŠŸ: æ¥æ”¶è€…: {receiver}, Type: {app_type}")
            else:
                logger.warning(f"[WX859] å‘é€App XMLæ¶ˆæ¯å¯èƒ½å¤±è´¥: æ¥æ”¶è€…: {receiver}, Type: {app_type}, ç»“æœ: {result}")

        elif reply.type == ReplyType.MINIAPP:
            app_input = reply.content
            # ç§»é™¤ os.path.exists æ£€æŸ¥ï¼Œäº¤ç”± _send_app å¤„ç†
            # ä½¿ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰æ–¹æ³•å‘é€å°ç¨‹åº
            result = loop.run_until_complete(self._send_app(receiver, app_input))
            
            if result and isinstance(result, dict) and result.get("Success", False):
                logger.info(f"[WX859] å‘é€å°ç¨‹åºæˆåŠŸ: æ¥æ”¶è€…: {receiver}")
            else:
                logger.warning(f"[WX859] å‘é€å°ç¨‹åºå¯èƒ½å¤±è´¥: æ¥æ”¶è€…: {receiver}, ç»“æœ: {result}")
        
        # ç§»é™¤ä¸å­˜åœ¨çš„ReplyType.Systemç±»å‹ï¼Œä½¿ç”¨ReplyType.INFOæˆ–å¿½ç•¥
        elif reply.type == ReplyType.INFO:
            system_input = reply.content
            # ç§»é™¤ os.path.exists æ£€æŸ¥ï¼Œäº¤ç”± _send_system å¤„ç†
            # ä½¿ç”¨æˆ‘ä»¬çš„è‡ªå®šä¹‰æ–¹æ³•å‘é€ç³»ç»Ÿæ¶ˆæ¯
            result = loop.run_until_complete(self._send_message(receiver, system_input))
            
            if result and isinstance(result, dict) and result.get("Success", False):
                logger.info(f"[WX859] å‘é€ç³»ç»Ÿæ¶ˆæ¯æˆåŠŸ: æ¥æ”¶è€…: {receiver}")
            else:
                logger.warning(f"[WX859] å‘é€ç³»ç»Ÿæ¶ˆæ¯å¯èƒ½å¤±è´¥: æ¥æ”¶è€…: {receiver}, ç»“æœ: {result}")
        
        elif reply.type == ReplyType.VIDEO_URL:
            logger.info(f"[WX859] Received VIDEO_URL reply: {reply.content}")
            to_wxid = context.get("receiver") # ä½¿ç”¨ .get() æ›´å®‰å…¨
            if not to_wxid:
                logger.error("[WX859] Cannot send VIDEO_URL, receiver is not defined in context.")
                return # å¦‚æœæ²¡æœ‰æ¥æ”¶è€…ï¼Œåˆ™è¿”å›

            session_id = context.get("session_id") or context.get("msg", {}).get("msg_id") or self.get_random_session()
            # ä¸‹é¢çš„ if not session_id ç†è®ºä¸Šä¸ä¼šæ‰§è¡Œï¼Œå› ä¸º or self.get_random_session() ä¿è¯äº†å®ƒæœ‰å€¼
            # å¯ä»¥è€ƒè™‘ç§»é™¤è¿™ä¸ª if å—ï¼Œæˆ–è€…ä¿ç•™ä½œä¸ºé¢å¤–çš„æ—¥å¿—ç‚¹
            if not session_id: # è¿™ä¸ªåˆ¤æ–­åœ¨ or self.get_random_session() åå…¶å®æ˜¯å¤šä½™çš„
                session_id = self.get_random_session() # è¿™ä¸€è¡Œä¸ä¼šè¢«æ‰§è¡Œ
                logger.warning(f"[WX859] session_id was unexpectedly still None for VIDEO_URL, using random: {session_id}")

            try:
                # loop å˜é‡åœ¨ send æ–¹æ³•çš„å¼€å¤´å®šä¹‰
                loop.run_until_complete(self.send_video(to_wxid, reply.content, session_id))
            except Exception as e:
                # send_video å†…éƒ¨å·²æœ‰è¯¦ç»†æ—¥å¿—ï¼Œè¿™é‡Œå¯ä»¥ç®€åŒ–æˆ–æ ¹æ®éœ€è¦è°ƒæ•´
                logger.error(f"[WX859] Error occurred in send_reply while processing VIDEO_URL: {str(e)}")
                # å†³å®šæ˜¯å¦é‡æ–°æŠ›å‡ºå¼‚å¸¸
                # raise 
            
            return
        
        elif reply.type == ReplyType.VOICE:
            original_voice_file_path = reply.content
            if not original_voice_file_path or not os.path.exists(original_voice_file_path):
                logger.error(f"[WX859] Send voice failed: Original voice file not found or path is empty: {original_voice_file_path}")
                return
            
            if not original_voice_file_path.lower().endswith('.mp3'):
                logger.error(f"[WX859] Send voice failed: Only .mp3 voice files are supported, got {original_voice_file_path}")
                return

            # FFmpeg preprocessing
            ffmpeg_path = _find_ffmpeg_path()
            
            # Correctly create temporary directory for ffmpeg output
            base_tmp_root = TmpDir().path() # e.g., ./tmp/
            voice_subdir_name = "wx859_voice_cache"
            voice_tmp_dir = os.path.join(base_tmp_root, voice_subdir_name) # e.g., ./tmp/wx859_voice_cache
            os.makedirs(voice_tmp_dir, exist_ok=True)
            processed_voice_path = os.path.join(voice_tmp_dir, f"ffmpeg_processed_{os.path.basename(original_voice_file_path)}")
            
            effective_voice_path = original_voice_file_path # Default to original if ffmpeg fails
            ffmpeg_success = False

            try:
                cmd = [
                    ffmpeg_path, "-y", "-i", original_voice_file_path,
                    "-acodec", "libmp3lame", "-ar", "44100", "-ab", "192k",
                    "-ac", "2", processed_voice_path
                ]
                logger.info(f"[WX859] Attempting to preprocess voice file with ffmpeg: {' '.join(cmd)}")
                process_result = subprocess.run(cmd, capture_output=True, text=True, check=False) # check=False to inspect manually
                if process_result.returncode == 0 and os.path.exists(processed_voice_path):
                    logger.info(f"[WX859] ffmpeg preprocessing successful. Using processed file: {processed_voice_path}")
                    effective_voice_path = processed_voice_path
                    ffmpeg_success = True
                else:
                    logger.warning(f"[WX859] ffmpeg preprocessing failed. Return code: {process_result.returncode}. Error: {process_result.stderr}. Will use original file.")
            except Exception as e_ffmpeg:
                logger.error(f"[WX859] Exception during ffmpeg preprocessing: {e_ffmpeg}. Will use original file.")

            temp_files_to_clean = []
            if ffmpeg_success and effective_voice_path != original_voice_file_path:
                temp_files_to_clean.append(effective_voice_path) # Add ffmpeg processed file for cleanup

            try:
                # Reduce segment duration to 25 seconds to see if it helps with EndFlag issue
                _total_duration_ms, segment_paths = split_audio(effective_voice_path, 60 * 1000) 
                temp_files_to_clean.extend(segment_paths) # Add segment paths from split_audio for cleanup

                if not segment_paths:
                    logger.error(f"[WX859] Voice splitting failed for {effective_voice_path}. No segments created.")
                    logger.info(f"[WX859] Attempting to send {effective_voice_path} as fallback.")
                    # Duration calculation for fallback is now inside _send_voice, so just pass path
                    fallback_result = loop.run_until_complete(self._send_voice(receiver, effective_voice_path))
                    if fallback_result and isinstance(fallback_result, dict) and fallback_result.get("Success", False):
                        logger.info(f"[WX859] Fallback: Sent voice file successfully: {effective_voice_path}")
                    else:
                        logger.warning(f"[WX859] Fallback: Sending voice file failed: {effective_voice_path}, Result: {fallback_result}")
                    return
                
                logger.info(f"[WX859] Voice file {effective_voice_path} split into {len(segment_paths)} segments.")

                for i, segment_path in enumerate(segment_paths):
                    # Duration calculation and SILK conversion are now inside _send_voice
                    segment_result = loop.run_until_complete(self._send_voice(receiver, segment_path))
                    if segment_result and isinstance(segment_result, dict) and segment_result.get("Success", False):
                        logger.info(f"[WX859] Sent voice segment {i+1}/{len(segment_paths)} successfully: {segment_path}")
                    else:
                        logger.warning(f"[WX859] Sending voice segment {i+1}/{len(segment_paths)} failed: {segment_path}, Result: {segment_result}")
                        # If a segment fails, we might decide to stop or continue. For now, continue.
                    
                    if i < len(segment_paths) - 1:
                        time.sleep(0.5)
            
            except Exception as e_split_send:
                logger.error(f"[WX859] Error during voice splitting or segmented sending for {effective_voice_path}: {e_split_send}")
                import traceback
                logger.error(traceback.format_exc())
            finally:
                logger.debug(f"[WX859] Cleaning up {len(temp_files_to_clean)} temporary voice file(s)...")
                for temp_file_path in temp_files_to_clean:
                    try:
                        if os.path.exists(temp_file_path):
                            os.remove(temp_file_path)
                            logger.debug(f"[WX859] Removed temporary voice file: {temp_file_path}")
                    except Exception as e_cleanup:
                        logger.warning(f"[WX859] Failed to remove temporary voice file {temp_file_path}: {e_cleanup}")

        elif reply.type == ReplyType.FILE:
            # å¤„ç†æ–‡ä»¶å‘é€
            file_path = reply.content
            if not file_path or not os.path.exists(file_path):
                logger.error(f"[WX859] Send file failed: File not found or path is empty: {file_path}")
                return
            
            logger.info(f"[WX859] å¼€å§‹å‘é€æ–‡ä»¶: {file_path} åˆ° {receiver}")
            
            try:
                # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•å‘é€æ–‡ä»¶
                send_result = loop.run_until_complete(self.send_file_message(receiver, file_path))
                
                if send_result and send_result.get("success", False):
                    logger.info(f"[WX859] æ–‡ä»¶å‘é€æˆåŠŸ: {file_path}")
                else:
                    error_msg = send_result.get("error", "æœªçŸ¥é”™è¯¯") if send_result else "å‘é€å¤±è´¥"
                    logger.error(f"[WX859] æ–‡ä»¶å‘é€å¤±è´¥: {file_path}, é”™è¯¯: {error_msg}")
                    
            except Exception as e:
                logger.error(f"[WX859] å‘é€æ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                import traceback
                logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

        else:
            logger.warning(f"[WX859] ä¸æ”¯æŒçš„å›å¤ç±»å‹: {reply.type}")
        
        loop.close() 

    async def _get_group_member_details(self, group_id):
        """è·å–ç¾¤æˆå‘˜è¯¦æƒ…"""
        try:
            logger.debug(f"[WX859] å°è¯•è·å–ç¾¤ {group_id} çš„æˆå‘˜è¯¦æƒ…")
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç¾¤æˆå‘˜ä¿¡æ¯ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            # å®šä¹‰ç¾¤èŠä¿¡æ¯æ–‡ä»¶è·¯å¾„
            tmp_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp")
            if not os.path.exists(tmp_dir):
                os.makedirs(tmp_dir)
            
            chatrooms_file = os.path.join(tmp_dir, 'wx859_rooms.json')
            
            # è¯»å–ç°æœ‰çš„ç¾¤èŠä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            chatrooms_info = {}
            if os.path.exists(chatrooms_file):
                try:
                    with open(chatrooms_file, 'r', encoding='utf-8') as f:
                        chatrooms_info = json.load(f)
                    logger.debug(f"[WX859] å·²åŠ è½½ {len(chatrooms_info)} ä¸ªç°æœ‰ç¾¤èŠä¿¡æ¯")
                except Exception as e:
                    logger.error(f"[WX859] åŠ è½½ç°æœ‰ç¾¤èŠä¿¡æ¯å¤±è´¥: {str(e)}")
            
            # æ£€æŸ¥è¯¥ç¾¤èŠæ˜¯å¦å·²å­˜åœ¨ä¸”æˆå‘˜ä¿¡æ¯æ˜¯å¦å·²æ›´æ–°
            # è®¾å®šç¼“å­˜æœ‰æ•ˆæœŸä¸º24å°æ—¶(86400ç§’)
            cache_expiry = 86400
            current_time = int(time.time())
            
            if (group_id in chatrooms_info and 
                "members" in chatrooms_info[group_id] and 
                len(chatrooms_info[group_id]["members"]) > 0 and
                "last_update" in chatrooms_info[group_id] and
                current_time - chatrooms_info[group_id]["last_update"] < cache_expiry):
                logger.debug(f"[WX859] ç¾¤ {group_id} æˆå‘˜ä¿¡æ¯å·²å­˜åœ¨ä¸”æœªè¿‡æœŸï¼Œè·³è¿‡æ›´æ–°")
                return chatrooms_info[group_id]
            
            logger.debug(f"[WX859] ç¾¤ {group_id} æˆå‘˜ä¿¡æ¯ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸï¼Œå¼€å§‹æ›´æ–°")
            
            # ============== æ–°å¢ï¼šé¦–å…ˆè°ƒç”¨GetChatRoomInfoè·å–ç¾¤åç§° ==============
            # è°ƒç”¨APIè·å–ç¾¤è¯¦æƒ…
            info_params = {
                "QID": group_id,  # ç¾¤IDå‚æ•°
                "wxid": self.wxid  # è‡ªå·±çš„wxidå‚æ•°ï¼Œæ”¹ä¸ºå°å†™
            }
            
            # è·å–APIé…ç½®
            api_host = conf().get("wx859_api_host", "127.0.0.1")
            api_port = conf().get("wx859_api_port", 8059)
            
            # å›ºå®šä½¿ç”¨859åè®®ï¼Œæ ¹æ®swagger.jsonå®šä¹‰ï¼Œä½¿ç”¨/apiå‰ç¼€
            api_path_prefix = "/api"
            
            logger.info(f"[WX859] æ­£åœ¨è¯·æ±‚ç¾¤è¯¦æƒ…API: http://{api_host}:{api_port}{api_path_prefix}/Group/GetChatRoomInfo")
            logger.info(f"[WX859] ç¾¤è¯¦æƒ…è¯·æ±‚å‚æ•°: {json.dumps(info_params, ensure_ascii=False)}")
            
            # è°ƒç”¨GetChatRoomInfo API
            group_info_response = await self._call_api("/Group/GetChatRoomInfo", info_params)
            
            # è§£æç¾¤åç§°
            group_name = None
            if group_info_response and isinstance(group_info_response, dict) and group_info_response.get("Success", False):
                data = group_info_response.get("Data", {})
                
                # é€’å½’å‡½æ•°ç”¨äºæŸ¥æ‰¾ç‰¹å®škeyçš„å€¼
                def find_value(obj, key):
                    # å¦‚æœæ˜¯å­—å…¸
                    if isinstance(obj, dict):
                        # ç›´æ¥æ£€æŸ¥å½“å‰å­—å…¸
                        if key in obj:
                            return obj[key]
                        # æ£€æŸ¥å¸¦æœ‰"string"åµŒå¥—çš„å­—å…¸
                        if key in obj and isinstance(obj[key], dict) and "string" in obj[key]:
                            return obj[key]["string"]
                        # é€’å½’æ£€æŸ¥å­—å…¸çš„æ‰€æœ‰å€¼
                        for k, v in obj.items():
                            result = find_value(v, key)
                            if result is not None:
                                return result
                    # å¦‚æœæ˜¯åˆ—è¡¨
                    elif isinstance(obj, list):
                        # é€’å½’æ£€æŸ¥åˆ—è¡¨çš„æ‰€æœ‰é¡¹
                        for item in obj:
                            result = find_value(item, key)
                            if result is not None:
                                return result
                    return None
                
                # å°è¯•å¤šç§å¯èƒ½çš„ç¾¤åç§°å­—æ®µ
                for name_key in ["NickName", "ChatRoomName", "nickname", "chatroomname", "DisplayName", "displayname"]:
                    name_value = find_value(data, name_key)
                    if name_value:
                        if isinstance(name_value, dict) and "string" in name_value:
                            group_name = name_value["string"]
                        elif isinstance(name_value, str):
                            group_name = name_value
                        if group_name:
                            logger.info(f"[WX859] æˆåŠŸè·å–åˆ°ç¾¤åç§°: {group_name} (å­—æ®µ: {name_key})")
                            break
                
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè®°å½•æ•´ä¸ªå“åº”ä»¥ä¾¿è°ƒè¯•
                if not group_name:
                    logger.warning(f"[WX859] æ— æ³•ä»APIå“åº”ä¸­æå–ç¾¤åç§°ï¼Œå“åº”å†…å®¹: {json.dumps(data, ensure_ascii=False)[:200]}...")
            else:
                logger.warning(f"[WX859] è·å–ç¾¤è¯¦æƒ…å¤±è´¥: {group_info_response}")
            
            # ç¡®ä¿åœ¨chatrooms_infoä¸­åˆ›å»ºè¯¥ç¾¤çš„æ¡ç›®
            if group_id not in chatrooms_info:
                chatrooms_info[group_id] = {
                    "chatroomId": group_id,
                    "nickName": group_name or group_id,  # å¦‚æœè·å–åˆ°ç¾¤ååˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨ç¾¤ID
                    "chatRoomOwner": "",
                    "members": [],
                    "last_update": int(time.time())
                }
            else:
                # æ›´æ–°ç°æœ‰æ¡ç›®çš„ç¾¤åç§°
                if group_name:
                    chatrooms_info[group_id]["nickName"] = group_name
            
            # ç«‹å³ä¿å­˜ç¾¤åç§°ä¿¡æ¯
            with open(chatrooms_file, 'w', encoding='utf-8') as f:
                json.dump(chatrooms_info, f, ensure_ascii=False, indent=2)
            
            logger.info(f"[WX859] å·²æ›´æ–°ç¾¤ {group_id} çš„åç§°: {group_name or 'æœªè·å–åˆ°'}")
            
            # æ›´æ–°ç¾¤åç¼“å­˜
            if group_name:
                if not hasattr(self, "group_name_cache"):
                    self.group_name_cache = {}
                self.group_name_cache[f"group_name_{group_id}"] = group_name
            # ============== ç¾¤åç§°è·å–å®Œæ¯• ==============
            
            # æ¥ä¸‹æ¥ç»§ç»­è·å–ç¾¤æˆå‘˜è¯¦æƒ…
            # è°ƒç”¨APIè·å–ç¾¤æˆå‘˜è¯¦æƒ…
            params = {
                "QID": group_id,  # ç¾¤IDå‚æ•°
                "wxid": self.wxid  # è‡ªå·±çš„wxidå‚æ•°ï¼Œæ”¹ä¸ºå°å†™
            }
            
            try:
                # æ„å»ºå®Œæ•´çš„API URLç”¨äºæ—¥å¿—
                api_url = f"http://{api_host}:{api_port}{api_path_prefix}/Group/GetChatRoomMemberDetail"
                logger.debug(f"[WX859] æ­£åœ¨è¯·æ±‚ç¾¤æˆå‘˜è¯¦æƒ…API: {api_url}")
                logger.debug(f"[WX859] è¯·æ±‚å‚æ•°: {json.dumps(params, ensure_ascii=False)}")
                
                # è°ƒç”¨APIè·å–ç¾¤æˆå‘˜è¯¦æƒ…
                response = await self._call_api("/Group/GetChatRoomMemberDetail", params)
                
                if not response or not isinstance(response, dict):
                    logger.error(f"[WX859] è·å–ç¾¤æˆå‘˜è¯¦æƒ…å¤±è´¥: æ— æ•ˆå“åº”")
                    return None
                
                # æ£€æŸ¥å“åº”æ˜¯å¦æˆåŠŸ
                if not response.get("Success", False):
                    logger.error(f"[WX859] è·å–ç¾¤æˆå‘˜è¯¦æƒ…å¤±è´¥: {response.get('Message', 'æœªçŸ¥é”™è¯¯')}")
                    return None
                
                # æå–NewChatroomData
                data = response.get("Data", {})
                new_chatroom_data = data.get("NewChatroomData", {})
                
                if not new_chatroom_data:
                    logger.error(f"[WX859] è·å–ç¾¤æˆå‘˜è¯¦æƒ…å¤±è´¥: å“åº”ä¸­æ— NewChatroomData")
                    return None
                
                # æå–æˆå‘˜ä¿¡æ¯
                member_count = new_chatroom_data.get("MemberCount", 0)
                chat_room_members = new_chatroom_data.get("ChatRoomMember", [])
                
                # ç¡®ä¿æ˜¯æœ‰æ•ˆçš„æˆå‘˜åˆ—è¡¨
                if not isinstance(chat_room_members, list):
                    logger.error(f"[WX859] è·å–ç¾¤æˆå‘˜è¯¦æƒ…å¤±è´¥: ChatRoomMemberä¸æ˜¯æœ‰æ•ˆçš„åˆ—è¡¨")
                    return None
                
                # æ›´æ–°ç¾¤èŠæˆå‘˜ä¿¡æ¯
                members = []
                for member in chat_room_members:
                    if not isinstance(member, dict):
                        continue
                    
                    # æå–æˆå‘˜å¿…è¦ä¿¡æ¯
                    member_info = {
                        "UserName": member.get("UserName", ""),
                        "NickName": member.get("NickName", ""),
                        "DisplayName": member.get("DisplayName", ""),
                        "ChatroomMemberFlag": member.get("ChatroomMemberFlag", 0),
                        "InviterUserName": member.get("InviterUserName", ""),
                        "BigHeadImgUrl": member.get("BigHeadImgUrl", ""),
                        "SmallHeadImgUrl": member.get("SmallHeadImgUrl", "")
                    }
                    
                    members.append(member_info)
                
                # æ›´æ–°ç¾¤èŠä¿¡æ¯
                chatrooms_info[group_id]["members"] = members
                chatrooms_info[group_id]["last_update"] = int(time.time())
                chatrooms_info[group_id]["memberCount"] = member_count
                
                # åŒæ—¶æ›´æ–°ç¾¤ä¸»ä¿¡æ¯
                for member in members:
                    if member.get("ChatroomMemberFlag") == 2049:  # ç¾¤ä¸»æ ‡å¿—
                        chatrooms_info[group_id]["chatRoomOwner"] = member.get("UserName", "")
                        break
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                with open(chatrooms_file, 'w', encoding='utf-8') as f:
                    json.dump(chatrooms_info, f, ensure_ascii=False, indent=2)
                
                logger.info(f"[WX859] å·²æ›´æ–°ç¾¤èŠ {group_id} æˆå‘˜ä¿¡æ¯ï¼Œæˆå‘˜æ•°: {len(members)}")
                
                # è¿”å›æˆå‘˜ä¿¡æ¯
                return new_chatroom_data
            except Exception as e:
                logger.error(f"[WX859] è·å–ç¾¤æˆå‘˜è¯¦æƒ…å¤±è´¥: {e}")
                logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                return None
        except Exception as e:
            logger.error(f"[WX859] è·å–ç¾¤æˆå‘˜è¯¦æƒ…è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None

    async def _get_group_name(self, group_id):
        """è·å–ç¾¤åç§°"""
        try:
            logger.debug(f"[WX859] å°è¯•è·å–ç¾¤ {group_id} çš„åç§°")
            
            # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦æœ‰ç¾¤å
            cache_key = f"group_name_{group_id}"
            if hasattr(self, "group_name_cache") and cache_key in self.group_name_cache:
                cached_name = self.group_name_cache[cache_key]
                logger.debug(f"[WX859] ä»ç¼“å­˜ä¸­è·å–ç¾¤å: {cached_name}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç¾¤æˆå‘˜è¯¦æƒ…
                tmp_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp")
                chatrooms_file = os.path.join(tmp_dir, 'wx859_rooms.json')
                
                need_update = True
                # è®¾å®šç¼“å­˜æœ‰æ•ˆæœŸä¸º24å°æ—¶(86400ç§’)
                cache_expiry = 86400
                current_time = int(time.time())
                
                if os.path.exists(chatrooms_file):
                    try:
                        with open(chatrooms_file, 'r', encoding='utf-8') as f:
                            chatrooms_info = json.load(f)
                        
                        # æ£€æŸ¥ç¾¤ä¿¡æ¯æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
                        if (group_id in chatrooms_info and 
                            "last_update" in chatrooms_info[group_id] and 
                            current_time - chatrooms_info[group_id]["last_update"] < cache_expiry and
                            "members" in chatrooms_info[group_id] and 
                            len(chatrooms_info[group_id]["members"]) > 0):
                            logger.debug(f"[WX859] ç¾¤ {group_id} ä¿¡æ¯å·²å­˜åœ¨ä¸”æœªè¿‡æœŸï¼Œè·³è¿‡æ›´æ–°")
                            need_update = False
                    except Exception as e:
                        logger.error(f"[WX859] æ£€æŸ¥ç¾¤ä¿¡æ¯ç¼“å­˜æ—¶å‡ºé”™: {e}")
                
                # åªæœ‰éœ€è¦æ›´æ–°æ—¶æ‰å¯åŠ¨çº¿ç¨‹è·å–ç¾¤æˆå‘˜è¯¦æƒ…
                if need_update:
                    logger.debug(f"[WX859] ç¾¤ {group_id} ä¿¡æ¯éœ€è¦æ›´æ–°ï¼Œå¯åŠ¨æ›´æ–°çº¿ç¨‹")
                    threading.Thread(target=lambda: asyncio.run(self._get_group_member_details(group_id))).start()
                
                return cached_name
            
            # æ£€æŸ¥æ–‡ä»¶ä¸­æ˜¯å¦å·²ç»æœ‰ç¾¤ä¿¡æ¯ï¼Œä¸”æœªè¿‡æœŸ
            tmp_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp")
            if not os.path.exists(tmp_dir):
                os.makedirs(tmp_dir)
            
            chatrooms_file = os.path.join(tmp_dir, 'wx859_rooms.json')
            
            # è®¾å®šç¼“å­˜æœ‰æ•ˆæœŸä¸º24å°æ—¶(86400ç§’)
            cache_expiry = 86400
            current_time = int(time.time())
            
            if os.path.exists(chatrooms_file):
                try:
                    with open(chatrooms_file, 'r', encoding='utf-8') as f:
                        chatrooms_info = json.load(f)
                    
                    # æ£€æŸ¥ç¾¤ä¿¡æ¯æ˜¯å¦å­˜åœ¨ä¸”æœªè¿‡æœŸ
                    if (group_id in chatrooms_info and 
                        "nickName" in chatrooms_info[group_id] and
                        chatrooms_info[group_id]["nickName"] and
                        chatrooms_info[group_id]["nickName"] != group_id and
                        "last_update" in chatrooms_info[group_id] and 
                        current_time - chatrooms_info[group_id]["last_update"] < cache_expiry):
                        
                        # ä»æ–‡ä»¶ä¸­è·å–ç¾¤å
                        group_name = chatrooms_info[group_id]["nickName"]
                        logger.debug(f"[WX859] ä»æ–‡ä»¶ç¼“å­˜ä¸­è·å–ç¾¤å: {group_name}")
                        
                        # ç¼“å­˜ç¾¤å
                        if not hasattr(self, "group_name_cache"):
                            self.group_name_cache = {}
                        self.group_name_cache[cache_key] = group_name
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç¾¤æˆå‘˜è¯¦æƒ…
                        need_update_members = not ("members" in chatrooms_info[group_id] and 
                                                len(chatrooms_info[group_id]["members"]) > 0)
                        
                        if need_update_members:
                            logger.debug(f"[WX859] ç¾¤ {group_id} åç§°å·²ç¼“å­˜ï¼Œä½†éœ€è¦æ›´æ–°æˆå‘˜ä¿¡æ¯")
                            threading.Thread(target=lambda: asyncio.run(self._get_group_member_details(group_id))).start()
                        else:
                            logger.debug(f"[WX859] ç¾¤ {group_id} ä¿¡æ¯å·²å®Œæ•´ä¸”æœªè¿‡æœŸï¼Œæ— éœ€æ›´æ–°")
                        
                        return group_name
                except Exception as e:
                    logger.error(f"[WX859] ä»æ–‡ä»¶è·å–ç¾¤åå‡ºé”™: {e}")
            
            logger.debug(f"[WX859] ç¾¤ {group_id} ä¿¡æ¯ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸï¼Œéœ€è¦ä»APIè·å–")
            
            # è°ƒç”¨APIè·å–ç¾¤ä¿¡æ¯ - ä½¿ç”¨ç¾¤èŠAPI
            params = {
                "QID": group_id,  # ç¾¤IDå‚æ•°ï¼Œæ­£ç¡®çš„å‚æ•°åæ˜¯QID
                "Wxid": self.wxid  # è‡ªå·±çš„wxidå‚æ•°
            }
            
            try:
                # è·å–APIé…ç½®
                api_host = conf().get("wx859_api_host", "127.0.0.1")
                api_port = conf().get("wx859_api_port", 8059)
                
                # å›ºå®šä½¿ç”¨859åè®®ï¼Œæ ¹æ®swagger.jsonå®šä¹‰ï¼Œä½¿ç”¨/apiå‰ç¼€
                api_path_prefix = "/api"
                
                # æ„å»ºå®Œæ•´çš„API URLç”¨äºæ—¥å¿—
                api_url = f"http://{api_host}:{api_port}{api_path_prefix}/Group/GetChatRoomInfo"
                logger.debug(f"[WX859] æ­£åœ¨è¯·æ±‚ç¾¤ä¿¡æ¯API: {api_url}")
                logger.debug(f"[WX859] è¯·æ±‚å‚æ•°: {json.dumps(params, ensure_ascii=False)}")  # è®°å½•è¯·æ±‚å‚æ•°
                
                # å°è¯•ä½¿ç”¨ç¾¤èŠä¸“ç”¨API
                group_info = await self._call_api("/Group/GetChatRoomInfo", params)
                
                # ä¿å­˜ç¾¤èŠè¯¦æƒ…åˆ°ç»Ÿä¸€çš„JSONæ–‡ä»¶
                try:
                    # è¯»å–ç°æœ‰çš„ç¾¤èŠä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    chatrooms_info = {}
                    if os.path.exists(chatrooms_file):
                        try:
                            with open(chatrooms_file, 'r', encoding='utf-8') as f:
                                chatrooms_info = json.load(f)
                            logger.debug(f"[WX859] å·²åŠ è½½ {len(chatrooms_info)} ä¸ªç°æœ‰ç¾¤èŠä¿¡æ¯")
                        except Exception as e:
                            logger.error(f"[WX859] åŠ è½½ç°æœ‰ç¾¤èŠä¿¡æ¯å¤±è´¥: {str(e)}")
                    
                    # æå–å¿…è¦çš„ç¾¤èŠä¿¡æ¯
                    if group_info and isinstance(group_info, dict):
                        # é€’å½’å‡½æ•°ç”¨äºæŸ¥æ‰¾ç‰¹å®škeyçš„å€¼
                        def find_value(obj, key):
                            # å¦‚æœæ˜¯å­—å…¸
                            if isinstance(obj, dict):
                                # ç›´æ¥æ£€æŸ¥å½“å‰å­—å…¸
                                if key in obj:
                                    return obj[key]
                                # æ£€æŸ¥å¸¦æœ‰"string"åµŒå¥—çš„å­—å…¸
                                if key in obj and isinstance(obj[key], dict) and "string" in obj[key]:
                                    return obj[key]["string"]
                                # é€’å½’æ£€æŸ¥å­—å…¸çš„æ‰€æœ‰å€¼
                                for k, v in obj.items():
                                    result = find_value(v, key)
                                    if result is not None:
                                        return result
                            # å¦‚æœæ˜¯åˆ—è¡¨
                            elif isinstance(obj, list):
                                # é€’å½’æ£€æŸ¥åˆ—è¡¨çš„æ‰€æœ‰é¡¹
                                for item in obj:
                                    result = find_value(item, key)
                                    if result is not None:
                                        return result
                            return None
                        
                        # å°è¯•æå–ç¾¤åç§°åŠå…¶ä»–ä¿¡æ¯
                        group_name = None
                        
                        # é¦–å…ˆå°è¯•ä»NickNameä¸­è·å–
                        nickname_obj = find_value(group_info, "NickName")
                        if isinstance(nickname_obj, dict) and "string" in nickname_obj:
                            group_name = nickname_obj["string"]
                        elif isinstance(nickname_obj, str):
                            group_name = nickname_obj
                        
                        # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–å¯èƒ½çš„å­—æ®µ
                        if not group_name:
                            for name_key in ["ChatRoomName", "nickname", "name", "DisplayName"]:
                                name_value = find_value(group_info, name_key)
                                if name_value:
                                    if isinstance(name_value, dict) and "string" in name_value:
                                        group_name = name_value["string"]
                                    elif isinstance(name_value, str):
                                        group_name = name_value
                                    if group_name:
                                        break
                        
                        # æå–ç¾¤ä¸»ID
                        owner_id = None
                        for owner_key in ["ChatRoomOwner", "chatroomowner", "Owner"]:
                            owner_value = find_value(group_info, owner_key)
                            if owner_value:
                                if isinstance(owner_value, dict) and "string" in owner_value:
                                    owner_id = owner_value["string"]
                                elif isinstance(owner_value, str):
                                    owner_id = owner_value
                                if owner_id:
                                    break
                        
                        # æ£€æŸ¥ç¾¤èŠä¿¡æ¯æ˜¯å¦å·²å­˜åœ¨
                        if group_id in chatrooms_info:
                            # æ›´æ–°å·²æœ‰ç¾¤èŠä¿¡æ¯
                            if group_name:
                                chatrooms_info[group_id]["nickName"] = group_name
                            if owner_id:
                                chatrooms_info[group_id]["chatRoomOwner"] = owner_id
                            chatrooms_info[group_id]["last_update"] = int(time.time())
                        else:
                            # åˆ›å»ºæ–°ç¾¤èŠä¿¡æ¯
                            chatrooms_info[group_id] = {
                                "chatroomId": group_id,
                                "nickName": group_name or group_id,
                                "chatRoomOwner": owner_id or "",
                                "members": [],
                                "last_update": int(time.time())
                            }
                        
                        # ä¿å­˜åˆ°æ–‡ä»¶
                        with open(chatrooms_file, 'w', encoding='utf-8') as f:
                            json.dump(chatrooms_info, f, ensure_ascii=False, indent=2)
                        
                        logger.info(f"[WX859] å·²æ›´æ–°ç¾¤èŠ {group_id} åŸºç¡€ä¿¡æ¯")
                        
                        # ç¼“å­˜ç¾¤å
                        if group_name:
                            if not hasattr(self, "group_name_cache"):
                                self.group_name_cache = {}
                            self.group_name_cache[cache_key] = group_name
                            
                            # å¼‚æ­¥è·å–ç¾¤æˆå‘˜è¯¦æƒ…ï¼ˆä¸é˜»å¡å½“å‰æ–¹æ³•ï¼‰
                            threading.Thread(target=lambda: asyncio.run(self._get_group_member_details(group_id))).start()
                            
                            return group_name
                    
                except Exception as save_err:
                    logger.error(f"[WX859] ä¿å­˜ç¾¤èŠä¿¡æ¯åˆ°æ–‡ä»¶å¤±è´¥: {save_err}")
                    import traceback
                    logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                
                # å¦‚æœä¸Šé¢çš„å¤„ç†æ²¡æœ‰è¿”å›ç¾¤åç§°ï¼Œå†æ¬¡å°è¯•ä»åŸå§‹æ•°æ®ä¸­æå–
                if group_info and isinstance(group_info, dict):
                    # å°è¯•ä»APIè¿”å›ä¸­è·å–ç¾¤åç§°
                    group_name = None
                    
                    # å°è¯•å¤šç§å¯èƒ½çš„å­—æ®µå
                    possible_fields = ["NickName", "nickname", "ChatRoomName", "chatroomname", "DisplayName", "displayname"]
                    for field in possible_fields:
                        if field in group_info and group_info[field]:
                            group_name = group_info[field]
                            if isinstance(group_name, dict) and "string" in group_name:
                                group_name = group_name["string"]
                            break
                    
                    if group_name:
                        logger.debug(f"[WX859] è·å–åˆ°ç¾¤åç§°: {group_name}")
                        
                        # ç¼“å­˜ç¾¤å
                        if not hasattr(self, "group_name_cache"):
                            self.group_name_cache = {}
                        self.group_name_cache[cache_key] = group_name
                        
                        # å¼‚æ­¥è·å–ç¾¤æˆå‘˜è¯¦æƒ…
                        threading.Thread(target=lambda: asyncio.run(self._get_group_member_details(group_id))).start()
                        
                        return group_name
                    else:
                        logger.warning(f"[WX859] APIè¿”å›æˆåŠŸä½†æœªæ‰¾åˆ°ç¾¤åç§°å­—æ®µ: {json.dumps(group_info, ensure_ascii=False)}")
                else:
                    logger.warning(f"[WX859] APIè¿”å›æ— æ•ˆæ•°æ®: {group_info}")
            except Exception as e:
                # è¯¦ç»†è®°å½•APIè¯·æ±‚å¤±è´¥çš„é”™è¯¯ä¿¡æ¯
                logger.error(f"[WX859] ä½¿ç”¨ç¾¤èŠAPIè·å–ç¾¤åç§°å¤±è´¥: {e}")
                logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
                logger.error(f"[WX859] è¯·æ±‚å‚æ•°: {json.dumps(params, ensure_ascii=False)}")
            
            # å¦‚æœæ— æ³•è·å–ç¾¤åï¼Œä½¿ç”¨ç¾¤IDä½œä¸ºåç§°
            logger.debug(f"[WX859] æ— æ³•è·å–ç¾¤åç§°ï¼Œä½¿ç”¨ç¾¤IDä»£æ›¿: {group_id}")
            # ç¼“å­˜ç»“æœ
            if not hasattr(self, "group_name_cache"):
                self.group_name_cache = {}
            self.group_name_cache[cache_key] = group_id
            
            # å°½ç®¡è·å–ç¾¤åå¤±è´¥ï¼Œä»ç„¶å°è¯•è·å–ç¾¤æˆå‘˜è¯¦æƒ…
            threading.Thread(target=lambda: asyncio.run(self._get_group_member_details(group_id))).start()
            
            return group_id
        except Exception as e:
            logger.error(f"[WX859] è·å–ç¾¤åç§°å¤±è´¥: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return group_id

    async def _get_chatroom_member_nickname(self, group_id, member_wxid):
        """è·å–ç¾¤æˆå‘˜çš„æ˜µç§°"""
        if not group_id or not member_wxid:
            return member_wxid
            
        try:
            # ä¼˜å…ˆä»ç¼“å­˜è·å–ç¾¤æˆå‘˜ä¿¡æ¯
            tmp_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tmp")
            chatrooms_file = os.path.join(tmp_dir, 'wx859_rooms.json')
            
            if os.path.exists(chatrooms_file):
                with open(chatrooms_file, 'r', encoding='utf-8') as f:
                    chatrooms_info = json.load(f)
                
                if group_id in chatrooms_info and "members" in chatrooms_info[group_id]:
                    for member in chatrooms_info[group_id]["members"]:
                        if member.get("UserName") == member_wxid:
                            # ä¼˜å…ˆä½¿ç”¨ç¾¤å†…æ˜¾ç¤ºåç§°(ç¾¤æ˜µç§°)
                            if member.get("DisplayName"):
                                logger.debug(f"[WX859] è·å–åˆ°æˆå‘˜ {member_wxid} çš„ç¾¤æ˜µç§°: {member.get('DisplayName')}")
                                return member.get("DisplayName")
                            # å…¶æ¬¡ä½¿ç”¨æˆå‘˜æ˜µç§°
                            elif member.get("NickName"):
                                logger.debug(f"[WX859] è·å–åˆ°æˆå‘˜ {member_wxid} çš„æ˜µç§°: {member.get('NickName')}")
                                return member.get("NickName")
            
            # å¦‚æœç¼“å­˜ä¸­æ²¡æœ‰ï¼Œå°è¯•æ›´æ–°ç¾¤æˆå‘˜ä¿¡æ¯
            await self._get_group_member_details(group_id)
            
            # å†æ¬¡å°è¯•ä»æ›´æ–°åçš„ç¼“å­˜ä¸­è·å–
            if os.path.exists(chatrooms_file):
                with open(chatrooms_file, 'r', encoding='utf-8') as f:
                    chatrooms_info = json.load(f)
                
                if group_id in chatrooms_info and "members" in chatrooms_info[group_id]:
                    for member in chatrooms_info[group_id]["members"]:
                        if member.get("UserName") == member_wxid:
                            # ä¼˜å…ˆä½¿ç”¨ç¾¤å†…æ˜¾ç¤ºåç§°
                            if member.get("DisplayName"):
                                logger.debug(f"[WX859] æ›´æ–°åè·å–åˆ°æˆå‘˜ {member_wxid} çš„ç¾¤æ˜µç§°: {member.get('DisplayName')}")
                                return member.get("DisplayName")
                            # å…¶æ¬¡ä½¿ç”¨æˆå‘˜æ˜µç§°
                            elif member.get("NickName"):
                                logger.debug(f"[WX859] æ›´æ–°åè·å–åˆ°æˆå‘˜ {member_wxid} çš„æ˜µç§°: {member.get('NickName')}")
                                return member.get("NickName")
        except Exception as e:
            logger.error(f"[WX859] è·å–ç¾¤æˆå‘˜æ˜µç§°å‡ºé”™: {e}")
        
        # é»˜è®¤è¿”å›wxid
        return member_wxid

    async def _get_current_login_wxid(self):
        """è·å–å½“å‰APIæœåŠ¡å™¨ç™»å½•çš„å¾®ä¿¡è´¦å·"""
        try:
            # å°è¯•é€šè¿‡profileæ¥å£è·å–å½“å‰ç™»å½•è´¦å·
            response = await self._call_api("/User/Profile", {"Wxid": ""})
            
            if response and isinstance(response, dict) and response.get("Success", False):
                data = response.get("Data", {})
                userinfo = data.get("userInfo", {})
                # å°è¯•è·å–userNameï¼Œè¿™é€šå¸¸æ˜¯wxid
                if "userName" in userinfo:
                    return userinfo["userName"]
                # å°è¯•è·å–UserNameï¼Œæœ‰äº›ç‰ˆæœ¬å¯èƒ½æ˜¯å¤§å†™
                elif "UserName" in userinfo:
                    return userinfo["UserName"]
                # å°è¯•è·å–stringç»“æ„ä¸­çš„wxid
                elif isinstance(userinfo, dict):
                    for key in ["userName", "UserName"]:
                        if key in userinfo and isinstance(userinfo[key], dict) and "string" in userinfo[key]:
                            return userinfo[key]["string"]
            
            # å¦‚æœä»¥ä¸Šæ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•é€šè¿‡å…¶ä»–æ¥å£
            response = await self._call_api("/User/GetSelfInfo", {})
            if response and isinstance(response, dict) and response.get("Success", False):
                data = response.get("Data", {})
                return data.get("Wxid", "")
                
            return ""
        except Exception as e:
            logger.error(f"[WX859] è·å–å½“å‰ç™»å½•è´¦å·å¤±è´¥: {e}")
            return ""
            
    async def _check_api_login_consistency(self, saved_wxid):
        """æ£€æŸ¥APIæœåŠ¡å™¨ç™»å½•çš„è´¦å·æ˜¯å¦ä¸ä¿å­˜çš„ä¸€è‡´"""
        try:
            # å°è¯•è·å–å½“å‰ç™»å½•çš„ç”¨æˆ·ä¿¡æ¯
            profile = await self.bot.get_profile()
            
            if not profile or not isinstance(profile, dict):
                logger.warning("[WX859] è·å–ç”¨æˆ·èµ„æ–™å¤±è´¥ï¼Œæ— æ³•ç¡®è®¤ç™»å½•ä¸€è‡´æ€§")
                return False
            
            # æå–å½“å‰ç™»å½•ç”¨æˆ·çš„wxid
            current_wxid = None
            userinfo = profile.get("userInfo", {})
            
            if isinstance(userinfo, dict):
                if "wxid" in userinfo:
                    current_wxid = userinfo["wxid"]
                elif "userName" in userinfo:
                    current_wxid = userinfo["userName"]
                elif "UserName" in userinfo:
                    current_wxid = userinfo["UserName"]
            
            # å¦‚æœæ²¡æœ‰è·å–åˆ°å½“å‰wxidï¼Œè¿”å›False
            if not current_wxid:
                logger.warning("[WX859] æ— æ³•ä»ç”¨æˆ·èµ„æ–™ä¸­è·å–wxidï¼Œæ— æ³•ç¡®è®¤ç™»å½•ä¸€è‡´æ€§")
                return False
            
            # æ¯”è¾ƒå½“å‰wxidä¸ä¿å­˜çš„wxidæ˜¯å¦ä¸€è‡´
            is_consistent = (current_wxid == saved_wxid)
            
            if is_consistent:
                logger.info(f"[WX859] APIæœåŠ¡å™¨ç™»å½•ç”¨æˆ·ä¸æœ¬åœ°ä¿å­˜ä¸€è‡´: {saved_wxid}")
            else:
                logger.warning(f"[WX859] APIæœåŠ¡å™¨ç™»å½•ç”¨æˆ· ({current_wxid}) ä¸æœ¬åœ°ä¿å­˜ ({saved_wxid}) ä¸ä¸€è‡´")
            
            return is_consistent
        except Exception as e:
            logger.error(f"[WX859] æ£€æŸ¥ç™»å½•ä¸€è‡´æ€§å¤±è´¥: {e}")
            return False

    async def _refresh_token(self, wxid, device_id=None):
        """å¤„ç†tokenè¿‡æœŸé—®é¢˜"""
        try:
            # å°è¯•ä½¿ç”¨RefreshTokenæ¥å£
            params = {
                "wxid": wxid  # å‚æ•°åæ”¹ä¸ºå°å†™
            }
            if device_id:
                params["device_id"] = device_id
                
            response = await self._call_api("/Login/RefreshToken", params)
            
            if response and isinstance(response, dict) and response.get("Success", False):
                logger.info("[WX859] æˆåŠŸåˆ·æ–°token")
                return True
                
            # å¦‚æœåˆ·æ–°å¤±è´¥ï¼Œå°è¯•äºŒæ¬¡ç™»å½•
            logger.info("[WX859] åˆ·æ–°tokenå¤±è´¥ï¼Œå°è¯•äºŒæ¬¡ç™»å½•")
            login_result = await self._twice_login(wxid, device_id)
            
            return login_result
        except Exception as e:
            logger.error(f"[WX859] åˆ·æ–°tokenå¤±è´¥: {e}")
            return False
            
    async def _process_api_response(self, response, wxid=None, device_id=None):
        """å¤„ç†APIå“åº”ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°token"""
        if not response:
            return response
            
        if isinstance(response, dict):
            # æ£€æŸ¥æ˜¯å¦è¿”å›tokenè¿‡æœŸé”™è¯¯
            error_code = response.get("code", 0)
            error_msg = response.get("message", "")
            
            token_expired_codes = [40014, 40016, 41001, 42001, 42002, 42003]
            token_expired_messages = ["token expired", "invalid token", "token invalid", "access_token expired"]
            
            is_token_expired = (error_code in token_expired_codes) or any(msg in error_msg.lower() for msg in token_expired_messages)
            
            if is_token_expired and wxid:
                logger.warning(f"[WX859] æ£€æµ‹åˆ°tokenè¿‡æœŸé—®é¢˜: {error_code} - {error_msg}")
                success = await self._refresh_token(wxid, device_id)
                if success:
                    logger.info("[WX859] åˆ·æ–°tokenæˆåŠŸï¼Œé‡è¯•è¯·æ±‚")
                    # è¿™é‡Œéœ€è¦è¿”å›ä¸€ä¸ªç‰¹æ®Šå€¼ï¼Œå‘ŠçŸ¥è°ƒç”¨æ–¹éœ€è¦é‡è¯•è¯·æ±‚
                    return {"__retry_needed__": True}
                else:
                    logger.error("[WX859] åˆ·æ–°tokenå¤±è´¥")
        
        return response

    async def _send_app_xml(self, to_user_id, xml_content, app_type: int):
        """å‘é€App XMLæ¶ˆæ¯çš„å¼‚æ­¥æ–¹æ³• (ä½¿ç”¨ _call_api å’Œ /Msg/SendApp ç«¯ç‚¹)"""
        try:
            if not to_user_id:
                logger.error("[WX859] Send App XML failed: receiver ID is empty")
                return None
            if not xml_content or not isinstance(xml_content, str):
                logger.error("[WX859] Send App XML failed: XML content is invalid or not a string")
                return None
            if not xml_content.strip():
                logger.error("[WX859] Send App XML failed: XML content is empty string")
                return None

            params = {
                "ToWxid": to_user_id,
                "Xml": xml_content, 
                "Type": app_type,   
                "wxid": self.wxid
            }
            
            logger.debug(f"[WX859] Calling _call_api for App XML. Endpoint: /Msg/SendApp, Params: Wxid={params['wxid']}, ToWxid={params['ToWxid']}, Type={params['Type']}, Xml snippet={xml_content[:100]}...")
            
            # Using the endpoint found in WechatAPIClient source, _call_api will prepend /api or /VXAPI
            result = await self._call_api("/Msg/SendApp", params)

            if result and isinstance(result, dict):
                success = result.get("Success", False)
                if not success:
                    error_msg = result.get("Message", "Unknown error after _call_api")
                    logger.error(f"[WX859] _call_api for Send App XML indicated failure: {error_msg}. API Result: {result}")
            else:
                logger.error(f"[WX859] _call_api for Send App XML returned invalid result: {result}")
            return result # Return the result from _call_api
                        
        except Exception as e:
            logger.error(f"[WX859] Send App XML failed (General Exception in _send_app_xml): {e}")
            import traceback
            logger.error(traceback.format_exc())
            # Ensure a consistent error response structure if needed by the caller
            return {"Success": False, "Message": f"Exception in _send_app_xml: {e}"}

    async def _send_voice(self, to_user_id, voice_file_path_segment):
        """å‘é€è¯­éŸ³æ¶ˆæ¯çš„å¼‚æ­¥æ–¹æ³• (å•ä¸ªMP3ç‰‡æ®µè·¯å¾„), å†…éƒ¨å¤„ç†SILKè½¬æ¢."""
        if not PYSLIK_AVAILABLE:
            logger.error("[WX859] Send voice failed: pysilk library is not available.")
            return {"Success": False, "Message": "pysilk library not available"}

        try:
            if not to_user_id:
                logger.error("[WX859] Send voice failed: receiver ID is empty")
                return {"Success": False, "Message": "Receiver ID empty"}
            if not os.path.exists(voice_file_path_segment):
                logger.error(f"[WX859] Send voice failed: voice segment file not found at {voice_file_path_segment}")
                return {"Success": False, "Message": f"Voice segment not found: {voice_file_path_segment}"}

            # Load MP3 segment with pydub
            try:
                audio = AudioSegment.from_file(voice_file_path_segment, format="mp3")
            except Exception as e_pydub_load:
                logger.error(f"[WX859] Failed to load voice segment {voice_file_path_segment} with pydub: {e_pydub_load}")
                logger.error(traceback.format_exc()) # Log full traceback for pydub errors
                return {"Success": False, "Message": f"Pydub load failed: {e_pydub_load}"}

            # Process audio: set channels, frame rate
            audio = audio.set_channels(1)
            supported_rates = [8000, 12000, 16000, 24000] # SILK supported rates
            closest_rate = min(supported_rates, key=lambda x: abs(x - audio.frame_rate))
            audio = audio.set_frame_rate(closest_rate)
            duration_ms = len(audio)

            if duration_ms == 0:
                logger.warning(f"[WX859] Voice segment {voice_file_path_segment} has zero duration after pydub processing. Skipping send.")
                return {"Success": False, "Message": "Zero duration audio"}

            # Encode to SILK using pysilk
            try:
                if hasattr(pysilk, 'async_encode') and asyncio.iscoroutinefunction(pysilk.async_encode):
                    silk_data = await pysilk.async_encode(audio.raw_data, sample_rate=audio.frame_rate)
                elif hasattr(pysilk, 'encode'): 
                    silk_data = pysilk.encode(audio.raw_data, sample_rate=audio.frame_rate)
                else:
                    logger.error("[WX859] pysilk does not have a usable 'encode' or 'async_encode' method.")
                    return {"Success": False, "Message": "pysilk encode method not found"}
            except Exception as e_silk_encode:
                logger.error(f"[WX859] SILK encoding failed for {voice_file_path_segment}: {e_silk_encode}")
                logger.error(traceback.format_exc()) # Log full traceback for silk errors
                return {"Success": False, "Message": f"SILK encoding failed: {e_silk_encode}"}
            
            voice_base64 = base64.b64encode(silk_data).decode('utf-8')

            params = {
                "ToWxid": to_user_id,
                "Wxid": self.wxid,
                "Base64": voice_base64,
                "Type": 4, 
                "VoiceTime": int(duration_ms)
            }
            
            logger.info(f"[WX859] Preparing to send SILK voice: ToWxid={to_user_id}, File={voice_file_path_segment}, VoiceTime={duration_ms}ms, Type=4")
            
            result = await self._call_api("/Msg/SendVoice", params)
            
            if result and result.get("Success"):
                logger.info(f"[WX859] Send SILK voice success: ToWxid={to_user_id}, File={voice_file_path_segment}, Result: {result}")
            else:
                logger.error(f"[WX859] Send SILK voice failed: ToWxid={to_user_id}, File={voice_file_path_segment}, Result: {result}")
            return result

        except Exception as e:
            logger.error(f"[WX859] Exception in _send_voice (SILK processing) for {voice_file_path_segment} to {to_user_id}: {e}")
            logger.error(traceback.format_exc())
            return {"Success": False, "Message": f"General exception in _send_voice: {e}"}

    def _compose_context(self, ctype: ContextType, content, **kwargs):
        """é‡å†™çˆ¶ç±»æ–¹æ³•ï¼Œæ„å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡"""
        try:
            # ç›´æ¥åˆ›å»ºContextå¯¹è±¡ï¼Œç¡®ä¿ç»“æ„æ­£ç¡®
            context = Context()
            context.type = ctype
            context.content = content
            
            # è·å–æ¶ˆæ¯å¯¹è±¡
            msg = kwargs.get('msg')
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¾¤èŠæ¶ˆæ¯
            isgroup = kwargs.get('isgroup', False)
            if isgroup and msg and hasattr(msg, 'from_user_id'):
                # è®¾ç½®ç¾¤ç»„ç›¸å…³ä¿¡æ¯
                context["isgroup"] = True
                context["from_user_nickname"] = msg.sender_wxid  # å‘é€è€…æ˜µç§°
                context["from_user_id"] = msg.sender_wxid  # å‘é€è€…ID
                context["to_user_id"] = msg.to_user_id  # æ¥æ”¶è€…ID
                context["other_user_id"] = msg.other_user_id or msg.from_user_id  # ç¾¤ID
                context["group_name"] = msg.from_user_id  # ä¸´æ—¶ä½¿ç”¨ç¾¤IDä½œä¸ºç¾¤å
                context["group_id"] = msg.from_user_id  # ç¾¤ID
                context["msg"] = msg  # æ¶ˆæ¯å¯¹è±¡
                
                # è®¾ç½®session_idä¸ºç¾¤ID
                context["session_id"] = msg.other_user_id or msg.from_user_id
                
            else:
                # ç§èŠæ¶ˆæ¯
                context["isgroup"] = False
                context["from_user_nickname"] = msg.sender_wxid if msg and hasattr(msg, 'sender_wxid') else ""
                context["from_user_id"] = msg.sender_wxid if msg and hasattr(msg, 'sender_wxid') else ""
                context["to_user_id"] = msg.to_user_id if msg and hasattr(msg, 'to_user_id') else ""
                context["other_user_id"] = None
                context["msg"] = msg
                
                # è®¾ç½®session_idä¸ºå‘é€è€…ID
                context["session_id"] = msg.sender_wxid if msg and hasattr(msg, 'sender_wxid') else ""

            # ğŸ”¥ ä¿®å¤ç¾¤èŠæ¶ˆæ¯æ¥æ”¶è€…IDè®¾ç½®é”™è¯¯çš„é—®é¢˜
            # å¯¹äºç¾¤èŠæ¶ˆæ¯ï¼Œæ¥æ”¶è€…åº”è¯¥æ˜¯ç¾¤èŠIDï¼Œè€Œä¸æ˜¯å‘é€è€…ä¿¡æ¯
            if isgroup and msg and hasattr(msg, 'from_user_id'):
                # ç¡®ä¿ç¾¤èŠæ¶ˆæ¯çš„æ¥æ”¶è€…æ˜¯ç¾¤èŠIDï¼ˆmsg.from_user_idï¼‰
                context["receiver"] = msg.from_user_id
                logger.debug(f"[WX859] ç¾¤èŠæ¶ˆæ¯æ¥æ”¶è€…è®¾ç½®ä¸ºç¾¤èŠID: {msg.from_user_id}")
            else:
                # ç§èŠæ¶ˆæ¯çš„æ¥æ”¶è€…æ˜¯å‘é€è€…
                context["receiver"] = msg.sender_wxid if msg and hasattr(msg, 'sender_wxid') else ""
                logger.debug(f"[WX859] ç§èŠæ¶ˆæ¯æ¥æ”¶è€…è®¾ç½®ä¸ºå‘é€è€…: {context['receiver']}")
            
            # è®°å½•åŸå§‹æ¶ˆæ¯ç±»å‹ 
            context["origin_ctype"] = ctype
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logger.debug(f"[WX859] ç”ŸæˆContextå¯¹è±¡: type={context.type}, content={context.content}, isgroup={context['isgroup']}, session_id={context.get('session_id', 'None')}, receiver={context.get('receiver', 'None')}")

            try:
                # æ‰‹åŠ¨è§¦å‘ ON_RECEIVE_MESSAGE äº‹ä»¶
                e_context = EventContext(Event.ON_RECEIVE_MESSAGE, {"channel": self, "context": context})
                PluginManager().emit_event(e_context)
                context = e_context["context"] # è·å–å¯èƒ½è¢«ä¿®æ”¹çš„ context

                # æ£€æŸ¥æ’ä»¶æ˜¯å¦é˜»æ­¢äº†æ¶ˆæ¯ æˆ– æ¸…ç©ºäº† context
                if e_context.is_pass() or context is None:
                    breaked_by = getattr(e_context, 'breaked_by', 'N/A') if hasattr(e_context, 'breaked_by') else 'N/A'
                    logger.info(f"[WX859] Event ON_RECEIVE_MESSAGE breaked or context is None by plugin {breaked_by}. Returning early.")
                    return context # è¿”å› None æˆ–è¢«æ’ä»¶ä¿®æ”¹çš„ context
            except Exception as plugin_e:
                logger.error(f"[WX859] Error during ON_RECEIVE_MESSAGE event processing: {plugin_e}", exc_info=True)
                # æ ¹æ®éœ€è¦å†³å®šæ˜¯å¦ç»§ç»­ï¼Œè¿™é‡Œé€‰æ‹©ç»§ç»­è¿”å›åŸå§‹ context
            # --- ç»“æŸæ’å…¥ä¿®æ”¹ ---

            return context # è¿”å›ï¼ˆå¯èƒ½è¢«æ’ä»¶ä¿®æ”¹è¿‡çš„ï¼‰context
        except Exception as e:
            # ... (åŸæœ‰çš„é”™è¯¯å¤„ç† L4875-L4878) ...
            logger.error(f"[WX859] æ„å»ºä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            logger.error(f"[WX859] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None
